[{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating. — Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2022-11-03T00:00:00Z","image":"https://jmwyf.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"https://jmwyf.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"PyTorch深度学习（2） Deep Learning = Learning Hierarchical Representations 深度学习即学习层次的表征。\n1. 卷积神经网络 1.1 神经网络可视化（Visualization of neural networks） 神经网络每一层的操作有点像将空间某些区域进行折叠\n1.2 卷积神经网络的起源（Convolutional Neural Network；CNN） 受到Fukushima在视觉皮层建模方面的启发，使用简单/复杂的细胞层次结构，结合有监督的训练和反向传播，由Yann LeCun教授于88-89年在多伦多大学开发了第一个CNN。\nFukushima的工作具体是什么呢？\n手写数字识别。首次提出应用多层简单或者复杂的细胞结构建模，特征：手工加无监督聚类学习。无反向传播。\n1.3 卷积神经网络分解 通用的CNN架构能被分解为以下几个基本结构。\n标准化（Normalisation）:对比度标准化等 滤波器组（Filter banks）:边缘检测等 非线性化（Non-linearities）:稀疏化、ReLU等 池化（pooling）:最大池化（max pooling）等 2. 自然信号数据（Natural Signals） 2.1 自然信号数据特性 周期性：在时域很多模式都会重复出现 局部性：相邻的点较相远的点来说更具关联性 合成性：复杂的事物可以由简单的事物组合而成。字母-\u0026gt;单词-\u0026gt;句子-\u0026gt;文章 2.2 对应神经网络中的处理方法 周期性$\\rightarrow$参数共享\n如果数据存在周期性，可以使用参数共享，即卷积核。 局部性$\\rightarrow$稀疏\n如果数据存在局部性，那么每个神经元只需要与前几个神经元连接 合成性$\\rightarrow$多层\n即神经网络中多层网络合成最终的结果 3. Pytorch实现Mnist手写字识别 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # load package and data import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets, transforms import matplotlib.pyplot as plt device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # 神经网络模型偏爱标准化数据，原因是均值为0方差为1的数据在sigmoid、tanh经过激活函数后求导得到的导数很大， # 反之原始数据不仅分布不均（噪声大）而且数值通常都很大（本例中数值范围是0~255），激活函数后求导得到的导数 # 则接近与0，这也被称为梯度消失。 # 目录放自己下载好的mnist目录，没有下载将download=True,自己新建一个存放数据目录即可 train_loader = torch.utils.data.DataLoader( datasets.MNIST(\u0026#39;../LSTM_mnist/mnist\u0026#39;, train=True, download=False, transform=transforms.Compose([ transforms.ToTensor(), # mnist数据集均值0.1307，标准差0.3081 transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True) test_loader = torch.utils.data.DataLoader( datasets.MNIST(\u0026#39;../LSTM_mnist/mnist\u0026#39;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=1000, shuffle=True) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # define model class SimpleCNN(nn.Module): def __init__(self, input_size, n_feature, output_size): super(SimpleCNN, self).__init__() self.n_feature = n_feature # 关于nn.Conv2d()中参数的解释 # in_channels (int): Number of channels in the input image # out_channels (int): Number of channels produced by the convolution # kernel_size (int or tuple): Size of the convolving kernel # default stride=1, padding=0, dilation=1, groups=1 # [groupsc参数详解](https://www.jianshu.com/p/20ba3d8f283c) # [图解卷积神经网络中stride, padding等操作可视化](https://github.com/vdumoulin/conv_arithmetic) # input: (N, C_in, H_in, W_in) self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5) self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5) self.fc1 = nn.Linear(n_feature*4*4, 50) self.fc2 = nn.Linear(50, 10) def forward(self, x): x = self.conv1(x) # Mnist数据原始大小（28*28）28-5+1 = 24 (24*24*n_feature) x = F.relu(x) x = F.max_pool2d(x, kernel_size=2) # (12*12*n_feature) x = self.conv2(x) # 12-5+1 = 8 (8*8*n_feature) x = F.relu(x) x = F.max_pool2d(x, kernel_size=2) # (4*4*n_feature)这里解释了上面全连接时为啥是4*4 x = x.view(-1, self.n_feature*4*4) x = self.fc1(x) x = F.relu(x) x = self.fc2(x) x = F.log_softmax(x, dim=1) return x 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 # hyper parameters epochs = 1 input_size = 28*28 output_size = 10 n_features = 6 lr = 0.01 model = SimpleCNN(input_size, n_features, output_size) model.to(device) # optimizer optimizer = optim.SGD(model.parameters(), lr, momentum=0.5) print(\u0026#39;Number of parameters: {}\u0026#39;.format(get_n_params(model))) # model train for epoch in range(epochs): model.train() for i, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) output = model(data) loss = F.nll_loss(output, target) optimizer.zero_grad() loss.backward() optimizer.step() if i % 100 == 0: print(\u0026#39;Train Epoch [{}/{}], [{}/{} ({:.0f}%)], Loss: {:.4f}\u0026#39;.format( epoch+1, epochs, i*len(data), len(train_loader.dataset), 100*i/len(train_loader), loss.item())) # model eval model.eval() test_loss = 0 correct = 0 accuracy_list = [] for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) test_loss += F.nll_loss(output, target, reduction=\u0026#39;sum\u0026#39;).item() pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability correct += pred.eq(target.data.view_as(pred)).cpu().sum().item() test_loss /= len(test_loader.dataset) accuracy = 100. * correct / len(test_loader.dataset) accuracy_list.append(accuracy) print(\u0026#39;\\nTest set Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\u0026#39;.format( test_loss, correct, len(test_loader.dataset), accuracy)) 1 2 3 4 5 6 7 # 几个预测的实例可视化 for i in range(10): plt.subplot(2, 5, i+1) plt.imshow(data[i][0]) plt.title(\u0026#34;Prediction: {}\u0026#34;.format( output.data.max(1, keepdim=True)[1][i].item())) plt.show() 4. 补充 可以做一个有趣的实验即打乱图片中的像素后CNN识别正确率下降，而全连接网络则不会，即与最开始提到的三个特性以及对于神经网络采取的假设是吻合的。 参考2中是对卷积神经网络全面的介绍，包括CNN中常用那些层，以及常用的模型和参数多少计算。 ref NYC PyTorch Deep Learning课程网站 cs231n convolutional networks pytorch官方文档Conv2d 课程convnet.ipynb ","date":"2020-04-01T14:51:32Z","image":"https://jmwyf.github.io/images/pytorch/mnist_pre.png","permalink":"https://jmwyf.github.io/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/","title":"PyTorch深度学习（2）"},{"content":"LSTM简介以及pytorch实例 在去年介绍的一篇paper中，应用了多任务RNN来解决问题，当时RNN指的即是LSTM。本文介绍LSTM实现以及应用。\n1. LSTM简介 循环神经网络要点在于可以将上一时刻的信息传递给下一时刻，但是在需要长程信息依赖的场景，训练一个好的RNN十分困难，存在梯度爆炸和梯度消失的情况。LSTM通过刻意的设计来解决该问题。\n简单的RNN网络中重复的模块只有一个简单的结构，例如一个relu层，而在LSTM中重复的模块拥有4个不同的结构相互交互来完成。\n1.1 首先决定从cell中丢弃什么信息 $$f_t = \\sigma(W_f*[h_{t-1}, X_t] + b_f) \\tag1$$ sigma函数在0到1选择代表丢弃与否\n1.2 什么样的新信息存放到cell中 $$i_t = \\sigma(W_i*[h_{t-1}, x_t] + b_i) \\tag2$$\n$$\\widetilde{C_t} = tanh(W_c*[h_{t-1}, x_t] + b_c) \\tag3$$\n$$C_t = f_t*C_{t-1} + {i_t} * \\widetilde{C_{t}} \\tag4$$\n4式中旧状态与$f_t$相乘，丢弃确定需要丢弃的信息，加上新的候选值。可以看到假如遗忘门一直为1，就可以保持以前的信息$C_{t-1}$\n1.3 输出结果 $$o_t = \\sigma(W_o[h_{t-1}, x_t] + b_o)\\tag5$$ $$h_t = o_t*tanh(C_t)\\tag6$$\n2. LSTM实例以及Pytorch实现 循环神经网络可以应用到以下场景。\n点对点（单个图片（文字）被分类；图像分类） 点对序列（单个图像（文字）被分为多个类；图像输出文字） 序列分析（一系列图片（文字）被分类；情感分析） 不等长序列对序列（机器翻译） 等长序列对序列（视频帧分类） 举两个例子：图像分类以及时间序列预测\n2.1 LSTM图像分类 关于图片分类常用卷积神经网络，侧重空间上处理；而循环神经网络侧重序列处理。但是也能用来图片分类。第一个例子以常用的mnist手写字体识别为例。\n2.1.1 导入所需用到的包以及超参数设置等 1 2 3 4 5 6 7 8 9 10 11 # Setup import torch from torch import nn from torch.utils.data import DataLoader import torchvision.datasets as dsets import torchvision.transforms as transforms torch.manual_seed(1) # Device configuration device = torch.device(\u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) 2.1.2 导入数据集 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # Mnist手写数字 train_data = dsets.MNIST(root=\u0026#39;./mnist/\u0026#39;, # 保存或者提取位置 train=True, # this is tra`ining data transform=transforms.ToTensor(), # 转换 PIL.Image or numpy.ndarray 成 # torch.FloatTensor (C x H x W), 训练的时候 normalize 成 [0.0, 1.0] 区间 download=True, # 没下载就下载, 下载了就不用再下了改成False ) test_data = dsets.MNIST(root=\u0026#39;./mnist/\u0026#39;, train=False, transform=transforms.ToTensor()) # Dataloader # PyTorch中数据读取的一个重要接口，该接口定义在dataloader.py中，只要是用PyTorch来训练模型基本都会用到该接口（除非用户重写…）， # 该接口的目的：将自定义的Dataset根据batch size大小、是否shuffle等封装成一个Batch Size大小的Tensor，用于后面的训练。 train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True) # 在每个epoch开始的时候，对数据重新打乱进行训练。在这里其实没啥用，因为只训练了一次 test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False) 2.1.3 建立模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # LSTM # __init__ is basically a function which will \u0026#34;initialize\u0026#34;/\u0026#34;activate\u0026#34; the properties of the class for a specific object # self represents that object which will inherit those properties class simpleLSTM(nn.Module): def __init__(self, input_size, hidden_size, num_layers, num_classes): super(simpleLSTM, self).__init__() self.hidden_size = hidden_size self.num_layers = num_layers self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) self.fc = nn.Linear(hidden_size, num_classes) def forward(self, x): # x shape (batch, time_step, input_size) # out shape (batch, time_step, output_size) # h_n shape (n_layers, batch, hidden_size) # h_c shape (n_layers, batch, hidden_size) # 初始化hidden和memory cell参数 h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # forward propagate lstm out, (h_n, h_c) = self.lstm(x, (h0, c0)) # 选取最后一个时刻的输出 out = self.fc(out[:, -1, :]) return out model = simpleLSTM(input_size, hidden_size, num_layers, num_classes) # loss and optimizer criterion = nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.parameters(), lr) 2.1.4 训练模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # train the model # 关于reshape(-1)的解释 https://www.zhihu.com/question/52684594 # view()和reshape()区别的解释 https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch # Hyper Parameters epochs = 1 # 训练整批数据多少次, 为了节约时间, 我们只训练一次 batch_size = 64 time_step = 28 # rnn 时间步数 / 图片高度 input_size = 28 # rnn 每步输入值 / 图片每行像素 hidden_size = 64 num_layers = 1 num_classes = 10 lr = 0.01 # learning rate total_step = len(train_loader) for epoch in range(epochs): for i, (images, labels) in enumerate(train_loader): images = images.reshape(-1, time_step, input_size).to(device) labels = labels.to(device) # forward pass outputs = model(images) loss = criterion(outputs, labels) # backward and optimize optimizer.zero_grad() loss.backward() optimizer.step() if i % 100 == 0: print(\u0026#39;Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\u0026#39; .format(epoch+1, epochs, i+1, total_step, loss.item())) 2.1.5 测试模型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Test the model # https://stackoverflow.com/questions/55627780/evaluating-pytorch-models-with-torch-no-grad-vs-model-eval # torch.max()用法。https://blog.csdn.net/weixin_43255962/article/details/84402586 model.eval() with torch.no_grad(): correct = 0 total = 0 for images, labels in test_loader: images = images.reshape(-1, time_step, input_size).to(device) labels = labels.to(device) outputs = model(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(\u0026#39;Test Accuracy of the model on the 10000 test images: {} %\u0026#39;.format(100 * correct / total)) 2.2 时间序列预测 Todo\n2.3 图像输出文字 Todo\n补充 在原始发表文献用的图示是类似于下图的这种，看起来比较好容易理解当初形成LSTM的原因 pytorch lstm函数用法示例\n1 2 3 4 5 rnn = nn.LSTM(10, 20, 2) # input_size, hidden_size, num_layers input = torch.randn(5, 3, 10) # time_step, batch, input_size（这里input_size即features） h0 = torch.randn(2, 3, 20) # num_layers, batch, hidden_size c0 = torch.randn(2, 3, 20) # num_layers, batch, hidden_size output, (hn, cn) = rnn(input, (h0, c0)) # output包含从最后一层lstm中输出的ht。shape: time_step, batch, hidden_size hidden_size is the number of units of your LSTM cell. This means all the layers (input, forget, etc.) will have this size\nhidden_size即pytorch隐含层每个结构中含有的隐含cell数目\nlstm函数中加入bidirectional=True参数即双向神经网络 Reference 理解LSTM(http://colah.github.io/posts/2015-08-Understanding-LSTMs/) 高效RNN(http://karpathy.github.io/2015/05/21/rnn-effectiveness/) Hochreiter \u0026amp; Schmidhuber (1997) LSTM Pytorch LSTM官方文档(https://pytorch.org/docs/stable/nn.html#lstm) ","date":"2020-03-09T15:07:13Z","image":"https://jmwyf.github.io/images/LSTM/LSTM.jpg","permalink":"https://jmwyf.github.io/p/lstm%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%BB%A5%E5%8F%8Apytorch%E5%AE%9E%E4%BE%8B/","title":"LSTM应用场景以及pytorch实例"},{"content":"PyTorch深度学习（1） 1. History, motivation and evolution of Deep Learning 科学技术发展如海浪一样也会潮起潮落，深度学习在经历了几次低谷后。2010年左右，在语音识别领域取得进展，2012年在计算机视觉领域也发展起来，随后各个领域都开始使用应用深度学习方法，而似乎渐渐抛弃了其他方法，那么深度学习是不是问题的最终解决之道呢？研究方向宽泛而多维才是合理的道路，不应过分追求热点领域。正如上世纪80年代日本学者在低谷时期仍然坚持自己的研究领域。\n学习表征：如何学习好的表征是深度学习要解决的问题之一，原始数据以一种有用的形式返回。自然状态下数据相互依赖有关系的。高效的表达方式应该是每类数据都是完全独立能完全单独表达某个方面。\nspace tiling random projections polynomial classifier radial basis functions kernel machines 2. Gradient Descent and Backpropagation 2.1 Gradient Descent $$J(w, b) = \\frac{1}{m}\\sum_1^mL(\\hat{y}^{(i)}, y^{i})$$ J(w, b)为问题的cost function即目标函数，即m个样本的损失函数平均值。使目标函数最小得到此时w,b参数是我们的优化问题。\n2.1.1 梯度下降(batch gradient descent) 梯度下降即上式对所有样本计算求出目标函数，通过对w,b求梯度来找到目标函数最小值，常用的一个比喻即找最快路径下山。数学理解是算法实现的重要一步，但与在计算机上实现还是有区别的，那么实际做法是什么样的呢？\n当你对复杂的问题想不清楚时，我们都可以从一个简单的例子出发来简化问题，对于这个问题考虑只有一个样本时，我们怎么编程实现呢？对w1、 b1，计算一个样本的loss然后对w1、b1求导优化思路很清晰，那么有m个样本的时候呢？只需将其他样本计算loss，然后对w1、b1求导相加。最后在通过学习率来更新w、b。可以看到每次更新都需要进行m次运算\n2.1.2 小样本梯度下降（mini-batch gradient descent） 在每次更新时用n个样本，不用全部的样本。在深度学习中常用这种方法。用mini-batch可以享受向量化带来的便利，也不用全梯度下降那么大计算量，同时这也是应对冗余数据的一种方法。\n2.1.3 随机梯度下降(stochastic gradient descent) 当n = 1的时候，每次更新的时候用1个样本。该方法在大多数情况下比全样本的梯度下降要快。\n三种优化方法最后收敛吗？最后能达到全局最小值吗？这是优化方法都需要考虑到的。可以阅读Optimization Methods for Large-Scale Machine Learning，我自己还没读过\u0026hellip;\n2.2 Backprop 反向传播是为了求梯度用到的微积分链式法则，从而使梯度下降算法运行。\n2.3 PyTorch训练神经网络步骤 output = model(input) 即神经网络前向传播 J = loss(output, label) 计算cost function model.zero_grad() 清除梯度计算 J.backward() 对requires_grad = True的变量计算梯度 optimiser.step() 进行梯度下降 3. 总结 看了前两节，觉得还是吴恩达大佬讲的好一些。建议网页上快速过内容即可，视频不用细看。\n","date":"2020-03-05T11:50:19Z","image":"https://jmwyf.github.io/images/pytorch/pytorch.jpeg","permalink":"https://jmwyf.github.io/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01/","title":"PyTorch深度学习（1）"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTex globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTex on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $$ y = x_t $$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"2019-03-08T00:00:00Z","permalink":"https://jmwyf.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"以下操作基于macOS，Windows仅供参考。\ngit初始化文件夹 进入目录\n1 git init 新建.gitignore 然后在其中加入需要忽略的文件或文件夹.gitignore 例如public\\\ngit删除远程分支文件 当我们需要删除暂存区或分支上的文件, 同时工作区也不需要这个文件了, 可以使用 git rm file_path\n当我们需要删除暂存区或分支上的文件, 但本地又需要使用, 只是不希望这个文件被版本控制, 可以使用 git rm –cached file_path\n所以我们经常使用以下命令来删除git中的文件\n1 2 3 git rm -r --cached filename git commit -m \u0026#39;delete some file\u0026#39; git push origin master git删除.DS_Store文件 从该仓库中删除已存在的DS_Store文件 1 find . -name .DS_Store -print0 | xargs -0 git rm -f --ignore-unmatch 新建.gitignore_global文件并将.DS_Store以及*/.DS_Store加入其中 1 2 3 4 vi .gitignore_global .DS_Store */.DS_Store git config --global core.excludesfile ~/.gitignore_global 推到仓库 1 2 git add .gitignore git commit -m \u0026#39;.DS_Store banished!\u0026#39; 检查仓库中是否还有 1 git status git冲突处理 git远程分支修改，本地也修改了准备提交出现冲突\n先拉在推 1 2 git pull --rebase #检查合并是否冲突 git push -u origin master 强制按本地更新 1 git push -f git子模块（submodule） 对于公共资源或者常用的代码，你可能会把最新版本逐个复制到N个项目中，如果使用了submodule模块，那么只需要在各个项目中\n1 git submodule update 进入子模块目录正常操作即可\ngit多账户切换 使用参考2中删除keychain access的方法，比较简单\nref git删除.DS_Store\nstackoverflow\ngit多账户切换\n","date":"2019-03-04T22:22:22Z","permalink":"https://jmwyf.github.io/p/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"git常用命令"}]