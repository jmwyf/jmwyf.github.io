<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><meta http-equiv=x-ua-compatible content="ie=edge"><title>Embedding是什么？ &#183; 从百草园到三味书屋</title><meta name=title content="Embedding是什么？ &#183; 从百草园到三味书屋"><meta name=description content="万物皆可Embedding"><link rel=canonical href=https://youngforever.tech/posts/20230222-embedding/><link type=text/css rel=stylesheet href=/css/main.bundle.min.1b07026ad335b957c216b421a55e1733ac5df10d02ae749f769a48518d7c9394.css integrity="sha256-GwcCatM1uVfCFrQhpV4XM6xd8Q0CrnSfdppIUY18k5Q="><script type=text/javascript src=/js/appearance.min.022d0ebc3b46a335eb1c7ef79b7f2de143d7cd5156d433638592ef1ce5f8554e.js integrity="sha256-Ai0OvDtGozXrHH73m38t4UPXzVFW1DNjhZLvHOX4VU4="></script>
<script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.75206d23ef83f4908b2bdd2317bf6ddff399e9173a16fff5451c40b8e857cfa8.js integrity="sha256-dSBtI++D9JCLK90jF79t3/OZ6Rc6Fv/1RRxAuOhXz6g=" data-copy=Copy data-copied=Copied></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:title" content="Embedding是什么？"><meta property="og:description" content="万物皆可Embedding"><meta property="og:type" content="article"><meta property="og:url" content="https://youngforever.tech/posts/20230222-embedding/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-02-21T23:13:00+00:00"><meta property="article:modified_time" content="2023-02-21T23:13:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Embedding是什么？"><meta name=twitter:description content="万物皆可Embedding"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"Embedding是什么？","headline":"Embedding是什么？","abstract":"万物皆可Embedding","inLanguage":"en","url":"https:\/\/youngforever.tech\/posts\/20230222-embedding\/","author":{"@type":"Person","name":"Yong"},"copyrightYear":"2023","dateCreated":"2023-02-21T23:13:00\u002b00:00","datePublished":"2023-02-21T23:13:00\u002b00:00","dateModified":"2023-02-21T23:13:00\u002b00:00","keywords":["nlp"],"mainEntityOfPage":"true","wordCount":"1103"}]</script><meta name=author content="Yong"><link href=https://github.com/yongfanbeta rel=me><link href=https://www.zhihu.com/people/kingofnight rel=me><link href=mailto:yongfan2020@outlook.com rel=me><link type=text/css rel=stylesheet href=/lib/katex/katex.min.b7600b193c9447a8351c98870a649381edb21ac786a1f74ef3c43ecce590c7f3748a479c570d18bb239eb7dc590d5f3e571d18d27d5addfdd0c7757d09c9ec28.css integrity="sha512-t2ALGTyUR6g1HJiHCmSTge2yGseGofdO88Q+zOWQx/N0ikecVw0YuyOet9xZDV8+Vx0Y0n1a3f3Qx3V9CcnsKA=="><script defer src=/lib/katex/katex.min.10a5b962f294de1a72c8e70dea34270313bf2fc82db3e61d615e98ca6b65f2993d625605b6a2608a1391b91a015caf3f70e2256a9a5d53a32cf0a74aeb204280.js integrity="sha512-EKW5YvKU3hpyyOcN6jQnAxO/L8gts+YdYV6Yymtl8pk9YlYFtqJgihORuRoBXK8/cOIlappdU6Ms8KdK6yBCgA=="></script>
<script defer src=/lib/katex/auto-render.min.8968ae052e67b7aafad1f0b3dba35dd19a9ed276e4d594c841b9772afee462c5fec8a314147ce3687dbe02733abe9d97b3e80d99a0405562634a6b8fc3be847e.js integrity="sha512-iWiuBS5nt6r60fCz26Nd0Zqe0nbk1ZTIQbl3Kv7kYsX+yKMUFHzjaH2+AnM6vp2Xs+gNmaBAVWJjSmuPw76Efg==" onload=renderMathInElement(document.body)></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-F4R8ND3VQP"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-F4R8ND3VQP",{anonymize_ip:!1})}</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold pe-2 text-primary-600 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral print:hidden sm:py-10"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>从百草园到三味书屋</a></div><ul class="flex list-none flex-col ltr:text-right rtl:text-left sm:flex-row"><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/about/ title=About><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">自画像</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/ai4h/ title=医学人工智能周刊><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">知无涯</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">朝花夕拾</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><a href=/tags/ title=Tags><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">标签</span></a></li><li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5"><button id=search-button-1 title="Search (/)">
<span class="group-dark:hover:text-primary-400 transition-colors group-hover:text-primary-600"><span class="relative inline-block align-text-bottom px-1 icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li></ul></nav></header><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Embedding是什么？</h1><div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2023-02-21 23:13:00 +0000 UTC">21 February 2023</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">3 mins</span></div><div class="my-1 text-xs leading-relaxed text-neutral-500 dark:text-neutral-400"><a href=/categories/deep-learning/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Deep Learning</a>
<a href=/tags/nlp/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">nlp</a></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs lg:ps-8"><div class="toc pe-5 print:hidden lg:sticky lg:top-10"><details open class="-ms-5 mt-0 overflow-hidden rounded-lg ps-5"><summary class="-ms-5 block cursor-pointer bg-neutral-100 py-1 ps-5 text-lg font-semibold text-neutral-800 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="-ms-5 border-s border-dotted border-neutral-300 py-2 ps-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#背景>背景</a></li><li><a href=#embedding是什么>Embedding是什么</a></li><li><a href=#embedding是如何实现的>Embedding是如何实现的</a></li><li><a href=#应用>应用</a></li></ul></nav></div></details></div></div><div class="min-w-0 min-h-0 max-w-prose grow"><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><p><figure><img class="mx-auto my-0 rounded-md" src=https://cdn.jsdelivr.net/gh/jmwyf/pichosting@master/embedding.png alt loading=lazy></figure></p><h2 id=背景 class="relative group">背景 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e8%83%8c%e6%99%af aria-label=Anchor>#</a></span></h2><p>在nlp领域，如何把词进行编码成数字，从而能输入到数学模型是需要考虑的：</p><p>索引编码<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>：</p><ul><li>整数编码，特征之间的关系无法捕捉</li></ul><p>one-hot编码的缺点：</p><ul><li>对于具有非常多类型的类别变量，变换后的向量维数过于巨大，且过于稀疏。</li><li>映射之间完全独立，并不能表示出不同类别之间的关系。</li></ul><h2 id=embedding是什么 class="relative group">Embedding是什么 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#embedding%e6%98%af%e4%bb%80%e4%b9%88 aria-label=Anchor>#</a></span></h2><p>嵌入是将正整数（索引值）转换为固定尺寸的稠密向量<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>。这句话来着keras文档中对embedding层的解释，非常概括，不太容易理解，但确实概括了要干的事情。</p><p>比如一句话，“我爱中国”对应的索引为[0,1,2,3]，要将这个索引转化为固定大小且稠密的向量来表示，而不是稀疏的one-hot编码。可以表示为$[[0.2, 0.5], [0.6,-0.1], [0.8, 0.4], [0.5, 0.5]]$，。</p><p>词嵌入通常是8-1024维度，根据数据量的大小来调整，高维度的嵌入能更好的捕捉词之间的关系，但是需要更多的数据来训练。</p><h2 id=embedding是如何实现的 class="relative group">Embedding是如何实现的 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#embedding%e6%98%af%e5%a6%82%e4%bd%95%e5%ae%9e%e7%8e%b0%e7%9a%84 aria-label=Anchor>#</a></span></h2><p>通过Embedding层实现，embedding层可以看作是一张从索引映射到稠密向量的查找表，当使用embedding层的时候，embedding层和神经网络其他层一样，权重是随机初始化的。根据你的训练任务，embedding层通过反向传播逐渐调整。</p><p>embedding层的具体结构即[索引长度，emb维度]的权重矩阵也可以看作查询表，输入为整数索引，对应权重矩阵即词嵌入。skip-gram模型的前半部分即词嵌入。</p><p>例如在tensorflow中，用于句子分类时的嵌入层，输入是整数索引，经过嵌入层、池化层、全连接输入训练可以得到嵌入层权重，即词嵌入。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>embedding_dim</span><span class=o>=</span><span class=mi>16</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Sequential</span><span class=p>([</span><span class=err> </span> 
</span></span><span class=line><span class=cl>	<span class=n>vectorize_layer</span><span class=p>,</span><span class=err> </span> 
</span></span><span class=line><span class=cl>	<span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s2>&#34;embedding&#34;</span><span class=p>),</span><span class=err> </span> 
</span></span><span class=line><span class=cl>	<span class=n>GlobalAveragePooling1D</span><span class=p>(),</span><span class=err> </span> <span class=n>Dense</span><span class=p>(</span><span class=mi>16</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;relu&#39;</span><span class=p>),</span><span class=err> </span> 
</span></span><span class=line><span class=cl>	<span class=n>Dense</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>])</span>
</span></span></code></pre></div><h2 id=应用 class="relative group">应用 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e5%ba%94%e7%94%a8 aria-label=Anchor>#</a></span></h2><p>最常用的就是词嵌入表达，但是万物可嵌入。Embedding在输入数据没有较好的数据表示时，能将输入数据根据下游任务转化为可学习的高维度向量表示，比如输入的为单词、图片或者输入的为空间位置等。</p><p>mnist数据集中的图片，可以通过嵌入层来表示，如下图所示，每个点代表一个图片(10000*784)，通过嵌入层，将图片的像素点转化为稠密的向量，然后通过t-SNE/pca降维，可以看到图片的空间分布。(generated by copilot)<figure><img class="mx-auto my-0 rounded-md" src=https://cdn.jsdelivr.net/gh/jmwyf/pichosting@master/mnistembedding.png alt loading=lazy></figure></p><p>在进行特征工程时，很难捕捉空间(时间)维度。通过使用深度学习嵌入层，我们可以通过提供一系列用户行为(作为索引)作为模型的输入来有效地捕捉这个空间维度。</p><p>我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=2cy4t3peazy8s</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://www.tensorflow.org/text/guide/word_embeddings target=_blank rel="noreferrer noopener">Word embeddings  |  Text  |  TensorFlow</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://keras.io/zh/layers/embeddings/ target=_blank rel="noreferrer noopener">嵌入层 Embedding - Keras 中文文档</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/20230205-skip-gram-part1/><span class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&larr;</span><span class="ltr:hidden rtl:inline">&rarr;</span></span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Skip-gram模型（1）</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-02-05 10:58:02 +0000 UTC">5 February 2023</time></span></span></a></span>
<span><a class="group flex text-right" href=/posts/20230302-clinicalbert/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">ClinicalBERT: 对医学文本建模用于再入院预测</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-03-01 10:12:00 +0000 UTC">1 March 2023</time></span></span>
<span class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class="ltr:inline rtl:hidden">&rarr;</span><span class="ltr:hidden rtl:inline">&larr;</span></span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><div id=cusdis_thread data-host=https://cusdis.com data-app-id=1cfc2662-243a-4573-b9e7-8b2b4a986fba data-page-id=f9287615825359c78e25e445c41a67c5 data-page-url=https://youngforever.tech/posts/20230222-embedding/ data-page-title=Embedding是什么？></div><script src=https://cusdis.com/js/cusdis.es.js></script></div></div></footer></article><div class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2023
Yong</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://git.io/hugo-congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="me-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"><button id=appearance-switcher-0 type=button aria-label="appearance switcher"><div class="flex h-12 w-12 items-center justify-center dark:hidden" title="Switch to dark appearance"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="hidden h-12 w-12 items-center justify-center dark:flex" title="Switch to light appearance"><span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://youngforever.tech/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative inline-block align-text-bottom px-1 icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative inline-block align-text-bottom px-1 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>