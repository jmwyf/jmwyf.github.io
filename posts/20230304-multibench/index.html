<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=theme-color content="rgb(255,255,255)"><meta http-equiv=x-ua-compatible content="ie=edge"><title>MultiBench多模态表征学习的多尺度基准 &#183; 从百草园到三味书屋</title><meta name=title content="MultiBench多模态表征学习的多尺度基准 &#183; 从百草园到三味书屋"><meta name=description content="Multiscale Benchmarks for Multimodal Representation Learning论文解读"><link rel=canonical href=https://jmwyf.github.io/posts/20230304-multibench/><link type=text/css rel=stylesheet href=/css/main.bundle.min.5f935e3bde5eb04b71e715589d63aef3157473e3876d675b8668999f64722e9730279be4ce53eef00b1b80ac602595bdd3a4a076af5d9c16137a98a6fadcb1eb.css integrity="sha512-X5NeO95esEtx5xVYnWOu8xV0c+OHbWdbhmiZn2RyLpcwJ5vkzlPu8AsbgKxgJZW906Sgdq9dnBYTepim+tyx6w=="><script type=text/javascript src=/js/appearance.min.c6198a5ecbc6c7b35a8568d29315f50cf5d775d4461c515a476359767f1a745c245aa83fa96b0c7d83da976cf77481e1fc29537a2391a53ffe69a991638802e6.js integrity="sha512-xhmKXsvGx7NahWjSkxX1DPXXddRGHFFaR2NZdn8adFwkWqg/qWsMfYPal2z3dIHh/ClTeiORpT/+aamRY4gC5g=="></script>
<script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.6d78c827ca7bcbf72056dbf698bf9aeb759a08966686187deb23f5949f73eca5f39b461284900cdfc08e2976d99eb80a8663648de778ba2a83e633ae16dbfc25.js integrity="sha512-bXjIJ8p7y/cgVtv2mL+a63WaCJZmhhh96yP1lJ9z7KXzm0YShJAM38COKXbZnrgKhmNkjed4uiqD5jOuFtv8JQ==" data-copy=Copy data-copied=Copied></script>
<link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:title" content="MultiBench多模态表征学习的多尺度基准"><meta property="og:description" content="Multiscale Benchmarks for Multimodal Representation Learning论文解读"><meta property="og:type" content="article"><meta property="og:url" content="https://jmwyf.github.io/posts/20230304-multibench/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-04T15:17:00+00:00"><meta property="article:modified_time" content="2023-03-04T15:17:00+00:00"><meta property="og:site_name" content="从百草园到三味书屋"><meta name=twitter:card content="summary"><meta name=twitter:title content="MultiBench多模态表征学习的多尺度基准"><meta name=twitter:description content="Multiscale Benchmarks for Multimodal Representation Learning论文解读"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posts","name":"MultiBench多模态表征学习的多尺度基准","headline":"MultiBench多模态表征学习的多尺度基准","abstract":"Multiscale Benchmarks for Multimodal Representation Learning论文解读","inLanguage":"en","url":"https:\/\/jmwyf.github.io\/posts\/20230304-multibench\/","author":{"@type":"Person","name":"Yong"},"copyrightYear":"2023","dateCreated":"2023-03-04T15:17:00\u002b00:00","datePublished":"2023-03-04T15:17:00\u002b00:00","dateModified":"2023-03-04T15:17:00\u002b00:00","keywords":["multimodal","mimic-iii"],"mainEntityOfPage":"true","wordCount":"1117"}]</script><meta name=author content="Yong"><link href=mailto:yongfan2020@outlook.com rel=me><script async src="https://www.googletagmanager.com/gtag/js?id=G-F4R8ND3VQP"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-F4R8ND3VQP",{anonymize_ip:!1})}</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><header class="py-6 font-semibold text-neutral-900 dark:text-neutral print:hidden sm:py-10"><nav class="flex items-start justify-between sm:items-center"><div class="flex flex-row items-center"><a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2" rel=me href=/>从百草园到三味书屋</a></div><ul class="flex flex-col list-none ltr:text-right rtl:text-left sm:flex-row"><li class="mb-1 group sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a href=/about/ title=About><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">自画像</span></a></li><li class="mb-1 group sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a href=/posts/ title=Posts><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">朝花夕拾</span></a></li><li class="mb-1 group sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><a href=/tags/ title=Tags><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2">签</span></a></li><li class="mb-1 group sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0"><button id=search-button-1 title="Search (/)">
<span class="transition-colors group-dark:hover:text-primary-400 group-hover:text-primary-600"><span class="relative inline-block align-text-bottom icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></span><span class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"></span></button></li></ul></nav></header><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header class=max-w-prose><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">MultiBench多模态表征学习的多尺度基准</h1><div class="mt-8 mb-12 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime="2023-03-04 15:17:00 +0000 UTC">4 March 2023</time><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">3 mins</span></div><div class="my-1 text-xs leading-relaxed text-neutral-500 dark:text-neutral-400"><a href=/categories/deep-learning/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">Deep Learning</a>
<a href=/tags/multimodal/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">multimodal</a>
<a href=/tags/mimic-iii/ class="rounded-md border border-neutral-200 px-1 py-[1px] hover:border-primary-300 hover:text-primary-700 dark:border-neutral-600 dark:hover:border-primary-600 dark:hover:text-primary-400">mimic-iii</a></div></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first px-0 lg:order-last lg:max-w-xs ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-10"><details open class="mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><a href=#引言>引言</a></li><li><a href=#多尺度多模态基准>多尺度多模态基准</a><ul><li><a href=#数据集>数据集</a></li><li><a href=#评价标准>评价标准</a></li></ul></li><li><a href=#multizoo多模态算法集合>MultiZoo：多模态算法集合</a><ul><li><a href=#数据预处理>数据预处理</a></li><li><a href=#融合范式>融合范式</a></li><li><a href=#优化目标>优化目标</a></li><li><a href=#训练过程>训练过程</a></li></ul></li><li><a href=#实验>实验</a></li><li><a href=#结论>结论</a><ul><li><a href=#未来拓展>未来拓展</a></li></ul></li><li><a href=#思考>思考</a></li></ul></nav></div></details></div></div><div class="min-w-0 min-h-0 max-w-prose grow"><p>MULTIBENCH，一个系统而统一的大规模多模态学习基准，涵盖15个数据集、10种模式、20个预测任务和6个研究领域<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>。</p><h2 id=引言 class="relative group">引言 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e5%bc%95%e8%a8%80 aria-label=Anchor>#</a></span></h2><p>背景：</p><ul><li>语言和视觉领域多模态学习发展不错，但是其他领域欠缺</li><li>现在的基准评价关注性能，没有量化缺点包括时间空间复杂度，由于不完美模态导致的鲁棒性降低，需要在性能、鲁棒性、复杂度取得平衡</li></ul><p>提出multibench就是解决以上问题：</p><ul><li>扩充收集各领域数据集、数据模态</li><li>量化复杂度</li><li>提出标准流程评价对噪声和缺失模态情况下的鲁棒性</li></ul><p>MultiBench是一个端到端的过程，包括数据预处理、数据集拆分、多模态算法、评估指标和交叉验证。</p><ul><li>开发工具包MultiZoo</li><li>可以用于workshop、教学等</li></ul><h2 id=多尺度多模态基准 class="relative group">多尺度多模态基准 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e5%a4%9a%e5%b0%ba%e5%ba%a6%e5%a4%9a%e6%a8%a1%e6%80%81%e5%9f%ba%e5%87%86 aria-label=Anchor>#</a></span></h2><p>第一版集中在多模态融合，对于多模态翻译等问题未来版本可能涉及</p><h3 id=数据集 class="relative group">数据集 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e6%95%b0%e6%8d%ae%e9%9b%86 aria-label=Anchor>#</a></span></h3><p>介绍了6大领域15个数据集，表1</p><ul><li>情感计算（affective computing）</li><li>医疗：时变和静态变量的整合使用</li><li>机器人</li><li>金融</li><li>人机交互</li><li>多媒体<figure><img class="mx-auto my-0 rounded-md" src=https://cdn.jsdelivr.net/gh/jmwyf/pichosting@master/multibenchdata.png alt></figure></li></ul><h3 id=评价标准 class="relative group">评价标准 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e8%af%84%e4%bb%b7%e6%a0%87%e5%87%86 aria-label=Anchor>#</a></span></h3><p>性能：</p><ul><li>regression: MSE, MAE,</li><li>classification: F1-score, AUPRC</li></ul><p>复杂度：</p><ul><li>data size in bits</li><li>number of model parameters</li><li>time and memory resources on CPU and GPU</li></ul><p>鲁棒性：</p><ul><li>单模态独有噪音：对图像、音频等单独处理</li><li>考虑多模态整体的不完善：比如缺失模态等</li></ul><h2 id=multizoo多模态算法集合 class="relative group">MultiZoo：多模态算法集合 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#multizoo%e5%a4%9a%e6%a8%a1%e6%80%81%e7%ae%97%e6%b3%95%e9%9b%86%e5%90%88 aria-label=Anchor>#</a></span></h2><p>涵盖实现multibench整个过程中的算法</p><h3 id=数据预处理 class="relative group">数据预处理 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e6%95%b0%e6%8d%ae%e9%a2%84%e5%a4%84%e7%90%86 aria-label=Anchor>#</a></span></h3><ul><li>WordAlign算法<ul><li>将各模态信息调整到统一粒度</li></ul></li></ul><h3 id=融合范式 class="relative group">融合范式 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e8%9e%8d%e5%90%88%e8%8c%83%e5%bc%8f aria-label=Anchor>#</a></span></h3><ul><li>早期和晚期融合<ul><li>EF，LF</li></ul></li><li>多模态张量: 多模态互补<ul><li>Tensor Fusion</li><li>Low-rank Tensor Fusion</li></ul></li><li>多模态乘法交互: 多模态交互<ul><li>MI-MATRIX</li><li>MI-VECTOR</li><li>MI-SCALAR</li></ul></li><li>多模态门控<ul><li>NL GATE: 自注意力机制</li></ul></li><li>时序注意力模型<ul><li>MULT: 多模态Transformer</li></ul></li><li>网络架构搜索<ul><li>MFAS</li></ul></li></ul><h3 id=优化目标 class="relative group">优化目标 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e4%bc%98%e5%8c%96%e7%9b%ae%e6%a0%87 aria-label=Anchor>#</a></span></h3><p>除了标准的监督损失函数，纳入一些新提出的目标函数</p><ul><li>CCA</li><li>REFNET</li><li>MFM</li><li>MCTN</li></ul><h3 id=训练过程 class="relative group">训练过程 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e8%ae%ad%e7%bb%83%e8%bf%87%e7%a8%8b aria-label=Anchor>#</a></span></h3><ul><li>Gradient Blending来计算融合的权重</li><li>Regularization by Maximizing Functional Entropies</li></ul><h2 id=实验 class="relative group">实验 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e5%ae%9e%e9%aa%8c aria-label=Anchor>#</a></span></h2><ul><li>泛化性能<ul><li>目前的方法表现出高方差，没有放之四海而皆准的模型，特别是对于未被研究的模式和任务。</li><li>后期融合表现比较均衡</li><li>有些融合方法是专门为2模态设计，有些在2/3模态表现不好</li></ul></li><li>单模态与多模态的权衡</li><li>性能与复杂度的权衡</li><li>性能与鲁棒性的权衡</li></ul><h2 id=结论 class="relative group">结论 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e7%bb%93%e8%ae%ba aria-label=Anchor>#</a></span></h2><p>一个大规模的基准，统一了以前在多模态研究中互不相干的工作，重点是易用性、可及性和可重复性。</p><h3 id=未来拓展 class="relative group">未来拓展 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e6%9c%aa%e6%9d%a5%e6%8b%93%e5%b1%95 aria-label=Anchor>#</a></span></h3><ul><li>其他的多模态问题</li><li>新的评价指标</li><li>多模态迁移学习或者协同学习</li><li>多模态多任务学习</li></ul><h2 id=思考 class="relative group">思考 <span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%e6%80%9d%e8%80%83 aria-label=Anchor>#</a></span></h2><p>MultiBench把以前多模态研究中使用的公开数据集，算法，评价指标等都统一在了一个框架下，期望标准化多模态学习过程，并且能将不同的算法模型在其他模态、任务中进行比较。大而全的框架确实能为各类多模态任务提供一个baseline，但是各专业领域内的多模态模型应该是存在一些差异的，就像我们很难期待一个医生能掌握律师干的事情，然而，人工智能的发展确实很快，比人还强大的通用人工智能应该也会实现。</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Liang, P. P. et al. MultiBench: Multiscale Benchmarks for Multimodal Representation Learning. (2021) doi:10.48550/arXiv.2107.07502.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="group flex" href=/posts/20230302-clinicalbert/><span class="mr-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-2 text-neutral-700 transition-transform group-hover:translate-x-[2px] group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">ClinicalBERT: 对医学文本建模用于再入院预测</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-03-01 10:12:00 +0000 UTC">1 March 2023</time></span></span></a></span>
<span><a class="group flex text-right" href=/posts/20230306-%E4%BB%80%E4%B9%88%E6%98%AF%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">什么是科学问题？</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime="2023-03-06 15:58:00 +0000 UTC">6 March 2023</time></span></span>
<span class="ml-2 text-neutral-700 transition-transform group-hover:translate-x-[2px] group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><div id=cusdis_thread data-host=https://cusdis.com data-app-id=1cfc2662-243a-4573-b9e7-8b2b4a986fba data-page-id=b20962d5c4b5c78cbe1f631106f92469 data-page-url=https://jmwyf.github.io/posts/20230304-multibench/ data-page-title=MultiBench多模态表征学习的多尺度基准></div><script async defer src=https://cusdis.com/js/cusdis.es.js></script></div></div></footer></article><div class="pointer-events-none absolute top-[100vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer class="py-10 print:hidden"><div class="flex items-center justify-between"><div><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2023
Yong</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://git.io/hugo-congo target=_blank rel="noopener noreferrer">Congo</a></p></div><div class="ltr:mr-14 rtl:ml-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"><button id=appearance-switcher-0 type=button aria-label="appearance switcher"><div class="flex items-center justify-center w-12 h-12 dark:hidden" title="Switch to dark appearance"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden w-12 h-12 dark:flex" title="Switch to light appearance"><span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div></footer><div id=search-wrapper class="invisible fixed inset-0 z-50 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://jmwyf.github.io/><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative inline-block align-text-bottom icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative inline-block align-text-bottom icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>