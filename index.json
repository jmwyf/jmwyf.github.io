[{"content":" æ—¥å¸¸æ¬ç –ğŸ“ï¼Œä¸šä½™ç§‘ç ”ğŸ§¬\n","date":"6 March 2023","permalink":"/","section":"","summary":"","title":""},{"content":"","date":"6 March 2023","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"6 March 2023","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"6 March 2023","permalink":"/tags/question/","section":"Tags","summary":"","title":"question"},{"content":"","date":"6 March 2023","permalink":"/categories/science/","section":"Categories","summary":"","title":"Science"},{"content":" ","date":"6 March 2023","permalink":"/tags/","section":"Tags","summary":" ","title":"Tags"},{"content":"ç§‘å­¦é—®é¢˜ï¼šåœ°çƒäººè¿˜æœªæ‰¾åˆ°ç­”æ¡ˆï¼Œä¸”æ— æ³•ç¡®å®šæ˜¯å¦èƒ½æ‰¾åˆ°ç­”æ¡ˆçš„é—®é¢˜ ï¼›12\næŠ€æœ¯é—®é¢˜ï¼šå®ç°æŸä¸ªç°å®å·²æœ‰åŠŸèƒ½çš„é€”å¾„ï¼›\nå·¥ç¨‹é—®é¢˜ï¼šç»“åˆå¤šä¸ªæŠ€æœ¯è§£å†³ä¸€ä¸ªç³»ç»ŸåŒ–ç°å®é—®é¢˜çš„æ–¹æ¡ˆï¼›\nï¼ˆç§‘å­¦é—®é¢˜ï¼šæˆ‘ä¸çŸ¥é“ï¼›\næŠ€æœ¯é—®é¢˜ï¼šæˆ‘æ²¡æƒ³åˆ°ï¼›\nå·¥ç¨‹é—®é¢˜ï¼šæˆ‘åšä¸äº†ï¼›ï¼‰\nå‚è€ƒæ–°ç‰ˆä¸–ç•Œå‰æ²¿125ä¸ªç§‘å­¦é—®é¢˜3\nSJTU \u0026amp; Science 125ä¸ªç§‘å­¦é—®é¢˜ï¼ˆ2021å¹´ç‰ˆæœ¬ï¼‰ # Medicine \u0026amp; Health (11) # åŒ»å­¦ä¸å¥åº·\nCan we predict the next pandemic? 1.æˆ‘ä»¬å¯ä»¥é¢„æµ‹ä¸‹ä¸€æ¬¡æµè¡Œç—…å—ï¼Ÿ\nWill we ever find a cure for the common cold? 2.æˆ‘ä»¬ä¼šæ‰¾åˆ°æ²»ç–—æ„Ÿå†’çš„æ–¹æ³•å—ï¼Ÿ\nCan we design and manufacture medicines customized for individual people? 3.æˆ‘ä»¬å¯ä»¥è®¾è®¡å’Œåˆ¶é€ å‡ºä¸ºä¸ªäººå®šåˆ¶çš„è¯ç‰©å—ï¼Ÿ\nCan a human tissue or organ be fully regenerated? 4.äººä½“ç»„ç»‡æˆ–å™¨å®˜å¯ä»¥å®Œå…¨å†ç”Ÿå—ï¼Ÿ\nHow is immune homeostasis maintained and regulated? 5.å¦‚ä½•ç»´æŒå’Œè°ƒèŠ‚å…ç–«ç¨³æ€ï¼Ÿ\nIs there a scientific basis to the Meridian System in traditional Chinese medicine? 6.ä¸­åŒ»çš„ç»ç»œç³»ç»Ÿæœ‰ç§‘å­¦ä¾æ®å—ï¼Ÿ\nHow will the next generation of vaccines be made? 7.ä¸‹ä¸€ä»£ç–«è‹—å°†å¦‚ä½•ç”Ÿäº§ï¼Ÿ\nCan we ever overcome antibiotic resistance? 8.æˆ‘ä»¬èƒ½å¦å…‹æœæŠ—ç”Ÿç´ è€è¯æ€§ï¼Ÿ\nWhat is the etiology of autism? 9.è‡ªé—­ç—‡çš„ç—…å› æ˜¯ä»€ä¹ˆï¼Ÿ\nWhat role does our microbiome play in health and disease? 10.æˆ‘ä»¬çš„å¾®ç”Ÿç‰©ç»„åœ¨å¥åº·å’Œç–¾ç—…ä¸­æ‰®æ¼”ä»€ä¹ˆè§’è‰²ï¼Ÿ\nCan xenotransplantation solve the shortage of donor organs? 11.å¼‚ç§ç§»æ¤èƒ½å¦è§£å†³ä¾›ä½“å™¨å®˜çš„çŸ­ç¼ºé—®é¢˜ï¼Ÿ\nBiology(22) # ç”Ÿå‘½ç§‘å­¦\nWhat could help conservation of the oceans? 1.ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä¿æŠ¤æµ·æ´‹ï¼Ÿ\nCan we stop ourselves from aging? 2.æˆ‘ä»¬å¯ä»¥é˜»æ­¢è‡ªå·±è¡°è€å—ï¼Ÿ\nWhy can only some cells become other cells? 3.ä¸ºä»€ä¹ˆåªæœ‰ä¸€äº›ç»†èƒä¼šå˜æˆå…¶ä»–ç»†èƒï¼Ÿ\nWhy are some genomes so big and others very small? 4.ä¸ºä»€ä¹ˆæœ‰äº›åŸºå› ç»„éå¸¸å¤§è€Œå¦ä¸€äº›å´å¾ˆå°ï¼Ÿ\nWill it be possible to cure all cancers? 5.æœ‰å¯èƒ½æ²»æ„ˆæ‰€æœ‰ç™Œç—‡å—ï¼Ÿ\nWhat genes make us uniquely human? 6.å“ªäº›åŸºå› ä½¿æˆ‘ä»¬äººç±»ä¸ä¼—ä¸åŒï¼Ÿ\nHow do migratory animals know where they\u0026rsquo;re going? 7.è¿å¾™åŠ¨ç‰©å¦‚ä½•çŸ¥é“å®ƒä»¬è¦å»å“ªé‡Œï¼Ÿ\nHow many species are there on Earth? 8.åœ°çƒä¸Šæœ‰å¤šå°‘ç‰©ç§ï¼Ÿ\nHow do organisms evolve? 9.æœ‰æœºä½“æ˜¯å¦‚ä½•è¿›åŒ–çš„ï¼Ÿ\nWhy did dinosaurs grow to be so big? 10.ä¸ºä»€ä¹ˆæé¾™é•¿å¾—å¦‚æ­¤ä¹‹å¤§ï¼Ÿ\nDid ancient humans interbreed with other human-like ancestors? 11.è¿œå¤äººç±»æ˜¯å¦æ›¾ä¸å…¶ä»–ç±»äººç¥–å…ˆæ‚äº¤ï¼Ÿ\nWhy do humans get so attached to dogs and cats? 12.äººç±»ä¸ºä»€ä¹ˆä¼šå¯¹çŒ«ç‹—å¦‚æ­¤ç€è¿·ï¼Ÿ\nWill the world\u0026rsquo;s population keep growing indefinitely? 13.ä¸–ç•Œäººå£ä¼šæ— é™å¢é•¿å—ï¼Ÿ\nWhy do we stop growing? 14.æˆ‘ä»¬ä¸ºä»€ä¹ˆä¼šåœæ­¢ç”Ÿé•¿ï¼Ÿ\nIs de-extinction possible? 15.èƒ½å¦å¤æ´»ç­ç»ç”Ÿç‰©ï¼Ÿ\nCan humans hibernate? 16.äººç±»å¯ä»¥å†¬çœ å—ï¼Ÿ\nWhere do human emotions originate? 17.äººç±»çš„æƒ…æ„Ÿæºäºä½•å¤„ï¼Ÿ\nWill humans look physically different in the future? 18.æœªæ¥äººç±»çš„å¤–è²Œä¼šæœ‰æ‰€ä¸åŒå—ï¼Ÿ\nWhy were there species explosions and mass extinction? 19.ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿç‰©ç§å¤§çˆ†å‘å’Œå¤§ç­ç»ï¼Ÿ\nHow might genome editing be used to cure disease? 20.åŸºå› ç»„ç¼–è¾‘å°†å¦‚ä½•ç”¨äºæ²»ç–—ç–¾ç—…ï¼Ÿ\nCan a cell be artificially synthesized? 21.å¯ä»¥äººå·¥åˆæˆç»†èƒå—ï¼Ÿ\nHow are biomolecules organized in cells to function orderly and effectively? 22.ç»†èƒå†…çš„ç”Ÿç‰©åˆ†å­æ˜¯å¦‚ä½•ç»„ç»‡ä»è€Œæœ‰åºæœ‰æ•ˆå‘æŒ¥ä½œç”¨çš„ï¼Ÿ\nInformation Science(4) # ä¿¡æ¯ç§‘å­¦\nIs there an upper limit to computer processing speed? 1.è®¡ç®—æœºå¤„ç†é€Ÿåº¦æ˜¯å¦æœ‰ä¸Šé™ï¼Ÿ\nCan AI replace a doctor? 2.AIå¯ä»¥ä»£æ›¿åŒ»ç”Ÿå—ï¼Ÿ\nCan topological quantum computing be realized? 3.æ‹“æ‰‘é‡å­è®¡ç®—å¯ä»¥å®ç°å—ï¼Ÿ\nCan DNA act as an information storage medium? 4.DNAå¯ä»¥ç”¨ä½œä¿¡æ¯å­˜å‚¨ä»‹è´¨å—ï¼Ÿ\nNeuroscience(12) # ç¥ç»ç§‘å­¦\nWhat are the coding principles embedded in neuronal spike trains? 1.ç¥ç»å…ƒæ”¾ç”µåºåˆ—çš„ç¼–ç å‡†åˆ™æ˜¯ä»€ä¹ˆï¼Ÿ\nWhere does consciousness lie? 2.æ„è¯†å­˜åœ¨äºä½•å¤„ï¼Ÿ\nCan human memory be stored, manipulated, and transplanted digitally? 3.èƒ½å¦æ•°å­—åŒ–åœ°å­˜å‚¨ã€æ“æ§å’Œç§»æ¤äººç±»è®°å¿†ï¼Ÿ\nWhy do we need sleep? 4.ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ç¡çœ ï¼Ÿ\nWhat is addiction and how does it work? 5.ä»€ä¹ˆæ˜¯æˆç˜¾ï¼Ÿ\nWhy do we fall in love? 6.ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¼šå å…¥çˆ±æ²³ï¼Ÿ\nHow did speech evolve and what parts of the brain control it? 7.è¨€è¯­å¦‚ä½•æ¼”å˜å½¢æˆï¼Œå¤§è„‘çš„å“ªäº›éƒ¨åˆ†å¯¹å…¶è¿›è¡Œæ§åˆ¶ï¼Ÿ\nHow smart are nonhuman animals? 8.é™¤äººç±»ä»¥å¤–çš„å…¶ä»–åŠ¨ç‰©æœ‰å¤šèªæ˜ï¼Ÿ\nWhy are most people right-handed? 9.ä¸ºä»€ä¹ˆå¤§å¤šæ•°äººéƒ½æ˜¯å³æ’‡å­ï¼Ÿ\nCan we cure neurodegenerative diseases? 10.æˆ‘ä»¬å¯ä»¥æ²»æ„ˆç¥ç»é€€è¡Œæ€§ç–¾ç—…å—ï¼Ÿ\nIs it possible to predict the future? 11.æœ‰å¯èƒ½é¢„çŸ¥æœªæ¥å—ï¼Ÿ\nCan we more effectively diagnose and treat complex mental disorders? 12.ç²¾ç¥éšœç¢èƒ½å¦æœ‰æ•ˆè¯Šæ–­å’Œæ²»ç–—ï¼Ÿ\nArtificial Intelligence(8) # äººå·¥æ™ºèƒ½\nWill injectable, disease-fighting nanobots ever be a reality? 1.å¯æ³¨å°„çš„æŠ—ç—…çº³ç±³æœºå™¨äººä¼šæˆä¸ºç°å®å—ï¼Ÿ\nWill it be possible to create sentient robots? 2.æ˜¯å¦æœ‰å¯èƒ½åˆ›å»ºæœ‰æ„ŸçŸ¥åŠ›çš„æœºå™¨äººï¼Ÿ\nIs there a limit to human intelligence? 3.äººç±»æ™ºåŠ›æ˜¯å¦æœ‰æé™ï¼Ÿ\nWill artificial intelligence replace humans? 4.äººå·¥æ™ºèƒ½ä¼šå–ä»£äººç±»å—ï¼Ÿ\nHow does group intelligence emerge? 5.ç¾¤ä½“æ™ºèƒ½æ˜¯å¦‚ä½•å‡ºç°çš„ï¼Ÿ\nCan robots or AIs have human creativity? 6.æœºå™¨äººæˆ– AI å¯ä»¥å…·æœ‰äººç±»åˆ›é€ åŠ›å—ï¼Ÿ\nCan quantum artificial intelligence imitate the human brain? 7.é‡å­äººå·¥æ™ºèƒ½å¯ä»¥æ¨¡ä»¿äººè„‘å—ï¼Ÿ\nCould we integrate with computers to form a human-machine hybrid species? 8.æˆ‘ä»¬å¯ä»¥å’Œè®¡ç®—æœºç»“åˆä»¥å½¢æˆäººæœºæ··åˆç‰©ç§å—ï¼Ÿ\nMathematical Sciences(3) # æ•°å­¦\nWhat makes prime numbers so special? 1.ä»€ä¹ˆä½¿ç´ æ•°å¦‚æ­¤ç‰¹åˆ«ï¼Ÿ\nWill the Navierâ€“Stokes problem ever be solved? 2.çº³ç»´å°”-æ–¯æ‰˜å…‹æ–¯é—®é¢˜ä¼šå¾—åˆ°è§£å†³å—ï¼Ÿ\nIs the Riemann hypothesis true? 3.é»æ›¼çŒœæƒ³æ˜¯çœŸçš„å—ï¼Ÿ\nChemistry(9) # åŒ–å­¦\nAre there more color pigments to discover? 1.è¿˜æœ‰æ›´å¤šè‰²å½©å…ƒç´ å¯å‘ç°å—ï¼Ÿ\nWill the periodic table ever be complete? 2.å…ƒç´ å‘¨æœŸè¡¨ä¼šå®Œæ•´å—ï¼Ÿ\nHow can we measure interface phenomena on the microscopic level? 3.å¦‚ä½•åœ¨å¾®è§‚å±‚é¢æµ‹é‡ç•Œé¢ç°è±¡ï¼Ÿ\nWhat is the future for energy storageï¼Ÿ 4.èƒ½é‡å­˜å‚¨çš„æœªæ¥æ˜¯æ€æ ·çš„ï¼Ÿ\nWhy does life require chirality? 5.ä¸ºä»€ä¹ˆç”Ÿå‘½éœ€è¦æ‰‹æ€§ï¼Ÿ\nHow can we better manage the world\u0026rsquo;s plastic waste? 6.æˆ‘ä»¬å¦‚ä½•æ›´å¥½åœ°ç®¡ç†ä¸–ç•Œä¸Šçš„å¡‘æ–™åºŸç‰©ï¼Ÿ\nWill AI redefine the future of chemistry? 7.AIä¼šé‡æ–°å®šä¹‰åŒ–å­¦çš„æœªæ¥å—ï¼Ÿ\nHow can matter be programmed into living materials? 8.ç‰©è´¨å¦‚ä½•è¢«ç¼–ç è€Œæˆä¸ºç”Ÿå‘½ææ–™ï¼Ÿ\nWhat drives reproduction in living systems? 9.æ˜¯ä»€ä¹ˆé©±åŠ¨ç”Ÿå‘½ç³»ç»Ÿçš„å¤åˆ¶ï¼Ÿ\nAstronomy(23) # å¤©æ–‡å­¦\nHow many dimensions are there in space? 1.ç©ºé—´ä¸­æœ‰å¤šå°‘ä¸ªç»´åº¦ï¼Ÿ\nWhat is the shape of the universe? 2.å®‡å®™çš„å½¢çŠ¶æ˜¯æ€æ ·çš„ï¼Ÿ\nWhere did the big bang start? 3.å¤§çˆ†ç‚¸ä»ä½•å¤„å¼€å§‹ï¼Ÿ\nWhy don\u0026rsquo;t the orbits of planets decay and cause them to crash into each other? 4.ä¸ºä»€ä¹ˆè¡Œæ˜Ÿçš„è½¨é“ä¸è¡°å‡å¹¶å¯¼è‡´å®ƒä»¬ç›¸äº’ç¢°æ’ï¼Ÿ\nWhen will the universe die? Will it continue to expand? 5.å®‡å®™ä½•æ—¶æ¶ˆäº¡ï¼Ÿå®ƒä¼šç»§ç»­è†¨èƒ€å—ï¼Ÿ\nIs it possible to live permanently on another planet? 6.æˆ‘ä»¬æœ‰å¯èƒ½åœ¨å¦ä¸€ä¸ªæ˜Ÿçƒä¸Šé•¿æœŸå±…ä½å—ï¼Ÿ\nWhy do black holes exist? 7.ä¸ºä»€ä¹ˆå­˜åœ¨é»‘æ´ï¼Ÿ\nWhat is the universe made of? 8.å®‡å®™æ˜¯ç”±ä»€ä¹ˆæ„æˆçš„ï¼Ÿ\nAre we alone in the universe? 9.æˆ‘ä»¬æ˜¯å®‡å®™ä¸­å”¯ä¸€çš„ç”Ÿå‘½ä½“å—ï¼Ÿ\nWhat is the origin of cosmic rays? 10.å®‡å®™å°„çº¿çš„èµ·æºæ˜¯ä»€ä¹ˆï¼Ÿ\nWhat is the origin of mass? 11.ç‰©è´¨çš„èµ·æºæ˜¯ä»€ä¹ˆï¼Ÿ\nWhat is the smallest scale of space-time? 12.æ—¶ç©ºçš„æœ€å°å°ºåº¦æ˜¯æ˜¯å¤šå°‘ï¼Ÿ\nIs water necessary for all life in the universe, or just on Earth? 13.æ°´æ˜¯å®‡å®™ä¸­æ‰€æœ‰ç”Ÿå‘½æ‰€å¿…éœ€çš„ä¹ˆï¼Œè¿˜æ˜¯ä»…å¯¹åœ°çƒç”Ÿå‘½ï¼Ÿ\nWhat is preventing humans from carrying out deep-space exploration? 14.æ˜¯ä»€ä¹ˆé˜»æ­¢äº†äººç±»è¿›è¡Œæ·±ç©ºæ¢æµ‹ï¼Ÿ\nIs Einstein\u0026rsquo;s general theory of relativity correct? 15.çˆ±å› æ–¯å¦çš„å¹¿ä¹‰ç›¸å¯¹è®ºæ˜¯æ­£ç¡®çš„å—ï¼Ÿ\nHow are pulsars formed? 16.è„‰å†²æ˜Ÿæ˜¯å¦‚ä½•å½¢æˆçš„ï¼Ÿ\nIs our Milky Way Galaxy special? 17.æˆ‘ä»¬çš„é“¶æ²³ç³»ç‰¹åˆ«å—ï¼Ÿ\nWhat is the volume, composition, and significance of the deep biosphere? 18.æ·±å±‚ç”Ÿç‰©åœˆçš„è§„æ¨¡ã€ç»„æˆå’Œæ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ\nWill humans one day have to leave the planet (or die trying)? 19.äººç±»æœ‰ä¸€å¤©ä¼šä¸å¾—ä¸ç¦»å¼€åœ°çƒå—ï¼ˆè¿˜æ˜¯ä¼šåœ¨å°è¯•ä¸­æ­»å»ï¼‰ï¼Ÿ\nWhere do the heavy elements in the universe come from? 20.å®‡å®™ä¸­çš„é‡å…ƒç´ æ¥è‡ªä½•å¤„ï¼Ÿ\nIs it possible to understand the structure of compact stars and matter? 21.æœ‰å¯èƒ½äº†è§£è‡´å¯†æ’æ˜Ÿå’Œç‰©è´¨çš„ç»“æ„å—ï¼Ÿ\nWhat is the origin of the high-energy cosmic neutrinos? 22.é«˜èƒ½å®‡å®™ä¸­å¾®å­çš„èµ·æºæ˜¯ä»€ä¹ˆï¼Ÿ\nWhat is gravity? 23.ä»€ä¹ˆæ˜¯é‡åŠ›ï¼Ÿ\nPhysics(18) # ç‰©ç†å­¦\nIs there a diffraction limit? 1.æœ‰è¡å°„æé™å—ï¼Ÿ\nWhat is the microscopic mechanism for high-temperature superconductivity? 2.é«˜æ¸©è¶…å¯¼çš„å¾®è§‚æœºç†æ˜¯ä»€ä¹ˆï¼Ÿ\nWhat are the limits of heat transfer in matter? 3.ç‰©è´¨ä¼ çƒ­çš„æé™æ˜¯ä»€ä¹ˆï¼Ÿ\nWhat are the fundamental principles of collective motion? 4.é›†ä½“è¿åŠ¨çš„åŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ\nWhat are the smallest building blocks of matter? 5.ä»€ä¹ˆæ˜¯ç‰©è´¨çš„æœ€å°ç»„æˆéƒ¨åˆ†ï¼Ÿ\nWill we ever travel at the speed of light? 6.æˆ‘ä»¬ä¼šä»¥å…‰é€Ÿè¡Œé©¶å—ï¼Ÿ\nWhat is quantum uncertainty and why is it important? 7.ä»€ä¹ˆæ˜¯é‡å­ä¸ç¡®å®šæ€§ï¼Œä¸ºä»€ä¹ˆå®ƒå¾ˆé‡è¦ï¼Ÿ\nWill there ever be a \u0026ldquo;theory of everything\u0026rdquo;? 8.ä¼šæœ‰â€œä¸‡æœ‰ç†è®ºâ€å—ï¼Ÿ\nWhy does time seem to flow in only one direction? 9.ä¸ºä»€ä¹ˆæ—¶é—´ä¼¼ä¹åªæœä¸€ä¸ªæ–¹å‘æµåŠ¨ï¼Ÿ\nWhat is dark matter? 10.ä»€ä¹ˆæ˜¯æš—ç‰©è´¨ï¼Ÿ\nCan we make a real, human-size invisibility cloak? 11.æˆ‘ä»¬å¯ä»¥åˆ¶ä½œå‡ºçœŸäººå¤§å°çš„éšå½¢æ–—ç¯·å—ï¼Ÿ\nAre there any particles that behave oppositely to the properties or states of photons? 12.æ˜¯å¦å­˜åœ¨ä¸å…‰å­æ€§è´¨æˆ–çŠ¶æ€ç›¸åçš„ç²’å­ï¼Ÿ\nWill the Bose-Einstein condensate be widely used in the future? 13.ç»è‰²-çˆ±å› æ–¯å¦å†·å‡ä½“æœªæ¥ä¼šè¢«å¹¿æ³›ä½¿ç”¨å—ï¼Ÿ\nCan humans make intense lasers with incoherence comparable to sunlight? 14.äººç±»èƒ½åˆ¶é€ å‡ºä¸å¤ªé˜³å…‰ç›¸ä¼¼çš„éç›¸å¹²å¼ºæ¿€å…‰å—ï¼Ÿ\nWhat is the maximum speed to which we can accelerate a particle? 15.æˆ‘ä»¬æœ€å¤šå¯ä»¥å°†ç²’å­åŠ é€Ÿåˆ°å¤šå¿«ï¼Ÿ\nIs quantum many-body entanglement more fundamental than quantum fields? 16.é‡å­å¤šä½“çº ç¼ æ¯”é‡å­åœºæ›´åŸºæœ¬å—ï¼Ÿ\nWhat is the optimum hardware for quantum computers? 17.é‡å­è®¡ç®—æœºçš„æœ€ä½³ç¡¬ä»¶æ˜¯ä»€ä¹ˆï¼Ÿ\nCan we accurately simulate the macro- and microworld? 18.æˆ‘ä»¬å¯ä»¥ç²¾ç¡®æ¨¡æ‹Ÿå®è§‚å’Œå¾®è§‚ä¸–ç•Œå—ï¼Ÿ\nEngineering \u0026amp; Material Science(4) # å·¥ç¨‹ä¸ææ–™ç§‘å­¦\nWhat is the ultimate statistical invariances of turbulence? 1.æ¹æµçš„æœ€ç»ˆç»Ÿè®¡ä¸å˜æ€§æ˜¯ä»€ä¹ˆï¼Ÿ\nHow can we break the current limit of energy conversion efficiencies? 2.æˆ‘ä»¬å¦‚ä½•çªç ´å½“å‰çš„èƒ½é‡è½¬æ¢æ•ˆç‡æé™ï¼Ÿ\nHow can we develop manufacturing systems on Mars? 3.æˆ‘ä»¬å¦‚ä½•åœ¨ç«æ˜Ÿä¸Šå¼€å‘åˆ¶é€ ç³»ç»Ÿï¼Ÿ\nIs a future of only self-driving cars realistic? 4.çº¯æ— äººé©¾é©¶æ±½è½¦çš„æœªæ¥æ˜¯å¦ç°å®ï¼Ÿ\nEcology(8) # ç”Ÿæ€å­¦\nCan we stop global climate change? 1.æˆ‘ä»¬å¯ä»¥é˜»æ­¢å…¨çƒæ°”å€™å˜åŒ–å—ï¼Ÿ\nWhere do we put all the excess carbon dioxide? 2.æˆ‘ä»¬èƒ½æŠŠè¿‡é‡çš„äºŒæ°§åŒ–ç¢³å­˜åˆ°ä½•å¤„ï¼Ÿ\nWhat creates the Earth\u0026rsquo;s magnetic field (and why does it move)? 3.æ˜¯ä»€ä¹ˆåˆ›é€ äº†åœ°çƒçš„ç£åœºï¼ˆä¸ºä»€ä¹ˆå®ƒä¼šç§»åŠ¨ï¼‰ï¼Ÿ\nWill we be able to predict catastrophic weather events (tsunami, hurricanes, earthquakes) more accurately? 4.æˆ‘ä»¬æ˜¯å¦èƒ½å¤Ÿæ›´å‡†ç¡®åœ°é¢„æµ‹ç¾å®³æ€§äº‹ä»¶ï¼ˆæµ·å•¸ã€é£“é£ã€åœ°éœ‡ï¼‰ï¼Ÿ\nWhat happens if all the ice on the planet melts? 5.å¦‚æœåœ°çƒä¸Šæ‰€æœ‰çš„å†°èåŒ–ä¼šæ€æ ·ï¼Ÿ\nCan we create an environmentally friendly replacement for plastics? 6.æˆ‘ä»¬å¯ä»¥åˆ›é€ ä¸€ç§ç¯ä¿çš„å¡‘æ–™æ›¿ä»£å“å—ï¼Ÿ\nCan we achieve a situation where essentially every material can be recycled and reused? 7.å‡ ä¹æ‰€æœ‰ææ–™éƒ½å¯ä»¥å›æ”¶å†åˆ©ç”¨æ˜¯å¦å¯ä»¥å®ç°ï¼Ÿ\nWill we soon see the end of monocultures like wheat, maize, rice, and soy? 8.æˆ‘ä»¬ä¼šå¾ˆå¿«çœ‹åˆ°å°éº¦ã€ç‰ç±³ã€å¤§ç±³å’Œå¤§è±†ç­‰å•ä¸€ä½œç‰©çš„ç»ˆç»“å—ï¼Ÿ\nEnergy Science(3) # èƒ½æºç§‘å­¦\nCould we live in a fossil-fuel-free world? 1.æˆ‘ä»¬å¯ä»¥ç”Ÿæ´»åœ¨ä¸€ä¸ªå»åŒ–çŸ³ç‡ƒæ–™çš„ä¸–ç•Œä¸­å—ï¼Ÿ\nWhat is the future of hydrogen energy? 2.æ°¢èƒ½çš„æœªæ¥æ˜¯æ€æ ·çš„ï¼Ÿ\nWill cold fusion ever be possible? 3.å†·èšå˜æœ‰å¯èƒ½å®ç°å—ï¼Ÿ\næ€è€ƒ # ç§‘å­¦é—®é¢˜æœ‰å¤§æœ‰å°ï¼Œä¸Šé¢æ˜¯å…¨äººç±»ç›®å‰è¿™ä¸ªé˜¶æ®µå…³æ³¨çš„å¤§ç§‘å­¦é—®é¢˜ï¼Œé‚£ä¹ˆå°è€Œç²¾çš„ç§‘å­¦é—®é¢˜è¯¥å¦‚ä½•å‡ç»ƒï¼Ÿ\nã€å¤æ—¦èµµæ–Œã€‘é¿å…å°´å°¬ï¼Œæ•™ä½ ä¸€å¥è¯è¯´æ¸…æ¥šä»€ä¹ˆæ˜¯ç§‘å­¦é—®é¢˜ã€æŠ€æœ¯é—®é¢˜å’Œå·¥ç¨‹é—®é¢˜_å“”å“©å“”å“©_bilibili\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nã€å¤æ—¦èµµæ–Œã€‘è€å¸ˆå–Šä½ æäº‹æƒ… | 125ä¸ªç§‘å­¦é—®é¢˜ï¼Œä½ æœ€æƒ³äº†è§£å“ªä¸ªï¼Ÿ_å“”å“©å“”å“©_bilibilic\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nå…¨ä¸–ç•Œæœ€å‰æ²¿çš„125ä¸ªç§‘å­¦é—®é¢˜ï¼\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"6 March 2023","permalink":"/posts/20230306-%E4%BB%80%E4%B9%88%E6%98%AF%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98/","section":"Posts","summary":"ç§‘å­¦é—®é¢˜æ˜¯è¿˜ä¸çŸ¥é“ç­”æ¡ˆçš„é—®é¢˜","title":"ä»€ä¹ˆæ˜¯ç§‘å­¦é—®é¢˜ï¼Ÿ"},{"content":"","date":"4 March 2023","permalink":"/categories/deep-learning/","section":"Categories","summary":"","title":"Deep Learning"},{"content":"","date":"4 March 2023","permalink":"/tags/mimic-iii/","section":"Tags","summary":"","title":"mimic-iii"},{"content":"MULTIBENCHï¼Œä¸€ä¸ªç³»ç»Ÿè€Œç»Ÿä¸€çš„å¤§è§„æ¨¡å¤šæ¨¡æ€å­¦ä¹ åŸºå‡†ï¼Œæ¶µç›–15ä¸ªæ•°æ®é›†ã€10ç§æ¨¡å¼ã€20ä¸ªé¢„æµ‹ä»»åŠ¡å’Œ6ä¸ªç ”ç©¶é¢†åŸŸ1ã€‚\nå¼•è¨€ # èƒŒæ™¯ï¼š\nè¯­è¨€å’Œè§†è§‰é¢†åŸŸå¤šæ¨¡æ€å­¦ä¹ å‘å±•ä¸é”™ï¼Œä½†æ˜¯å…¶ä»–é¢†åŸŸæ¬ ç¼º ç°åœ¨çš„åŸºå‡†è¯„ä»·å…³æ³¨æ€§èƒ½ï¼Œæ²¡æœ‰é‡åŒ–ç¼ºç‚¹åŒ…æ‹¬æ—¶é—´ç©ºé—´å¤æ‚åº¦ï¼Œç”±äºä¸å®Œç¾æ¨¡æ€å¯¼è‡´çš„é²æ£’æ€§é™ä½ï¼Œéœ€è¦åœ¨æ€§èƒ½ã€é²æ£’æ€§ã€å¤æ‚åº¦å–å¾—å¹³è¡¡ æå‡ºmultibenchå°±æ˜¯è§£å†³ä»¥ä¸Šé—®é¢˜ï¼š\næ‰©å……æ”¶é›†å„é¢†åŸŸæ•°æ®é›†ã€æ•°æ®æ¨¡æ€ é‡åŒ–å¤æ‚åº¦ æå‡ºæ ‡å‡†æµç¨‹è¯„ä»·å¯¹å™ªå£°å’Œç¼ºå¤±æ¨¡æ€æƒ…å†µä¸‹çš„é²æ£’æ€§ MultiBenchæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„è¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ•°æ®é›†æ‹†åˆ†ã€å¤šæ¨¡æ€ç®—æ³•ã€è¯„ä¼°æŒ‡æ ‡å’Œäº¤å‰éªŒè¯ã€‚\nå¼€å‘å·¥å…·åŒ…MultiZoo å¯ä»¥ç”¨äºworkshopã€æ•™å­¦ç­‰ å¤šå°ºåº¦å¤šæ¨¡æ€åŸºå‡† # ç¬¬ä¸€ç‰ˆé›†ä¸­åœ¨å¤šæ¨¡æ€èåˆï¼Œå¯¹äºå¤šæ¨¡æ€ç¿»è¯‘ç­‰é—®é¢˜æœªæ¥ç‰ˆæœ¬å¯èƒ½æ¶‰åŠ\næ•°æ®é›† # ä»‹ç»äº†6å¤§é¢†åŸŸ15ä¸ªæ•°æ®é›†ï¼Œè¡¨1\næƒ…æ„Ÿè®¡ç®—ï¼ˆaffective computingï¼‰ åŒ»ç–—ï¼šæ—¶å˜å’Œé™æ€å˜é‡çš„æ•´åˆä½¿ç”¨ æœºå™¨äºº é‡‘è äººæœºäº¤äº’ å¤šåª’ä½“ è¯„ä»·æ ‡å‡† # æ€§èƒ½ï¼š\nregression: MSE, MAE, classification: F1-score, AUPRC å¤æ‚åº¦ï¼š\ndata size in bits number of model parameters time and memory resources on CPU and GPU é²æ£’æ€§ï¼š\nå•æ¨¡æ€ç‹¬æœ‰å™ªéŸ³ï¼šå¯¹å›¾åƒã€éŸ³é¢‘ç­‰å•ç‹¬å¤„ç† è€ƒè™‘å¤šæ¨¡æ€æ•´ä½“çš„ä¸å®Œå–„ï¼šæ¯”å¦‚ç¼ºå¤±æ¨¡æ€ç­‰ MultiZooï¼šå¤šæ¨¡æ€ç®—æ³•é›†åˆ # æ¶µç›–å®ç°multibenchæ•´ä¸ªè¿‡ç¨‹ä¸­çš„ç®—æ³•\næ•°æ®é¢„å¤„ç† # WordAlignç®—æ³• å°†å„æ¨¡æ€ä¿¡æ¯è°ƒæ•´åˆ°ç»Ÿä¸€ç²’åº¦ èåˆèŒƒå¼ # æ—©æœŸå’Œæ™šæœŸèåˆ EFï¼ŒLF å¤šæ¨¡æ€å¼ é‡: å¤šæ¨¡æ€äº’è¡¥ Tensor Fusion Low-rank Tensor Fusion å¤šæ¨¡æ€ä¹˜æ³•äº¤äº’: å¤šæ¨¡æ€äº¤äº’ MI-MATRIX MI-VECTOR MI-SCALAR å¤šæ¨¡æ€é—¨æ§ NL GATE: è‡ªæ³¨æ„åŠ›æœºåˆ¶ æ—¶åºæ³¨æ„åŠ›æ¨¡å‹ MULT: å¤šæ¨¡æ€Transformer ç½‘ç»œæ¶æ„æœç´¢ MFAS ä¼˜åŒ–ç›®æ ‡ # é™¤äº†æ ‡å‡†çš„ç›‘ç£æŸå¤±å‡½æ•°ï¼Œçº³å…¥ä¸€äº›æ–°æå‡ºçš„ç›®æ ‡å‡½æ•°\nCCA REFNET MFM MCTN è®­ç»ƒè¿‡ç¨‹ # Gradient Blendingæ¥è®¡ç®—èåˆçš„æƒé‡ Regularization by Maximizing Functional Entropies å®éªŒ # æ³›åŒ–æ€§èƒ½ ç›®å‰çš„æ–¹æ³•è¡¨ç°å‡ºé«˜æ–¹å·®ï¼Œæ²¡æœ‰æ”¾ä¹‹å››æµ·è€Œçš†å‡†çš„æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæœªè¢«ç ”ç©¶çš„æ¨¡å¼å’Œä»»åŠ¡ã€‚ åæœŸèåˆè¡¨ç°æ¯”è¾ƒå‡è¡¡ æœ‰äº›èåˆæ–¹æ³•æ˜¯ä¸“é—¨ä¸º2æ¨¡æ€è®¾è®¡ï¼Œæœ‰äº›åœ¨2/3æ¨¡æ€è¡¨ç°ä¸å¥½ å•æ¨¡æ€ä¸å¤šæ¨¡æ€çš„æƒè¡¡ æ€§èƒ½ä¸å¤æ‚åº¦çš„æƒè¡¡ æ€§èƒ½ä¸é²æ£’æ€§çš„æƒè¡¡ ç»“è®º # ä¸€ä¸ªå¤§è§„æ¨¡çš„åŸºå‡†ï¼Œç»Ÿä¸€äº†ä»¥å‰åœ¨å¤šæ¨¡æ€ç ”ç©¶ä¸­äº’ä¸ç›¸å¹²çš„å·¥ä½œï¼Œé‡ç‚¹æ˜¯æ˜“ç”¨æ€§ã€å¯åŠæ€§å’Œå¯é‡å¤æ€§ã€‚\næœªæ¥æ‹“å±• # å…¶ä»–çš„å¤šæ¨¡æ€é—®é¢˜ æ–°çš„è¯„ä»·æŒ‡æ ‡ å¤šæ¨¡æ€è¿ç§»å­¦ä¹ æˆ–è€…ååŒå­¦ä¹  å¤šæ¨¡æ€å¤šä»»åŠ¡å­¦ä¹  æ€è€ƒ # MultiBenchæŠŠä»¥å‰å¤šæ¨¡æ€ç ”ç©¶ä¸­ä½¿ç”¨çš„å…¬å¼€æ•°æ®é›†ï¼Œç®—æ³•ï¼Œè¯„ä»·æŒ‡æ ‡ç­‰éƒ½ç»Ÿä¸€åœ¨äº†ä¸€ä¸ªæ¡†æ¶ä¸‹ï¼ŒæœŸæœ›æ ‡å‡†åŒ–å¤šæ¨¡æ€å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶ä¸”èƒ½å°†ä¸åŒçš„ç®—æ³•æ¨¡å‹åœ¨å…¶ä»–æ¨¡æ€ã€ä»»åŠ¡ä¸­è¿›è¡Œæ¯”è¾ƒã€‚å¤§è€Œå…¨çš„æ¡†æ¶ç¡®å®èƒ½ä¸ºå„ç±»å¤šæ¨¡æ€ä»»åŠ¡æä¾›ä¸€ä¸ªbaselineï¼Œä½†æ˜¯å„ä¸“ä¸šé¢†åŸŸå†…çš„å¤šæ¨¡æ€æ¨¡å‹åº”è¯¥æ˜¯å­˜åœ¨ä¸€äº›å·®å¼‚çš„ï¼Œå°±åƒæˆ‘ä»¬å¾ˆéš¾æœŸå¾…ä¸€ä¸ªåŒ»ç”Ÿèƒ½æŒæ¡å¾‹å¸ˆå¹²çš„äº‹æƒ…ï¼Œç„¶è€Œï¼Œäººå·¥æ™ºèƒ½çš„å‘å±•ç¡®å®å¾ˆå¿«ï¼Œæ¯”äººè¿˜å¼ºå¤§çš„é€šç”¨äººå·¥æ™ºèƒ½åº”è¯¥ä¹Ÿä¼šå®ç°ã€‚\nLiang, P. P. et al. MultiBench: Multiscale Benchmarks for Multimodal Representation Learning. (2021) doi:10.48550/arXiv.2107.07502.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"4 March 2023","permalink":"/posts/20230304-multibench/","section":"Posts","summary":"Multiscale Benchmarks for Multimodal Representation Learningè®ºæ–‡è§£è¯»","title":"MultiBenchå¤šæ¨¡æ€è¡¨å¾å­¦ä¹ çš„å¤šå°ºåº¦åŸºå‡†"},{"content":"","date":"4 March 2023","permalink":"/tags/multimodal/","section":"Tags","summary":"","title":"multimodal"},{"content":"","date":"1 March 2023","permalink":"/tags/bert/","section":"Tags","summary":"","title":"bert"},{"content":" ä½¿ç”¨ä¸´åºŠæ–‡æœ¬é¢„è®­ç»ƒBERTç„¶ååœ¨å†å…¥é™¢ä»»åŠ¡ä¸­å¾®è°ƒ\nå¼•è¨€ # éç»“æ„åŒ–ã€é«˜ç»´ç¨€ç–ä¿¡æ¯ä¾‹å¦‚ä¸´åºŠæ–‡æœ¬éš¾ä»¥åœ¨ä¸´åºŠæœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ä½¿ç”¨ã€‚ä¸´åºŠæ–‡æœ¬ä¸­åŒ…å«ä»€ä¹ˆæ ·çš„ä¸´åºŠä»·å€¼ï¼Ÿæ›´åŠ ä¸°å¯Œã€è¯¦ç»†ã€‚ç„¶è€Œé‡ç—‡ç›‘æŠ¤å®¤åŒ»ç”Ÿåœ¨æœ‰é™æ—¶é—´å†…éœ€è¦åšå‡ºæœ€ä¼˜å†³ç­–ï¼Œè¯»å¤§é‡çš„ä¸´åºŠæ–‡æœ¬ï¼Œå¢åŠ å·¥ä½œé‡ã€‚\nå†å…¥é™¢ä¼šé™ä½æ‚£è€…ç”Ÿæ´»è´¨é‡ã€å¢åŠ èŠ±è´¹ã€‚è¿™ç¯‡æ–‡ç« æ—¨åœ¨å»ºç«‹ä¸€ä¸ªå‡ºé™¢å†³ç­–æ¨¡å‹ï¼Œæ ¹æ®åŒ»æŠ¤äººå‘˜ç¬”è®°åŠ¨æ€çš„èµ‹äºˆæ‚£è€…30å¤©å†å…¥é™¢çš„é£é™©ã€‚\nèƒŒæ™¯ # ä¸´åºŠæ–‡æœ¬ä¼šæœ‰ç¼©å†™ã€é»‘è¯ã€ä¸æ ‡å‡†çš„è¯­æ³•ç»“æ„ï¼Œä»ä¸´åºŠæ–‡æœ¬ä¸­å­¦ä¹ æœ‰ç”¨çš„è¡¨å¾å…·æœ‰æŒ‘æˆ˜ã€‚ä»¥å¾€çš„æ–¹æ³•æ— æ³•æ•æ‰è·å–ä¸´åºŠæ„ä¹‰çš„æ–‡æœ¬é•¿ç¨‹ä¾èµ–ï¼Œä»‹ç»BERTï¼Œä»¥åŠåŸºäºBERTå·²ç»å¼€å±•çš„å·¥ä½œï¼Œå·²ç»æœ‰äººæŠŠBERTç”¨åœ¨ä¸´åºŠæ–‡æœ¬äº†ï¼Œæœ¬æ–‡åœ¨å†å…¥é™¢ä»»åŠ¡ä¸Šè¯„ä¼°æ”¹è¿›ClinicalBERTå¹¶ä¸”åœ¨æ›´é•¿çš„åºåˆ—ä¸Šè¿›è¡Œé¢„è®­ç»ƒã€‚\nä»‹ç»å‰äººåœ¨ICUå†å…¥é™¢é¢„æµ‹ä¸Šçš„å·¥ä½œï¼Œç¼ºç‚¹ï¼šå¤§å¤šæ•°å·¥ä½œéƒ½åªç”¨äº†å‡ºé™¢çš„ä¿¡æ¯ï¼ŒClinicalBERTä½¿ç”¨æ‚£è€…ä½é™¢æ•´ä¸ªæ—¶é—´æ®µä¿¡æ¯ã€‚\nè¯¥å·¥ä½œçš„é‡è¦æ€§ # ç”¨å‡ºé™¢ä¿¡æ¯æ¥é¢„æµ‹æ„å‘³ç€å‡å°‘äº†å†å…¥é™¢é£é™©çš„æœºä¼šå°‘äº†ï¼Œéƒ½è¦å‡ºé™¢äº†ï¼Œæ­¤åˆ»å‘Šè¯‰æœ‰å†å…¥é™¢çš„é£é™©ï¼Œéš¾ä»¥é‡‡å–æªæ–½ï¼› ç”±äºåŒ»é™¢å·²ç»æœ‰å¾ˆå¤šè¯¯æŠ¥è­¦ï¼ŒåŒ»ç–—æ¨¡å‹éœ€è¦é«˜çš„PPV1ï¼Œè¯¥æ¨¡å‹åŒå…¶ä»–æ¨¡å‹ç›¸æ¯”æœ‰æœ€é«˜çš„recall2ï¼› æ¨¡å‹ä¸­attentionèƒ½ç”¨äºå¯è§†åŒ–è§£é‡Šã€‚ æ–¹æ³• # ä»€ä¹ˆæ˜¯BERT # BERTæ˜¯åŸºäºtransformerç¼–ç å™¨æ¶æ„çš„æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå®ƒç”¨äºå­¦ä¹ æ–‡æœ¬çš„åµŒå…¥è¡¨è¾¾ã€‚\nè‡ªæ³¨æ„åŠ›æœºåˆ¶ BERTæ¨¡å‹é€šè¿‡2ä¸ªæ— ç›‘ç£ä»»åŠ¡è¿›è¡Œé¢„è®­ç»ƒï¼šæ©ç æ¨¡å‹å’Œä¸‹ä¸€ä¸ªå¥å­é¢„æµ‹ã€‚ ä¸´åºŠæ–‡æœ¬åµŒå…¥ # å…ˆåˆ†è¯æˆtoken3ï¼Œè¿™é‡Œæ˜¯å­è¯ç²’åº¦çš„tokenization4 ClinicalBertçš„tokenåŒ…æ‹¬å­è¯ã€åˆ†æ®µåµŒå…¥ã€ä½ç½®åµŒå…¥ç›¸åŠ åçš„ç»“æœ åˆ†æ®µåµŒå…¥æ˜¯å½“å¤šä¸ªåºåˆ—è¾“å…¥æ—¶ï¼Œè¡¨ç¤ºå½“å‰çš„tokenå±äºå“ªä¸€æ®µ ä½ç½®åµŒå…¥å³åœ¨è¾“å…¥åºåˆ—ä¸­tokençš„ä½ç½® è‡ªæ³¨æ„åŠ›æœºåˆ¶ # ç”¨äºè¾“å…¥tokenä¹‹é—´çš„å…³ç³»æ•æ‰\né¢„è®­ç»ƒ # BERTæ˜¯åœ¨BooksCorpuså’ŒWikipediaä¸­é¢„è®­ç»ƒçš„ï¼Œä¸´åºŠæ–‡æœ¬é»‘è¯ç¼©å†™ï¼Œä¸ä¸€èˆ¬æ–‡æœ¬å¯èƒ½è¯­æ³•ä¹Ÿä¸ä¸€æ ·ï¼Œéœ€è¦åœ¨ä¸´åºŠæ–‡æœ¬ä¸­è¿›è¡Œé¢„è®­ç»ƒã€‚æŸå¤±å‡½æ•°æ˜¯é¢„æµ‹æ©ç å•è¯ä»»åŠ¡å’Œé¢„æµ‹ä¸¤ä¸ªå¥å­æ˜¯å¦è¿ç»­ä»»åŠ¡æŸå¤±å‡½æ•°ä¹‹å’Œã€‚\nå¾®è°ƒ # åœ¨å†å…¥é™¢ä»»åŠ¡ä¸­å¾®è°ƒ $$P(readmit = 1 | h_{[cls]}) = \\sigma(Wh_{[cls]})$$ å¼ä¸­Wä¸ºå‚æ•°ï¼Œhä¸ºBERTæ¨¡å‹è¾“å‡ºã€‚\nå®éªŒ # æ•°æ® # MIMIC-IIIä¸­2083180ä»½å»éšç§åŒ–åçš„æ–‡æœ¬ï¼Œäº”æŠ˜æ¯ä¸€è½®å…¶ä¸­å››æŠ˜é¢„è®­ç»ƒï¼Œæœ€åä¸€æŠ˜å¾®è°ƒ\nå®è¯ç ”ç©¶I # åœ¨ä¸´åºŠè¯­è¨€å»ºæ¨¡ä¸­ClinicalBERTä¸BERTè¿›è¡Œæ¯”è¾ƒï¼šé¢„æµ‹æ©ç tokenä»¥åŠ2ä¸ªå¥å­æ˜¯å¦è¿ç»­ä»»åŠ¡ä¸­å‡ä¼˜äºBERT å®šæ€§åˆ†æï¼šä¸“å®¶ç»™å‡ºç›¸ä¼¼åŒ»å­¦æ¦‚å¿µï¼ŒClinicalBERTå­¦ä¹ åµŒå…¥è¡¨è¾¾åï¼Œè¿›è¡Œé™ç»´å¯è§†åŒ–ï¼Œå‘ç°ç›¸è¿‘ å®šé‡åˆ†æï¼šé‡‡ç”¨ç›¸ä¼¼åº¦åº¦é‡å…¬å¼è®¡ç®—è¡¨å¾ä¹‹å‰ç›¸ä¼¼åº¦ï¼Œç„¶åä¸ä¸“å®¶æ‰“åˆ†çš„ç›¸ä¼¼åº¦è¿›è¡Œå…³è”åˆ†æè®¡ç®—pearsonç›¸å…³ç³»æ•° å®è¯ç ”ç©¶II # å†å…¥é™¢é˜Ÿåˆ—ï¼š34560æ‚£è€…ï¼Œ2963å†å…¥é™¢ï¼Œ42358è´Ÿæ ·æœ¬ï¼Œè¿™é‡Œä¸ºå•¥æœ‰è¿™ä¹ˆå¤šè´Ÿæ ·æœ¬ï¼Ÿ è°ƒæ•´åçš„å†å…¥é™¢é¢„æµ‹ï¼š $$P(readmit = 1|h_{patient}) = \\frac{P^n_{max}+P^n_{mean}n/c}{1+n/c}$$ æœ‰äº›æ–‡æœ¬æ˜¯æ¯”è¾ƒé‡è¦ï¼Œæœ‰äº›æ–‡æœ¬å¯¹å†å…¥é™¢é¢„æµ‹ä¸é‡è¦ï¼Œæ‰€ä»¥è¦åŒ…æ‹¬æœ€å¤§çš„æ¦‚ç‡ å™ªå£°ä¼šé™ä½æ€§èƒ½ï¼Œæ¶ˆé™¤å™ªéŸ³çš„æ–¹æ³•è¿˜æ˜¯å–å¤§å¤šæ•°å€¼çš„å¹³å‡ï¼Œå¦‚æœåºåˆ—è¶Šé•¿ï¼Œå™ªå£°å‡ºç°çš„å¯èƒ½æ€§è¶Šå¤§ï¼Œæ‰€ä»¥éœ€è¦å¹³å‡å€¼çš„æƒé‡è¶Šå¤§ï¼Œå¼•å…¥äº†n/cä½œä¸ºæ¯”ä¾‹å› å­ åˆ†æ¯åˆ™æ˜¯ç”¨äºæ¦‚ç‡å½’ä¸€åŒ–åˆ°0,1åŒºé—´ è¯„ä¼°æŒ‡æ ‡ AUROC AUPRC RP80ï¼šå‡†ç¡®åº¦ä¸º80%æ—¶å€™åˆ°å¬å›ç‡ æ¨¡å‹æ¯”è¾ƒï¼šBag of wordsï¼ŒBI-LSTMï¼ŒBERT ç”¨å‡ºé™¢è®°å½•æ¥è¿›è¡Œå†å…¥é™¢é¢„æµ‹ ç”¨24-48å°æ—¶æ•°æ®é¢„æµ‹ï¼Œä»¥åŠ48-72å°æ—¶æ•°æ®é¢„æµ‹ å¯è§£é‡Šæ€§ ç»™å‡ºä¸€å¥è¯çš„self-attentionæƒé‡ç¤ºæ„å›¾ è®¨è®º # å»ºè®®åœ¨ç§æœ‰æ•°æ®é›†ä¸Šé‡æ–°è®­ç»ƒååœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­ä½¿ç”¨\nä»£ç  # GitHub - kexinhuang12345/clinicalBERT: ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission (CHIL 2020 Workshop)\næ€è€ƒ # è‡ªchatgptåï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å—åˆ°å¹¿æ³›å…³æ³¨ï¼ŒåŒ»å­¦è¯­è¨€æ¨¡å‹çš„å‘å±•ä¼¼ä¹æœ‰å¤šç§è·¯å¾„ï¼Œä¸€ç§æ˜¯ç›´æ¥åœ¨é€šç”¨æ–‡æœ¬ä¸Šé¢„è®­ç»ƒï¼Œä¸€ç§æ˜¯åœ¨åŒ»å­¦æ–‡æœ¬ä¸­é¢„è®­ç»ƒï¼Œæˆ–æ˜¯é€šç”¨æ¨¡å‹åœ¨é¢†åŸŸå¾®è°ƒï¼Œä¸ªäººæ„Ÿè§‰åº”è¯¥æ˜¯ç¬¬ä¸‰ç§æ•ˆæœä¼šè¾ƒå¥½ã€‚\nHuang, K., Altosaar, J. \u0026amp; Ranganath, R. ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission. in CHIL (arXiv, 2020). doi:10.48550/arXiv.1904.05342.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPPV: é˜³æ€§é¢„æµ‹é‡Œé¢çœŸæ­£çš„é˜³æ€§æ¯”ä¾‹\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nrecall: æ­£æ ·æœ¬ä¸­å®é™…é¢„æµ‹ä¸ºæ­£ï¼Œå³çœŸé˜³æ€§ç‡\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ntoken: å°†åŸå§‹æ–‡æœ¬åˆ‡åˆ†æˆå­å•å…ƒçš„è¿‡ç¨‹å°±å«åšTokenizationï¼Œå­å•å…ƒå³token\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"1 March 2023","permalink":"/posts/20230302-clinicalbert/","section":"Posts","summary":"ClinicalBERT Modeling Clinical Notes and Predicting Hospital Readmissionè®ºæ–‡è§£è¯»","title":"ClinicalBERT: å¯¹åŒ»å­¦æ–‡æœ¬å»ºæ¨¡ç”¨äºå†å…¥é™¢é¢„æµ‹"},{"content":"","date":"1 March 2023","permalink":"/tags/nlp/","section":"Tags","summary":"","title":"nlp"},{"content":" èƒŒæ™¯ # åœ¨nlpé¢†åŸŸï¼Œå¦‚ä½•æŠŠè¯è¿›è¡Œç¼–ç æˆæ•°å­—ï¼Œä»è€Œèƒ½è¾“å…¥åˆ°æ•°å­¦æ¨¡å‹æ˜¯éœ€è¦è€ƒè™‘çš„ï¼š\nç´¢å¼•ç¼–ç 1ï¼š\næ•´æ•°ç¼–ç ï¼Œç‰¹å¾ä¹‹é—´çš„å…³ç³»æ— æ³•æ•æ‰ one-hotç¼–ç çš„ç¼ºç‚¹ï¼š\nå¯¹äºå…·æœ‰éå¸¸å¤šç±»å‹çš„ç±»åˆ«å˜é‡ï¼Œå˜æ¢åçš„å‘é‡ç»´æ•°è¿‡äºå·¨å¤§ï¼Œä¸”è¿‡äºç¨€ç–ã€‚ æ˜ å°„ä¹‹é—´å®Œå…¨ç‹¬ç«‹ï¼Œå¹¶ä¸èƒ½è¡¨ç¤ºå‡ºä¸åŒç±»åˆ«ä¹‹é—´çš„å…³ç³»ã€‚ Embeddingæ˜¯ä»€ä¹ˆ # åµŒå…¥æ˜¯å°†æ­£æ•´æ•°ï¼ˆç´¢å¼•å€¼ï¼‰è½¬æ¢ä¸ºå›ºå®šå°ºå¯¸çš„ç¨ å¯†å‘é‡2ã€‚è¿™å¥è¯æ¥ç€kerasæ–‡æ¡£ä¸­å¯¹embeddingå±‚çš„è§£é‡Šï¼Œéå¸¸æ¦‚æ‹¬ï¼Œä¸å¤ªå®¹æ˜“ç†è§£ï¼Œä½†ç¡®å®æ¦‚æ‹¬äº†è¦å¹²çš„äº‹æƒ…ã€‚\næ¯”å¦‚ä¸€å¥è¯ï¼Œâ€œæˆ‘çˆ±ä¸­å›½â€å¯¹åº”çš„ç´¢å¼•ä¸º[0,1,2,3]ï¼Œè¦å°†è¿™ä¸ªç´¢å¼•è½¬åŒ–ä¸ºå›ºå®šå¤§å°ä¸”ç¨ å¯†çš„å‘é‡æ¥è¡¨ç¤ºï¼Œè€Œä¸æ˜¯ç¨€ç–çš„one-hotç¼–ç ã€‚å¯ä»¥è¡¨ç¤ºä¸º$[[0.2, 0.5], [0.6,-0.1], [0.8, 0.4], [0.5, 0.5]]$ï¼Œã€‚\nè¯åµŒå…¥é€šå¸¸æ˜¯8-1024ç»´åº¦ï¼Œæ ¹æ®æ•°æ®é‡çš„å¤§å°æ¥è°ƒæ•´ï¼Œé«˜ç»´åº¦çš„åµŒå…¥èƒ½æ›´å¥½çš„æ•æ‰è¯ä¹‹é—´çš„å…³ç³»ï¼Œä½†æ˜¯éœ€è¦æ›´å¤šçš„æ•°æ®æ¥è®­ç»ƒã€‚\nEmbeddingæ˜¯å¦‚ä½•å®ç°çš„ # é€šè¿‡Embeddingå±‚å®ç°ï¼Œembeddingå±‚å¯ä»¥çœ‹ä½œæ˜¯ä¸€å¼ ä»ç´¢å¼•æ˜ å°„åˆ°ç¨ å¯†å‘é‡çš„æŸ¥æ‰¾è¡¨ï¼Œå½“ä½¿ç”¨embeddingå±‚çš„æ—¶å€™ï¼Œembeddingå±‚å’Œç¥ç»ç½‘ç»œå…¶ä»–å±‚ä¸€æ ·ï¼Œæƒé‡æ˜¯éšæœºåˆå§‹åŒ–çš„ã€‚æ ¹æ®ä½ çš„è®­ç»ƒä»»åŠ¡ï¼Œembeddingå±‚é€šè¿‡åå‘ä¼ æ’­é€æ¸è°ƒæ•´ã€‚\nembeddingå±‚çš„å…·ä½“ç»“æ„å³å…¨è¿æ¥ç½‘ç»œï¼Œè¾“å…¥ä¸ºæ•´æ•°ç´¢å¼•ï¼Œéšå«å±‚æ˜¯embeddingçš„ç»´åº¦ï¼Œéšå«å±‚çš„æƒé‡å°±æ˜¯è¯åµŒå…¥ã€‚skip-gramæ¨¡å‹çš„å‰åŠéƒ¨åˆ†å³è¯åµŒå…¥ã€‚\nä¾‹å¦‚åœ¨tensorflowä¸­ï¼Œç”¨äºå¥å­åˆ†ç±»æ—¶çš„åµŒå…¥å±‚ï¼Œè¾“å…¥æ˜¯æ•´æ•°ç´¢å¼•ï¼Œç»è¿‡åµŒå…¥å±‚ã€æ± åŒ–å±‚ã€å…¨è¿æ¥è¾“å…¥è®­ç»ƒå¯ä»¥å¾—åˆ°åµŒå…¥å±‚æƒé‡ï¼Œå³è¯åµŒå…¥ã€‚\nembedding_dim=16 model = Sequential([Â vectorize_layer,Â Embedding(vocab_size, embedding_dim, name=\u0026#34;embedding\u0026#34;),Â GlobalAveragePooling1D(),Â Dense(16, activation=\u0026#39;relu\u0026#39;),Â Dense(1) ]) åº”ç”¨ # æœ€å¸¸ç”¨çš„å°±æ˜¯è¯åµŒå…¥è¡¨è¾¾ï¼Œä½†æ˜¯ä¸‡ç‰©å¯åµŒå…¥ã€‚Embeddingåœ¨è¾“å…¥æ•°æ®æ²¡æœ‰è¾ƒå¥½çš„æ•°æ®è¡¨ç¤ºæ—¶ï¼Œèƒ½å°†è¾“å…¥æ•°æ®æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡è½¬åŒ–ä¸ºå¯å­¦ä¹ çš„é«˜ç»´åº¦å‘é‡è¡¨ç¤ºï¼Œæ¯”å¦‚è¾“å…¥çš„ä¸ºå•è¯ã€å›¾ç‰‡æˆ–è€…è¾“å…¥çš„ä¸ºç©ºé—´ä½ç½®ç­‰ã€‚\nmnistæ•°æ®é›†ä¸­çš„å›¾ç‰‡ï¼Œå¯ä»¥é€šè¿‡åµŒå…¥å±‚æ¥è¡¨ç¤ºï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ¯ä¸ªç‚¹ä»£è¡¨ä¸€ä¸ªå›¾ç‰‡(10000*784)ï¼Œé€šè¿‡åµŒå…¥å±‚ï¼Œå°†å›¾ç‰‡çš„åƒç´ ç‚¹è½¬åŒ–ä¸ºç¨ å¯†çš„å‘é‡ï¼Œç„¶åé€šè¿‡t-SNE/pcaé™ç»´ï¼Œå¯ä»¥çœ‹åˆ°å›¾ç‰‡çš„ç©ºé—´åˆ†å¸ƒã€‚(generated by copilot) åœ¨è¿›è¡Œç‰¹å¾å·¥ç¨‹æ—¶ï¼Œå¾ˆéš¾æ•æ‰ç©ºé—´(æ—¶é—´)ç»´åº¦ã€‚é€šè¿‡ä½¿ç”¨æ·±åº¦å­¦ä¹ åµŒå…¥å±‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æä¾›ä¸€ç³»åˆ—ç”¨æˆ·è¡Œä¸º(ä½œä¸ºç´¢å¼•)ä½œä¸ºæ¨¡å‹çš„è¾“å…¥æ¥æœ‰æ•ˆåœ°æ•æ‰è¿™ä¸ªç©ºé—´ç»´åº¦ã€‚\næˆ‘çš„åšå®¢å³å°†åŒæ­¥è‡³è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒºï¼Œé‚€è¯·å¤§å®¶ä¸€åŒå…¥é©»ï¼šhttps://cloud.tencent.com/developer/support-plan?invite_code=2cy4t3peazy8s\nWord embeddings |Â Text |Â TensorFlow\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nåµŒå…¥å±‚ Embedding - Keras ä¸­æ–‡æ–‡æ¡£\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"21 February 2023","permalink":"/posts/20230222-embedding/","section":"Posts","summary":"ä¸‡ç‰©çš†å¯Embedding","title":"Embeddingæ˜¯ä»€ä¹ˆï¼Ÿ"},{"content":" ç®€ä»‹ # Skip-gram1å±äºWord2Vecçš„ä¸€ç§ï¼Œç»™å®šinputï¼Œé¢„æµ‹ä¸Šä¸‹æ–‡ï¼Œè€ŒCBOWï¼ˆè§è¡¥å……ï¼‰æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡æ¥é¢„æµ‹inputã€‚\nWord2Vecæ¨¡å‹åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤2ï¼š\nå»ºç«‹æ¨¡å‹ï¼Œè¿™ç±»æ–¹æ³•ä¸è‡ªç¼–ç æ¨¡å‹æœ‰ç‚¹åƒï¼Œå»ºæ¨¡ä¸æ˜¯æœ€ç»ˆç›®çš„ï¼› é€šè¿‡æ¨¡å‹è·å–åµŒå…¥è¯å‘é‡ã€‚ æ¨¡å‹ç»†èŠ‚ # æ•´ä½“æ¡†æ¶å›¾\nè¾“å…¥å±‚ # è¯ä¸èƒ½ç›´æ¥è¾“å…¥ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œæ¯”å¦‚è®­ç»ƒæ ·æœ¬ä¸­æœ‰10000ä¸ªä¸åŒçš„è¯ï¼Œå°†æŸä¸ªè¯â€œæˆ‘â€æˆ–è€…â€œæˆ‘ä»¬â€è¿›è¡Œone-hotç¼–ç ï¼Œå½¢æˆ10000ç»´çš„å‘é‡ï¼Œå…¶ä¸­â€œæˆ‘â€çš„åœ°æ–¹ä¸º1ï¼Œå…¶ä»–å‡ä¸º0ã€‚å¯¹äºSkip-gramè¾“å…¥å•ä¸ªè¯å‘é‡ï¼Œè¾“å‡ºå°±æ˜¯è¿™ä¸ªè¯é™„è¿‘çš„è¯ç»„æˆçš„å‘é‡ã€‚\næ¨¡å‹è¾“å…¥è¾“å‡ºå‡ä¸º10000ç»´åº¦å‘é‡$\\{0,1\\}^{10000}$\néšå«å±‚ # å‡å¦‚æƒ³ç”¨300ä¸ªç‰¹å¾æ¥è¡¨å¾è¯ï¼Œé‚£ä¹ˆéšå«å±‚å•ä¸ªç¥ç»å…ƒæƒé‡ä¸º[10000, 1]ï¼Œ300ä¸ªç¥ç»å…ƒä¸º[10000, 300] ä¸Šå›¾å¯ä»¥ç†è§£ä¸ºè¾“å…¥ç»è¿‡éšå«å±‚ä½œç”¨åˆšå¥½å¾—åˆ°å•è¯çš„è¡¨å¾ã€‚è¾“å…¥å’Œéšå«å±‚ä¸¤éƒ¨åˆ†å¯ä»¥è¿›è¡Œè¯åµŒå…¥å³embeddingã€‚\nè¾“å‡ºå±‚ # æ¨¡å‹è¾“å‡ºä¸º10000ç»´åº¦å‘é‡ï¼Œè¦è¾¾åˆ°è¿™æ ·çš„è¾“å‡ºå±‚ä¸º10000ä¸ªç¥ç»å…ƒï¼Œå¹¶ä¸”è¿™äº›ç¥ç»å…ƒè¾“å‡ºå’Œä¸º1ï¼Œä½¿ç”¨softmaxå‡½æ•°æ¥è¾¾åˆ°è¿™ç§æ•ˆæœã€‚ä»¥ä¸‹ä¸¤ä¸ªç­‰å¼å±•ç¤ºä¸€ä¸ªè¯å‘é‡åœ¨ç¥ç»ç½‘ç»œä¸­çš„å‰å‘ä¼ æ’­ã€‚\n$$ \\begin{bmatrix} 1 \u0026amp; 10000 \\end{bmatrix} \\times \\begin{bmatrix} 10000 \u0026amp; 300 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; 300 \\end{bmatrix} \\ $$\n$$ \\begin{bmatrix} 1 \u0026amp; 300 \\end{bmatrix} \\times \\begin{bmatrix} 300 \u0026amp; 10000 \\end{bmatrix} = \\begin{bmatrix} 1 \u0026amp; 10000 \\end{bmatrix} \\ $$\nè¡¥å…… # skip-gramåå­—ç”±æ¥3ï¼š\né¦–å…ˆn-gramæ˜¯ä¸€ç³»åˆ—è¿ç»­çš„è¯ï¼ˆtokensï¼‰ï¼Œè€Œskip-gramï¼Œæˆ–è€…skip-n-gramï¼Œskipçš„æ˜¯tokenä¹‹é—´çš„gapï¼Œjumps over theæ˜¯ä¸€ä¸ª3-gramï¼Œé‚£ä¹ˆ(jumps, the)åˆšå¥½skipäº†ä¸€ä¸ªgram (over)ã€‚\nä»€ä¹ˆæ˜¯Softmaxï¼Ÿ4\nSoftmaxä»å­—é¢ä¸Šæ¥è¯´ï¼Œå¯ä»¥åˆ†æˆsoftå’Œmaxä¸¤ä¸ªéƒ¨åˆ†ã€‚maxæ•…åæ€è®®å°±æ˜¯æœ€å¤§å€¼çš„æ„æ€ã€‚Softmaxçš„æ ¸å¿ƒåœ¨äºsoftï¼Œè€Œsoftæœ‰è½¯çš„å«ä¹‰ï¼Œä¸ä¹‹ç›¸å¯¹çš„æ˜¯hardç¡¬ã€‚å¾ˆå¤šåœºæ™¯ä¸­éœ€è¦æˆ‘ä»¬æ‰¾å‡ºæ•°ç»„æ‰€æœ‰å…ƒç´ ä¸­å€¼æœ€å¤§çš„å…ƒç´ ï¼Œå®è´¨ä¸Šéƒ½æ˜¯æ±‚çš„hardmaxã€‚hardmaxæœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯åªé€‰å‡ºå…¶ä¸­ä¸€ä¸ªæœ€å¤§çš„å€¼ï¼Œå³éé»‘å³ç™½ã€‚Softmaxçš„å«ä¹‰å°±åœ¨äºä¸å†å”¯ä¸€çš„ç¡®å®šæŸä¸€ä¸ªæœ€å¤§å€¼ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªè¾“å‡ºåˆ†ç±»çš„ç»“æœéƒ½èµ‹äºˆä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œè¡¨ç¤ºå±äºæ¯ä¸ªç±»åˆ«çš„å¯èƒ½æ€§ã€‚ç»è¿‡ä½¿ç”¨æŒ‡æ•°å½¢å¼çš„Softmaxå‡½æ•°èƒ½å¤Ÿå°†å·®è·å¤§çš„æ•°å€¼è·ç¦»æ‹‰çš„æ›´å¤§ã€‚\nCBOWæ˜¯ä»€ä¹ˆï¼Ÿ\nContinuous Bag of Word Modelè¿ç»­è¯å¸¦æ¨¡å‹ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡æ¥é¢„æµ‹ä¸­é—´çš„è¯\nWord2Vec Tutorial - The Skip-Gram Model Â· Chris McCormick\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nç†è§£ Word2Vec ä¹‹ Skip-Gram æ¨¡å‹ - çŸ¥ä¹\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nskip-grammæ¨¡å‹skipäº†ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå«skip-grammæ¨¡å‹ï¼Ÿ - çŸ¥ä¹\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nä¸€æ–‡è¯¦è§£Softmaxå‡½æ•° - çŸ¥ä¹\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"5 February 2023","permalink":"/posts/20230205-skip-gram-part1/","section":"Posts","summary":"","title":"Skip-gramæ¨¡å‹ï¼ˆ1ï¼‰"},{"content":"","date":"4 February 2023","permalink":"/tags/medical-data/","section":"Tags","summary":"","title":"medical data"},{"content":"","date":"4 February 2023","permalink":"/tags/mimic-iv/","section":"Tags","summary":"","title":"mimic-iv"},{"content":"","date":"4 February 2023","permalink":"/categories/paper/","section":"Categories","summary":"","title":"Paper"},{"content":" ã€ŠThe MIMIC Code Repository: Enabling reproducibility in critical care researchã€‹è®ºæ–‡ å¼•è¨€ # ç§‘å­¦ç»“æœçš„å¯é‡å¤æ€§è¶Šæ¥è¶Šå—åˆ°å…³æ³¨1ï¼› åŒ»ç–—é¢†åŸŸè¿›å…¥æ•°å­—åŒ–é©å‘½ï¼ˆæœ¬æ–‡æ˜¯2017å¹´æ¥æ”¶ï¼‰ï¼Œå¼•å‡ºå½¢æˆMIMIC-IIIæ•°æ®åº“ï¼› EHRäºŒæ¬¡åˆ†æéœ€è¦ä¸´åºŠä¸“å®¶å’Œæ•°æ®ç§‘å­¦å®¶çš„åˆä½œï¼Œåœ¨EHRæ•°æ®åº“ä¸Šæ¨å¯¼æˆ–è€…å®šä¹‰ä¸€äº›æ¦‚å¿µæ˜¯éœ€è¦èµ„æºçš„ï¼Œå¯¹äºæ²¡æœ‰ç‰¹åˆ«å¼ºçš„ä¸´åºŠèƒŒæ™¯æˆ–è€…æ•°æ®ç§‘å­¦æŠ€èƒ½çš„äººæ¥è¯´å·¨å¤§éšœç¢ï¼› è¯¥æ–‡ä»‹ç»MIMICä»£ç ä»“åº“ï¼Œä»‹ç»ä¸é‡ç—‡ç›¸å…³æ¦‚å¿µçš„å¯¼å‡ºä»¥åŠç›¸å…³å‡è®¾æ¡ä»¶ç­‰ï¼› å…¬å¼€æ•°æ®å·²ç»é€æ¸æœ‰äº†ï¼Œå…¬å¼€ç›¸åº”çš„æ•°æ®ä»£ç åŒæ ·é‡è¦ã€‚åŠ é€Ÿå¹¶æå‡æœªæ¥ç ”ç©¶çš„ä¸€è‡´æ€§ä»¥åŠæœ‰æ•ˆæ€§ã€‚ ä»£ç ä»“åº“è¯¦æƒ… # Concepts ä»ç”µå­ç—…å†ä¸­æå–é‡è¦æ¦‚å¿µçš„ä»£ç ã€‚æ¯”å¦‚æå–AKIçš„æ¨¡å— Executable documents å¯æ‰§è¡Œçš„Notebooksæ–‡ä»¶ï¼Œå¯é‡å¤çš„ç¤ºä¾‹ç ”ç©¶æˆ–è€…æ•™ç¨‹ Community å»ºç«‹å…¬å¼€è®¨è®ºä¾¿äºç¤¾åŒºæˆå‘˜è´¡çŒ® æ¦‚å¿µconcepts # ä»£ç åº“ä¸­å¸¸ç”¨çš„æ¦‚å¿µ\nç–¾ç—…ä¸¥é‡ç¨‹åº¦è¯„åˆ†Severity of illness scores # åœ¨å›é¡¾æ€§æ•°æ®åº“ä¸­éš¾ä»¥è®¡ç®—\nå¤§å¤šéƒ½æ˜¯åœ¨å‰ç»æ€§å®éªŒä¸­è·å–çš„ï¼› å¸¸è§„æ”¶é›†çš„æ•°æ®ç¼ºç›¸åº”å…ƒç´ ã€‚æœ‰äº›ç‰¹å¾æœªçº³å…¥ç»“æ„åŒ–ç”µå­ç—…å†ç³»ç»Ÿï¼Œå¦å¤–åˆ™æ˜¯å¯¹æŸç§æƒ…å†µçš„æ‚£è€…æ²¡æœ‰ç»Ÿä¸€çš„åè®®æ¥å®šä¹‰çŠ¶æ€ ç›®å‰MIMICä»£ç åº“ä¸­æœ‰ï¼š\nacute physiology score(APS)-III simplified acute physiology score(SAPS) SAPS-II Oxford acute severity of illness score(OASIS) å™¨å®˜è¡°ç«­Organ dysfunction scores # SOFAè®¡ç®—æ–¹å¼ä¸åŒï¼Œç”±äºGCSè¯„åˆ†å®šä¹‰ä¸åŒ\nSequential Organ Failure Assessment(SOFA), Logistic Organ Dysfunction system(LODS)\næ²»ç–—æ—¶é—´Time of treatment # ç”±äºæ•°æ®è·å–çš„é™åˆ¶ï¼Œè®¸å¤šè¯ç‰©å’Œç¡®åˆ‡çš„æ²»ç–—æ—¶é—´æ— æ³•å¾—å‡ºï¼Œéœ€è¦æ ¹æ®ä¸´åºŠç»éªŒè¯†åˆ«å…¶ä»–å¯æ›¿ä»£çš„æ•°æ®\næœºæ¢°é€šæ°”æ—¶é•¿ï¼šè¯†åˆ«æœºæ¢°é€šæ°”æ—¶é•¿éœ€è¦å¤æ‚çš„é€»è¾‘è§„åˆ™ï¼ˆæ–‡ä¸­å›¾3ï¼‰ è¡€ç®¡åŠ å‹è¯ç‰©ä½¿ç”¨ CRRT è„“æ¯’ç—‡sepsis # sepsiså®šä¹‰æœ‰å¤šç§ç‰ˆæœ¬ï¼Œè¿™é‡Œç»™å‡ºäº†Angus 2001ï¼ŒMartin 2003ï¼ŒIwashyna 2014ä¸‰ä¸ªç‰ˆæœ¬\nå…±ç—…Comorbidities # ç»™å‡ºäº†4ä¸ªç‰ˆæœ¬\nElixhauser A 1998 American Health and Research Quality groupï¼ˆAHRQï¼‰ Quan 2005 Van Walraven 2009 conceptæŒ‡å— # å¯æ‰§è¡Œæ–‡æ¡£ # å½“æ•°æ®å’Œä»£ç éƒ½å…¬å¼€å¯è·å–ï¼Œæä¾›ä¸€ç§ç ”ç©¶å¯ä»¥è¢«é‡ç°çš„æ¡†æ¶ï¼ŒåŸºäºRmdæˆ–notebookç»™å‡ºå®ä¾‹ã€‚\nHsu 2015ç ”ç©¶å¤ç° indwelling arterial catheters and their association with in-hospital mortality for hemodynamically stable patients with respiratory failure aline.ipynbæå–æ•°æ® aline.Rmdæ•°æ®åˆ†æ æ•™ç¨‹ definition of CRRT introduction to SQL a step-by-step guide to selecting a study cohort an outline of the data-capture process ç¤¾åŒº # è®©ç ”ç©¶äººå‘˜å’Œæ•°æ®ç»´æŠ¤äººå‘˜ã€ä¸´åºŠäººå‘˜å…±åŒæå‡ä»£ç \nç»“è®º # å…¬å¼€æ•°æ®åº“çš„æ¡ˆä¾‹å·²ç»ä¸å°‘ï¼Œä¸ºäº†è®©ç ”ç©¶æ›´åŠ é€æ˜ï¼Œä¹Ÿéœ€è¦å…¬å¼€ç›¸åº”æ•°æ®åˆ†æå’Œæ•°æ®å¤„ç†çš„ä»£ç \nè¡¥å…… # ä»£ç åº“åœ°å€ï¼šhttps://github.com/MIT-LCP/mimic-code ä¹‹å‰ä»¥MIMIC-IIIä¸ºä¸»ï¼Œç°åœ¨mimic-iiiå’Œmimic-ivåˆå¹¶åœ¨ä¸€èµ·äº† mimicæ•°æ®åº“ä¸ºäº†è®©ç ”ç©¶è€…è®¿é—®æ›´åŠ æ–¹ä¾¿ï¼Œå¾ˆå¤§ä¸€ä¸ªæ”¹å˜æ˜¯éƒ¨ç½²åœ¨äº‘ä¸Šæ¯”å¦‚googleçš„äº‘å¹³å°ï¼Œäº‘å¹³å°ä¸Šéœ€è¦big queryè¯­æ³•æ¥è®¿é—®ï¼Œæ‰€ä»¥ç°åœ¨ä»£ç åº“å…³äºæ•°æ®æå–çš„ä»£ç æ›´æ–°ä»¥big queryä¸ºä¸»ï¼Œéœ€è¦é€šè¿‡è„šæœ¬è½¬åŒ–ä¸ºé€‚åˆpostgresè¯­æ³• Open a terminal in theÂ conceptsÂ folder. RunÂ convert_bigquery_to_postgres.sh. e.g.Â bash convert_bigquery_to_postgres.sh This file outputs the scripts to theÂ postgresÂ subfolder after applying a few changes. This also creates theÂ postgres_make_concepts.sqlÂ script in the postgres subfolder. ä»ä»£ç ä»“åº“å¯¼å‡ºçš„æ¦‚å¿µconceptséƒ½æ”¾åˆ°mimic_derivedæ•°æ®é›†é‡Œ Johnson, A. E. W., Stone, D. J., Celi, L. A. \u0026amp; Pollard, T. J. The MIMIC Code Repository: enabling reproducibility in critical care research. J Am Med Inform Assn 25, 32â€“39 (2018).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"4 February 2023","permalink":"/posts/20230204-mimic-code/","section":"Posts","summary":"","title":"å…¬å¼€é‡ç—‡ç›‘æŠ¤æ•°æ®åº“MIMICä»£ç ä»“åº“ä»‹ç»"},{"content":"èƒŒæ™¯ # æœ¬æ–‡1é¦–å…ˆä»‹ç»mimicé¡¹ç›®çš„ç”±æ¥ï¼ŒåŒ»é™¢æ•°æ®å½’æ¡£ç³»ç»Ÿéƒ½ä¸æ˜¯ä¸ºç ”ç©¶è®¾è®¡çš„ï¼Œéš¾ä»¥è®¿é—®ä»¥åŠæŸ¥è¯¢ï¼› MIMICä»0-4å‘å±•ç®€ä»‹ï¼› å…¶ä»–æ•°æ®åº“ç®€ä»‹ eICU-CRDï¼Œç¾å›½å¤šä¸­å¿ƒ200859ä¾‹ICUè®°å½• AmsterdamUMCdbï¼Œè·å…°å•åŒ»å­¦ä¸­å¿ƒ20109ä¾‹æ‚£è€…23106æ¬¡å…¥é™¢è®°å½• HiRIDData detailsï¼Œç‘å£«34000å…¥é™¢æ‚£è€…é«˜åˆ†è¾¨ç‡æ•°æ®ï¼ˆæ¯ä¸¤åˆ†é’Ÿä¸€ä¸ªæ•°æ®ç‚¹ï¼Œ712ä¸­å¸¸è§„æ‰‹æœºç”Ÿç†æ•°æ®ï¼‰ HiRID has a higher time resolution than other published datasets, most importantly for bedside monitoring with most parameters recordedÂ every 2 minutes å»éšç§åŒ–æ–¹æ³•å¯ä»¥å€Ÿé‰´ PICï¼Œä¸­å›½12881ä¾‹æ‚£è€…13941æ¬¡å„¿ç§‘ICUè®°å½• é—®é¢˜ï¼Œå½“å‰æ•°æ®åº“éƒ½åªæ˜¯å•æ¨¡æ€çš„æ•°æ®æˆ–å„æœ‰ç‰¹ç‚¹ï¼Œä¸”ä¸´åºŠå®è·µå‘å±•å˜åŒ–å¿«ï¼Œæ•°æ®åº“éœ€è¦ä¸æ–­æ›´æ–°å®Œå–„ï¼› MIMIC-IVæ˜¯å½“ä»£çš„ç»¼åˆå¤šæ¨¡æ€æ•°æ®åº“ æ–¹æ³• # mimic-ivæ•°æ®åº“æ˜¯æ€ä¹ˆå»ºçš„ï¼Ÿ\nè·å–ã€è½¬åŒ–ã€å»éšç§åŒ– è·å– # BIDMCåŒ»é™¢å¸¸è§„çš„ä¸´åºŠæ•°æ®å­˜å‚¨åœ¨microsoft SQLä¸­ï¼Œé€šè¿‡VPNè½¬ç§»åˆ°MITæœåŠ¡å™¨çš„PostgreSQLï¼Œè¡¥å……æ•°æ®å¦‚ICDã€æ‚£è€…æ­»äº¡ä¿¡æ¯ç­‰å¤–éƒ¨å¯¼å…¥åˆ°PostgreSQL\né˜Ÿåˆ—ï¼š2008-2019ï¼Œ18å²ä»¥ä¸Š åºŠæ—ä¿¡æ¯æ¥è‡ªäºMetaVisionï¼ŒåŒ»é™¢EHRä¼šé€šè¿‡HL7æ¨ä¿¡æ¯åˆ°MetaVision å¤–éƒ¨æ•°æ®ä¸»è¦è¯´æ˜DRGså’ŒICDæ˜¯å¦‚ä½•å¤„ç†ä»¥åŠæ­»äº¡ä¿¡æ¯å¦‚ä½•å¤„ç† DRGså’ŒICDç”±äºæ•°æ®åº“è·¨åº¦æ—¶é—´é•¿ä»¥åŠä¸åŒç‰ˆæœ¬ï¼Œåœ¨æ•°æ®åº“ä¸­æŠŠè¿™äº›éƒ½å¯¼å…¥äº† æ­»äº¡ä¿¡æ¯é€šè¿‡ä¸é©¬è¨è¯¸å¡å·ç”Ÿå‘½è®°å½•å’Œç»Ÿè®¡ç™»è®°å¤„è¿›è¡ŒåŒ¹é…ï¼Œè€Œéç¤¾ä¿æ¡£æ¡ˆ è½¬åŒ– # è½¬åŒ–æœ‰ä¸¤æ¡åŸåˆ™\nä¸MIMIC-IIIä¿æŒå…¼å®¹ å°½é‡å‡å°‘å¤„ç†è¿‡ç¨‹è®©å…¬å¼€æ•°æ®ä¸ä¸´åºŠå®è·µæ•°æ®ä¿æŒä¸€è‡´ æ•°æ®è¢«åˆ†ä¸ºä¸‰ä¸ªç»„ï¼šhospã€icuå’Œnote\nhospï¼šadmission/discharge/transferï¼ˆADTï¼‰ï¼Œå®éªŒå®¤æ£€æŸ¥ç»“æœï¼Œå¾®ç”Ÿç‰©åŸ¹å…»ï¼Œå¤„æ–¹ï¼Œç®¡ç†æ•°æ® icuï¼šæ‚£è€…å‡ºå…¥é‡ã€è¾“æ¶²ã€æ“ä½œã€è®°å½•åˆ°çš„è§‚æµ‹å€¼ç­‰ noteï¼šå‡ºé™¢æ€»ç»“å’Œæ”¾å°„å­¦æŠ¥å‘Šï¼Œä¹Ÿåˆ›å»ºäº†ç›¸å¯¹åº”çš„è‡ªç”±æ–‡æœ¬ç»“æ„åŒ–è¡¨â€œå®ä½“-å±æ€§-å€¼â€ å»éšç§åŒ– # éµä»The Health Insurance Portability and Accountability Actï¼ˆHIPAAï¼‰æ¡æ¬¾è§„å®šäº†18é¡¹æ ‡è¯†ç¬¦ï¼ŒåŒ…æ‹¬å§“åã€åœ°å€ã€å¹´é¾„ç­‰éœ€è¦å»æ‰ æ—¥æœŸç§»åŠ¨ï¼Œä½†æ—¶é—´ç‚¹é—´è·ä¿ç•™ ç»“åˆäº†ä¸¤ä¸ªå…¬å¼€çš„ç®—æ³•23ä»è‡ªç”±æ–‡æœ¬ä¸­ç§»é™¤ä¸ªäººå¥åº·ä¿¡æ¯ï¼ˆPHIï¼‰ ä¸¤ä¸ªç®—æ³•éƒ½æ²¡æ•æ‰åˆ°çš„ï¼Œä»æ•°æ®åº“ä¸­ç§»é™¤ï¼Ÿè¿™ä¸ªæ²¡å†™å…·ä½“æ€ä¹ˆåš æ•°æ®è®°å½•ç»“æœ # è¿™ä¸€éƒ¨åˆ†ç±»ä¼¼ä¼ ç»Ÿè®ºæ–‡çš„ç»“æœï¼Œè¯¦ç»†ä»‹ç»äº†hospã€icuã€noteæ¨¡å—é‡Œé¢çš„æ•°æ®æƒ…å†µï¼Œå¯¹å„è¡¨è¿›è¡Œä»‹ç»\nHosp # é¦–å…ˆä»‹ç»æ¨¡å—é‡Œä¸»è¦é”®å€¼ä»¥åŠè¡¨ä¹‹é—´è¿æ¥å…³ç³»ï¼Œä¸MIMIC-IIIä¸€è‡´\næ‚£è€…åŸºæœ¬ä¿¡æ¯ï¼špatientsã€admissionså’Œtransfersè¡¨\næ‚£è€…æ—¶é—´ä¿¡æ¯ï¼Œanchor_yearã€anchor_ageã€anchor_year_groupè¿™å‡ ä¸ªé‡è¦é¡¹ anchor_yearé”šå®šå¹´ä»½ï¼Œç”±äºæ—¶é—´éƒ½æ˜¯å»éšç§åŒ–çš„å¹³ç§»è¿‡çš„ï¼Œè¿™é‡Œå¯ä»¥çœ‹ä½œå¹³ç§»ä¹‹åçš„å‚è€ƒå¹´ä»½ anchor_year_groupæ˜¯çœŸå®å¹´ä»½çš„åŒºé—´ æ‚£è€…æ­»äº¡ä¿¡æ¯æœ€å¤šåˆ°æ‚£è€…å‡ºé™¢1å¹´ä¸ºæ­¢ ç®¡ç†ä¿¡æ¯ï¼šservicesã€poeã€poe_detailè¡¨\nservices æ‚£è€…ä½é™¢æœŸé—´æ‰€å—åˆ°çš„åŒ»ç–—æœåŠ¡ poe åŒ»å˜±å½•å…¥ç³»ç»Ÿï¼šæ²»ç–—å’Œæ“ä½œ è®¡è´¹ä¿¡æ¯ï¼šdiagnoses_icdã€procedures_icdã€drgcodesã€hcpcsevents\næ£€æŸ¥ç»“æœï¼šmicrobiologyeventsã€labevents\nè¯ç‰©ä¿¡æ¯ï¼šprescriptionsã€pharmacyã€emarã€emar_detail\nå¤„æ–¹ã€è¯æˆ¿ä¿¡æ¯ï¼› 2016å¹´éƒ¨ç½²electronic Medicine Administration Recordï¼ŒeMARï¼› çœ‹èµ·æ¥å…³ç³»æ¯”è¾ƒå¤æ‚ä½¿ç”¨å¾—ç»“åˆå®ä¾‹ ICU # chartevents, d_items, datetimeevents, icustays, inputevents, outputevents, and procedureeventsè¡¨\nNote # å‡ºé™¢æ€»ç»“ï¼š\nä¸»è¯‰ã€ç°ç—…å²ã€æ—¢å¾€ç—…å²ã€ç®€è¦ç—…ç¨‹ã€ä½“æ ¼æ£€æŸ¥å’Œå‡ºé™¢è¯Šæ–­ æ”¾å°„å­¦æŠ¥å‘Šï¼š\nxå°„çº¿ã€CTã€MRIã€è¶…å£° æŠ€æœ¯éªŒè¯ç»“æœ # å®Œæ•´æ€§æ£€æŸ¥ æ•°æ®åº“è‡ªèº«æ˜¯å®Œå¤‡çš„ï¼Œä¸ä¼šå‡ºç°æŸä¸ªæ‚£è€…çš„ä¿¡æ¯åªå‡ºç°ä¸€å¼ è¡¨å…¶ä»–è¡¨éƒ½æ‰¾ä¸åˆ°çš„æƒ…å†µ ä¸€è‡´æ€§æ£€æŸ¥ æ•°æ®ç»“æœä¸ä¸€äº›å¸¸è¯†ä¸€è‡´ å»éšç§åŒ–æ£€æŸ¥ ä½¿ç”¨ç¬”è®° # å¦‚ä½•è·å– å‚åŠ è¯¾ç¨‹ ç­¾ç½²data use agreement, DUA ä»£ç åº“ä»¥åŠæ¨¡ç‰ˆ æ€è€ƒ # MIMICæ•°æ®åº“ä¸€æ­¥ä¸€æ­¥å‘å±•å·²ç»æ¥åˆ°äº†ç¬¬å››ç‰ˆï¼Œå¾ˆå¥½çš„ä½“ç°äº†ç§‘å­¦ç ”ç©¶çš„å¯æŒç»­å‘å±•ã€‚ ä¸MIMIC-IIIè®ºæ–‡å†™æ³•ä¸åŒï¼Œmimic-ivå¯¹æ•°æ®åº“æ„å»ºè¿‡ç¨‹å†™çš„æ›´åŠ è¯¦ç»†ï¼Œå¯æ“ä½œæ€§æ›´é«˜ï¼Œè€Œmimic-iiiç”±äºæ²¡æœ‰å¾ˆå¥½çš„æŠŠè¿™ä¸ªè¿‡ç¨‹ç»“æ„åŒ–æŠ½è±¡åˆ†æˆå‡ æ­¥æ˜¾å¾—æ„å»ºç»†èŠ‚ä¸è¶³ï¼Œè€Œmimic-iiiè®ºæ–‡è¡¨æ ¼æ¯”è¾ƒä¸°å¯Œï¼Œå¯¹æ•°æ®åº“è¿›è¡Œäº†ä¸€äº›ç²—ç²’åº¦çš„ä»‹ç»ï¼Œmimic-ivè®ºæ–‡æ²¡æœ‰ã€‚ä¸ªäººè®¤ä¸ºivè¿™ç¯‡è®ºæ–‡å†™çš„æ›´å¥½ä¸€ç‚¹ã€‚ ä¼´éšç€æ•°æ®ç±»å‹è¶Šæ¥è¶Šå¤šã€æ•°æ®åº“è¶Šæ¥è¶Šå¤šï¼Œæ•°æ®åˆ†æäººå‘˜ä¹Ÿéœ€è¦æŒæ¡æ›´å¤šç±»å‹æ•°æ®é¢„å¤„ç†æ–¹æ³•ã€‚é¢å¯¹æ–‡æœ¬ã€å›¾åƒã€æ³¢å½¢çš„å¤šæ¨¡æ€æ•°æ®åˆ†ææˆ–è€…åœ¨ä¸å®Œå¤‡æ•°æ®æƒ…å†µä¸‹æ¨¡å‹çš„ä¸ç¡®å®šæ€§æˆä¸ºä¸¤ä¸ªç›¸å¯¹åº”çš„ç ”ç©¶æ–¹å‘ã€‚ Johnson, A. E. W. et al. MIMIC-IV, a freely accessible electronic health record dataset. Sci Data 10, 1 (2023).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nNeamatullah, I. et al. Automated de-identification of free-text medical records. BMC medical informatics and decision making 8,1â€“17 (2008).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nJohnson, A. E. W., Bulgarelli, L. \u0026amp; Pollard, T. J. Deidentification of free-text medical records using pre-trained bidirectional transformers. In Proceedings of the ACM Conference on Health, Inference, and Learning, 214â€“221 (2020).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"17 January 2023","permalink":"/posts/20230117-mimiciv/","section":"Posts","summary":"ã€ŠMIMIC-IV, a freely accessible electronic health record datasetã€‹è®ºæ–‡ç¬”è®°","title":"å…¬å¼€é‡ç—‡ç›‘æŠ¤æ•°æ®åº“MIMIC-IVä»‹ç»"},{"content":"","date":"13 January 2023","permalink":"/categories/class/","section":"Categories","summary":"","title":"Class"},{"content":"","date":"13 January 2023","permalink":"/tags/deep-learning/","section":"Tags","summary":"","title":"deep learning"},{"content":" 1.Introduction to Deep learning # éœ‡æ’¼ï¼Œç¬¬ä¸€èŠ‚è¯¾ç›´æ¥æ”¾å¤§æ‹›ï¼Œç”¨è‡ªå·±æ‹æ‘„çš„è§†é¢‘å’Œå¥¥å·´é©¬åˆæˆæ¥ä»‹ç»è¿™é—¨è¯¾ç¨‹ã€‚ ä¸ç®¡è€å¸ˆåœ¨è¯¾ç¨‹ä¸Šè®²ä»€ä¹ˆï¼Œå¸Œæœ›ä½ ä»¬èƒ½çœŸæ­£çš„æ€è€ƒä¸ºä»€ä¹ˆè¿™ä¸€æ­¥æ˜¯é‡è¦è€Œä¸”å¿…é¡»çš„ï¼Œæ­£æ˜¯è¿™äº›æ€è€ƒæ‰èƒ½åšå‡ºçœŸæ­£ä»¤äººæƒŠè®¶çš„çªç ´ã€‚ 2.Deep Sequence Model # Three way to solve gradient vanish\nGated Cells LSTM Forget Store Update Output Attention [[Transformer]] 3.Deep Computer Vision # ä»‹ç»å·ç§¯æ“ä½œï¼Œæ˜¯ä¸€ç§æå–ç‰¹å¾çš„æ–¹æ³•ç”Ÿæˆfeature mapsï¼ˆè¿˜æœ‰å…¶ä»–çš„æ–¹æ³•å¯ä»¥ç”¨å—ï¼Ÿç„¶åæ•ˆæœè¿˜ä¸é”™ï¼‰ï¼› ä¸å…¨è¿æ¥ç›¸æ¯”çš„ä¼˜ç‚¹ï¼› Fast RCNNç”¨äºç›®æ ‡æ£€æµ‹ï¼Œæ€ä¹ˆå®ç°æ¨èç‰¹å®šåŒºåŸŸå›¾åƒï¼Ÿ åŒ»å­¦å›¾ç‰‡åˆ†å‰² æ€»ç»“ï¼š åŸç† CNNæ¶æ„ åº”ç”¨ 4.Deep Generative Models # what ç›®æ ‡: æ¥è‡ªäºä¸€äº›åˆ†å¸ƒä¸­çš„è®­ç»ƒæ ·æœ¬ï¼Œé€šè¿‡è¿™äº›æ ·æœ¬å­¦ä¹ æ¨¡å‹æ¥è¡¨å¾è¿™ä¸ªåˆ†å¸ƒï¼› how å¯†åº¦ä¼°è®¡ï¼›ç¥ç»ç½‘ç»œé€‚åˆæ¥è¿›è¡Œé«˜ç»´åº¦è¡¨å¾ï¼› why Debiasing: Capable of uncovering underlying features in a dataset Outlier detection: how can we detect when we encounter something new or rare? Latent variable representation: ä¸¾ä¾‹äº‹ç‰©çš„æŠ•å½±ï¼Œåªèƒ½çœ‹è§å½±å­å³è¡¨è±¡ï¼Œè€Œè¢«ç¯å…‰ç…§å°„çš„å®ç‰©æ˜¯çœ‹ä¸è§çš„å³éšå˜é‡ï¼›è¦åšçš„æ˜¯é€šè¿‡è§‚å¯Ÿåˆ°çš„æŠ•å½±æ¥å¯¹å®ç‰©è¿›è¡Œå»ºæ¨¡ Autoencoder: reconstruction loss å®Œå…¨æ˜¯ç¡®å®šæ€§æ€§ VAEsï¼šnormal prior + regularization reconstruction loss + regularization term encoder: $q_\\phi(z|x)$ decoder: $p_\\theta(x|z)$ KL-divergence: $D(q_\\phi(z|x)||p(z))$ GANs make a generative model by having two neural networks compete with each other â­ï¸CycleGAN: domain transformations è§†é¢‘å¼€å¤´çš„è§†é¢‘å°±æ˜¯ç”¨è¿™ä¸ªåˆæˆ 5.Deep reinforcement learning # Reward: $$R_t = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + \u0026hellip;$$ Q-function: expected total future reward $$Q(s_t, a_t) = E[R_t|s_t, a_t]$$ Policy: to infer the best action to take at its state, choose an action that maximizes future reward $$\\pi^*(s)=\\mathop{\\arg\\max}\\limits_{s}Q(s, a)$$ Value Learning find $Q(s, a)$ $a = \\mathop{\\arg\\max}\\limits_{a}Q(s, a)$ Police Learning find $\\pi(s)$ sample $a\\sim\\pi(s)$ Deep Q Network(DQN) Policy Gradient AlphaGo 6.DL Limitations and New Frontiers # limitations Generalization data is important Uncertainty in Deep learning adversarial attack Algorithmic Bias Frontiers encoder many real world data cannot be captured by standard encodings GCNï¼ˆGraph Convolutional Networksï¼‰ Automated AI 7. LiDAR for Autonomous Driving # @INNOVIZ\nCamera Vs LiDAR äº’è¡¥ï¼Œè§†çº¿ä¸å¥½çš„æƒ…å†µ å†—ä½™èƒ½ä¿è¯å‡†ç¡® Safety and Comfort 8. Automatic Speech Recognition # @Rev\nConformer CTC 9. AI fore Science # Principled AI Algorithms for challenging domains @Caltech\n10. Uncertainty in Deep Learning # longer versionï¼šNeurIPS 2020 Tutorial @Google AI Brain Team\nReturn a distribution over predictions rather than a single prediction Out-of-Distribution Robustness covariate shift: distribution of features changes open-set recognition: new classes may appear at test time label shift: distribution of label changes sources of uncertainty Model uncertainty è®¤çŸ¥ä¸Šçš„ä¸ç¡®å®šæ€§ Data uncertainty human disagreement label noise measurement noise missing data how to compute BDN GP Deep Ensemble MCMC multi-input and multi outputï¼ˆMIMOï¼‰ how to communicate with uncertainty? 7-10è®²å¾ˆä¸€èˆ¬ï¼Œä¸€ä¸ªå¤æ‚çš„ä¸»é¢˜ï¼Œéœ€è¦å°†èƒŒæ™¯è®²æ¸…æ¥šï¼Œå…¬å¸è®²ä¸œè¥¿ä¹Ÿæ²¡å•¥å…·ä½“ç»†èŠ‚ã€‚\nRef # ã€åŒè¯­å­—å¹•ã€‘MITã€Šæ·±åº¦å­¦ä¹ å¯¼è®º(6.S191)ã€‹è¯¾ç¨‹(2021)_å“”å“©å“”å“©_bilibili introtodeeplearning.com MIT 6.S191: Deep Generative Modeling - YouTube ","date":"13 January 2023","permalink":"/posts/20230113-introduction-deep-learning/","section":"Posts","summary":"","title":"MIT 6.S91 Introduction Deep Learning Notes"},{"content":" Introduction # å¤§æ•°æ®è®©å¤æ‚æ¨¡å‹çš„ä¼˜åŠ¿æ˜æ˜¾ æå‡ºä¸€ç§æ–°é¢–ç»Ÿä¸€çš„æ–¹æ³•ç”¨äºæ¨¡å‹è§£é‡Š ç”¨æ¨¡å‹çš„æ–¹æ³•æ¥è§£é‡Šå¤æ‚æ¨¡å‹ï¼ˆç”¨é­”æ³•æ‰“è´¥é­”æ³•ï¼‰ æå‡ºSHAPå€¼ä½œä¸ºå„ç§æ–¹æ³•è¿‘ä¼¼ç»Ÿä¸€ç‰¹å¾é‡è¦åº¦åº¦é‡ æå‡ºæ–°çš„SHAPå€¼ä¼°è®¡æ–¹æ³• Interpretation model properties # æè¿°è§£é‡Šæ¨¡å‹éœ€è¦æœ‰çš„ä¸‰ä¸ªæ€§è´¨ï¼Œè€Œç°åœ¨è§£é‡Šæ–¹æ³•çš„ç¼ºé™·æœ‰å“ªäº›1\nå±€éƒ¨å‡†ç¡®æ€§ï¼šå¦‚æœxâ€˜æ˜¯xçš„ç®€åŒ–ç‰¹å¾ï¼Œå¯¹åº”è§£é‡Šæ¨¡å‹g(x\u0026rsquo;) = f(x)ï¼Œå³è§£é‡Šæ¨¡å‹åœ¨ç»™å®šçš„ç‰¹å¾æƒ…å†µä¸‹èƒ½è§£é‡Šä¸ºä»€ä¹ˆæ¨¡å‹é¢„æµ‹å€¼æ˜¯è¿™ä¹ˆå¤šã€‚ ç¼ºå¤±æ€§ï¼šå½“x\u0026rsquo;=0çš„æ—¶å€™ï¼Œè´¡çŒ®åº¦$\\phi$ä¸º0 ä¸€è‡´æ€§ï¼šæ¨¡å‹æ”¹å˜å¯¼è‡´ç‰¹å¾å˜çš„æ›´é‡è¦æ—¶ï¼Œè´¡çŒ®åº¦ä¹Ÿåº”è¯¥å˜å¤§ Additive Feature Attribution methods # ä¸€å¤§ç±»æ–¹æ³•ä¸­è§£é‡Šæ¨¡å‹æ˜¯ä¸€ç³»åˆ—äºŒå…ƒå˜é‡çš„çº¿æ€§å‡½æ•° ç§°ä¸ºAdditive Feature Attribution methodsï¼ˆAFAï¼‰ç›¸åŠ ç‰¹å¾å½’å› æ–¹æ³• $$g(z\u0026rsquo;) = \\phi_0 + \\sum_{i=1}^{M}\\phi_i z\u0026rsquo;_{i}$$ $z\u0026rsquo; \\in {0, 1}^M$\nClassic Shapley Value Estimation # $$\\phi_{i} = \\sum_{S \\subseteq F\\backslash{i}}\\frac{|S|!(|F|-|S|-1)!}{|F|!}[f_{S\\cup{i}}(x_{S\\cup{i}})-f_{S(x_S)}]$$ åŸºäºä¸Šé¢å…¬å¼ç²¾ç¡®è®¡ç®—å¾ˆéº»çƒ¦ï¼Œç‰¹å¾çš„æ’åˆ—æœ‰$2^F$ç§ï¼Œè®¡ç®—é‡å·¨å¤§\nSHAP # SHAPåˆ†ä¸ºæ¨¡å‹æ— å…³å’Œæ¨¡å‹ç›¸å…³ä¸¤ç±»æ–¹æ³•ç”¨æ¥è¿‘ä¼¼æ±‚è§£ï¼Œæ¨¡å‹æ— å…³çš„ä»£è¡¨æ˜¯kernelSHAPï¼Œè€Œæ¨¡å‹ç›¸å…³çš„ä»£è¡¨åˆ™æœ‰DeepSHAPå’ŒTreeSHAPï¼Œä¸€ä¸ªæ˜¯é’ˆå¯¹æ·±åº¦å­¦ä¹ ï¼Œä¸€ä¸ªæ˜¯é’ˆå¯¹æ ‘æ¨¡å‹ã€‚\nKernel SHAP # LIME # LIME2ï¼ˆLocal interpretable model-agnostic explanations)ï¼ˆwhy should I trust you: Explaining the predictions of any classifierï¼‰é€šè¿‡ç”Ÿæˆçš„åŒ…å«éœ€è¦è§£é‡Šç‚¹å‘¨å›´çš„æ‰°åŠ¨æ•°æ®å’ŒåŸºäºé»‘ç®±æ¨¡å‹é¢„æµ‹ç»“æœçš„æ•°æ®é›†ï¼Œè®­ç»ƒä¸€ä¸ªå¯ä»¥è§£é‡Šçš„æ¨¡å‹ï¼Œæ¯”å¦‚é€»è¾‘å›å½’ã€å†³ç­–æ ‘ï¼Œè¿™ä¸ªå¯è§£é‡Šæ¨¡å‹éœ€è¦åœ¨è§£é‡Šç‚¹å‘¨å›´è¾¾åˆ°è¾ƒå¥½çš„æ•ˆæœã€‚ $$\\xi = \\mathop{\\arg\\min}\\limits_{g\\in G}L(f,g,\\pi_x) + \\Omega(g)$$\nfä¸ºéœ€è§£é‡Šæ¨¡å‹ gä¸ºå¯èƒ½çš„è§£é‡Šæ¨¡å‹ $\\pi_x$ä¸ºå®šä¹‰å®ä¾‹å‘¨å›´å¤šå¤§èŒƒå›´ ç®—æ³•è¿‡ç¨‹ï¼š\né€‰æ‹©éœ€è¦è§£é‡Šæ„Ÿå…´è¶£çš„å®ä¾‹ å¯¹å…¶è¿›è¡Œæ‰°åŠ¨ï¼Œå¹¶å¾—åˆ°é»‘ç®±æ¨¡å‹å¯¹åº”ç»“æœäº§ç”Ÿæ–°æ•°æ®é›† æ ¹æ®ä¸å®ä¾‹çš„æ¥è¿‘ç¨‹åº¦ï¼Œå¯¹æ–°æ•°æ®é›†è¿›è¡Œèµ‹äºˆæƒé‡ åŸºäºæ–°æ•°æ®é›†å’Œä¸Šè¿°æŸå¤±å‡½æ•°æ±‚è§£å¯è§£é‡Šæ¨¡å‹ è§£é‡Šé¢„æµ‹å€¼ Figure 3: Toy example to present intuition for LIME KernelSHAPï¼ˆLinear LIME + Shapley valueï¼‰ # LIMEï¼ˆLocal interpretable model-agnostic explanationsï¼‰æ–¹æ³•çš„æ‹“å±•ï¼Œé€šè¿‡ä¿®æ”¹LIMEéœ€è¦æ±‚è§£lossç­‰å¼å‚æ•°ï¼Œå…¶ä¸»è¦æ€è·¯æ˜¯åˆ©ç”¨æ ¸å˜æ¢ï¼Œè®©$\\phi$ç¬¦åˆshapley value3 ç®—æ³•è¿‡ç¨‹4ï¼š\næ ¹æ®$z_k^{\u0026rsquo;} \\in {0, 1}^M$é€‰æ‹©kä¸ªæ ·æœ¬ å°†$z_k^{\u0026rsquo;} \\in {0, 1}^M$è½¬åŒ–ä¸ºåŸå§‹ç‰¹å¾å€¼å¹¶è®¡ç®—é»‘ç®±æ¨¡å‹é¢„æµ‹å€¼ åŸºäºSHAP kernelè®¡ç®—$z_k^{\u0026rsquo;}$ æ ·æœ¬æƒé‡ï¼Œ$z_k$é‡Œé¢1çš„ä¸ªæ•°ä¸ä¸€æ ·æƒé‡å°±ä¸ä¸€æ · æ‹Ÿåˆçº¿æ€§æ¨¡å‹ ä»çº¿æ€§æ¨¡å‹ä¸­è¿”å›Shapley values SHAPæ ¸ä¸º(æ¨å¯¼è¿‡ç¨‹è§2è¡¥å……ææ–™)ï¼š $$\\pi_{x\u0026rsquo;}(z\u0026rsquo;)= \\frac{(M-1)}{(M choose |z\u0026rsquo;|)|z\u0026rsquo;|(M-|z\u0026rsquo;|)}$$ $$L(f,g, \\pi_{x\u0026rsquo;})=\\sum_{z\u0026rsquo;\\in Z}[f(h_x^{-1}(z\u0026rsquo;))-g(z\u0026rsquo;)]^2\\pi_{x\u0026rsquo;}(z\u0026rsquo;)$$ x\u0026rsquo;ä¸ºç®€åŒ–è¾“å…¥ï¼Œ$x=h_x(x\u0026rsquo;)$, $z\u0026rsquo; \\subseteq x\u0026rsquo;$ å…¶ä¸­ç¬¬äºŒæ­¥ï¼šThe functionÂ hÂ maps 1â€™s to the corresponding value from the instance x that we want to explain. For tabular data, it maps 0â€™s to the values of another instance that we sample from the data. This means that we equate â€œfeature value is absentâ€ with â€œfeature value is replaced by random feature value from dataâ€. Deep SHAP # DeepLIFTï¼ˆLearning Important FeaTuresï¼‰ # DeepLIFT5æ–¹æ³•ä½¿ç”¨ç¥ç»å…ƒçš„æ¿€æ´»ä¸å…¶â€œå‚è€ƒâ€è¿›è¡Œæ¯”è¾ƒï¼Œå…¶ä¸­å‚è€ƒæ˜¯ç¥ç»å…ƒåœ¨ç½‘ç»œè·å¾—â€œå‚è€ƒè¾“å…¥â€æ—¶å…·æœ‰çš„æ¿€æ´»çŠ¶æ€ï¼ˆå‚è€ƒè¾“å…¥æ ¹æ®å…·ä½“ä»»åŠ¡çš„å†…å®¹å®šä¹‰ï¼‰ã€‚è¯¥æ–¹æ³•èµ‹äºˆæ¯ä¸ªç‰¹å¾é‡è¦åº¦åˆ†æ•°ä¹‹å’Œç­‰äºé¢„æµ‹å€¼ä¸åŸºäºå‚è€ƒè¾“å…¥çš„é¢„æµ‹å€¼ä¹‹é—´çš„å·®å¼‚6ã€‚ èƒ½è§£å†³åŸºäºæ¢¯åº¦æ–¹æ³•çš„ä¸è¶³ï¼Œä¾‹å¦‚å‚è€ƒçš„å·®å¼‚ä¸æ˜¯0çš„æƒ…å†µä¸‹æ¢¯åº¦ä»ç„¶å¯èƒ½æ˜¯0ã€‚ $$\\sum_{i=1}^n C_{\\Delta x_i \\Delta t} = \\Delta t \\tag1$$ $\\Delta t = t - t^0$, ç¥ç»å…ƒè¾“å‡ºä¸å‚è€ƒè¾“å‡ºçš„å·®å¼‚ï¼Œ$\\Delta x$è¾“å…¥ç›¸å¯¹å‚è€ƒè¾“å…¥çš„å˜åŒ–ï¼Œ Cå³ç‰¹å¾çš„è´¡çŒ®\n$$m_{\\Delta x\\Delta t} = \\frac{C_{\\Delta x\\Delta t}}{\\Delta x} \\tag2$$ å®šä¹‰ä¹˜å­multiplierï¼Œæ»¡è¶³é“¾å¼æ³•åˆ™ ç®—æ³•æ­¥éª¤7ï¼š\nå®šä¹‰å‚è€ƒå€¼ choosing a good reference would rely on domain-specific knowledge, and in some cases it may be best to compute DeepLIFT scores against multiple different references æ¯”å¦‚å›¾åƒç”¨å…¨0æˆ–è€…æ¨¡ç³Šç‰ˆæœ¬ï¼ŒåŸºå› æ•°æ®ç”¨æœ¬åº•æœŸæœ›é¢‘ç‡ åŒºåˆ†æ­£è´Ÿè´¡çŒ®ï¼ˆ2019ï¼‰ è´¡çŒ®åº¦è§„åˆ™ çº¿æ€§å±‚ç›´æ¥æ˜¯ç³»æ•°$w* \\Delta x_i$ éçº¿æ€§å˜åŒ–æ˜¯$m_{\\Delta x\\Delta y} = \\frac{C_{\\Delta x\\Delta y}}{\\Delta x} =\\frac{\\Delta y}{\\Delta x}$ DeepSHAP(DeepLIFT + Shapley value) # å°½ç®¡kernelSHAPæ˜¯é€‚ç”¨äºæ‰€æœ‰æ¨¡å‹çš„åŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä¸€ç§å¯è§£é‡Šæ–¹æ³•ï¼Œä½†æ˜¯æœ‰æ²¡æœ‰èƒ½åˆ©ç”¨ç¥ç»ç½‘ç»œç‰¹æ€§çš„å¯è§£é‡Šæ–¹æ³•ä»è€Œæé«˜è®¡ç®—æ•ˆç‡ã€‚ DeepLIFTè®¡ç®—çš„åˆ†æ•°è¿‘ä¼¼äºShapley value?å¹¶ä¸æ˜¯è¿™ä¸ªæ€è·¯\nthe Shapely values measure the average marginal effect of including an input over all possible orderings in which inputs can be included. If we define â€œincludingâ€ an input as setting it to its actual value instead of its reference value, DeepLIFT can be thought of as a fast approximation of the Shapely values8 Though a variety of methods exist for estimating SHAP values, we implemented a modified version of the DeepLIFT algorithm, which computes SHAP by estimating differences in model activations during backpropagation relative to a standard reference. figure from ref[3] åŸºäºShapley valueçš„å®šä¹‰ä»¥åŠå…¬å¼å¯ä»¥çœ‹å‡ºé‡è¦çš„ä¸€éƒ¨åˆ†å³è¾¹é™…æ•ˆåº”ï¼Œå³æ¨¡å‹åŒ…å«è¯¥ç‰¹å¾å‡å»æœªåŒ…å«è¯¥éƒ¨åˆ†ã€‚åœ¨ä¸Šè¿°ä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å—é‡Œé¢ï¼Œç‰¹å¾é¡ºåºé€‰æ‹©éƒ½ä¸å­˜åœ¨ã€‚åœ¨è®¤ä¸ºåŒ…å«ç‰¹å¾å³ç›¸å¯¹äºå‚è€ƒè¾“å…¥æ˜¯çœŸå®è¾“å…¥çš„æƒ…å†µä¸‹ï¼ŒæŠŠåŒ…å«ç‰¹å¾åä¹˜å­ç›´æ¥é“¾å¼æ³•åˆ™åšä¸ºSHAPå€¼è¿‘ä¼¼å…¬å¼ åœ¨ä¸Šè¿°ç®€å•ç½‘ç»œç»„ä»¶é‡Œé¢ï¼Œè¾“å…¥åˆ°è¾“å‡ºä¹‹é—´å¯ä»¥çœ‹ä½œçº¿æ€§è¿‘ä¼¼ä»è€Œå¾—åˆ°å…¬å¼16 æŠŠç”¨å®é™…å€¼ä»£æ›¿å‚è€ƒå€¼çœ‹ä½œæ˜¯åŒ…å«æŸä¸ªç‰¹å¾ï¼ŒDeepLIFTæ–¹æ³•ä¸DeepSHAPä¼¼ä¹çœ‹ä¸åˆ°åŒºåˆ«? 6 â€“ Interpretability â€“ Machine Learning Blog | ML@CMU | Carnegie Mellon University\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nRibeiro, M. T., Singh, S. \u0026amp; Guestrin, C. â€˜Why Should I Trust You?â€™: Explaining the Predictions of Any Classifier. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 1135â€“1144 (2016) doi:10.1145/2939672.2939778.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nA Unified Approach to Interpreting Model Predictions\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n9.6 SHAP (SHapley Additive exPlanations) | Interpretable Machine Learning\u0026#160;\u0026#x21a9;\u0026#xfe0e;\ndeeplift 0.6.13.0 on PyPI - Libraries.io\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nExplainable Neural Networks: Recent Advancements, Part 3 | by G Roshan Lal | Towards Data Science\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nShrikumar, A., Greenside, P., Shcherbina, A. \u0026amp; Kundaje, A. Not Just a Black Box: Learning Important Features Through Propagating Activation Differences. Preprint at https://doi.org/10.48550/arXiv.1605.01713 (2017).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nShrikumar, A., Greenside, P. \u0026amp; Kundaje, A. Learning Important Features Through Propagating Activation Differences. Preprint at http://arxiv.org/abs/1704.02685 (2019).\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"6 January 2023","permalink":"/posts/20230106-shap/","section":"Posts","summary":"","title":"ã€ŠA Unified Approach to interpreting Model Predictionsã€‹è®ºæ–‡è§£è¯»"},{"content":"","date":"6 January 2023","permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"machine learning"},{"content":"","date":"6 January 2023","permalink":"/tags/shap/","section":"Tags","summary":"","title":"SHAP"},{"content":"I am currently an engineer of Center for Artificial Intelligence In Medicine in a Hospital. My research focuses on three areas:\nSecondary analysis EHRs Wearable device data analysis Multimodal fusion learning in healthcare ","date":"3 November 2022","permalink":"/about/","section":"","summary":"I am currently an engineer of Center for Artificial Intelligence In Medicine in a Hospital.","title":"About"},{"content":"","date":"14 August 2020","permalink":"/tags/friends/","section":"Tags","summary":"","title":"friends"},{"content":" å‹é“¾ä»¥åŠå€¼å¾—å…³æ³¨çš„å¤§ç‰›ï¼ Website Details Irene Y. Chen Irene study machine learning for equitable healthcare want to be a friend? To add your site to this list, please fell free to email me\n","date":"14 August 2020","permalink":"/people/","section":"","summary":"","title":"Friends"},{"content":"","date":"14 August 2020","permalink":"/tags/people/","section":"Tags","summary":"","title":"people"},{"content":"","date":"1 April 2020","permalink":"/tags/pytorch/","section":"Tags","summary":"","title":"pytorch"},{"content":" Deep Learning = Learning Hierarchical Representations æ·±åº¦å­¦ä¹ å³å­¦ä¹ å±‚æ¬¡çš„è¡¨å¾ã€‚ 1. å·ç§¯ç¥ç»ç½‘ç»œ # 1.1 ç¥ç»ç½‘ç»œå¯è§†åŒ–ï¼ˆVisualization of neural networksï¼‰ # ç¥ç»ç½‘ç»œæ¯ä¸€å±‚çš„æ“ä½œæœ‰ç‚¹åƒå°†ç©ºé—´æŸäº›åŒºåŸŸè¿›è¡ŒæŠ˜å \n1.2 å·ç§¯ç¥ç»ç½‘ç»œçš„èµ·æºï¼ˆConvolutional Neural Networkï¼›CNNï¼‰ # å—åˆ°Fukushimaåœ¨è§†è§‰çš®å±‚å»ºæ¨¡æ–¹é¢çš„å¯å‘ï¼Œä½¿ç”¨ç®€å•/å¤æ‚çš„ç»†èƒå±‚æ¬¡ç»“æ„ï¼Œç»“åˆæœ‰ç›‘ç£çš„è®­ç»ƒå’Œåå‘ä¼ æ’­ï¼Œç”±Yann LeCunæ•™æˆäº88-89å¹´åœ¨å¤šä¼¦å¤šå¤§å­¦å¼€å‘äº†ç¬¬ä¸€ä¸ªCNNã€‚\nFukushimaçš„å·¥ä½œå…·ä½“æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ\næ‰‹å†™æ•°å­—è¯†åˆ«ã€‚é¦–æ¬¡æå‡ºåº”ç”¨å¤šå±‚ç®€å•æˆ–è€…å¤æ‚çš„ç»†èƒç»“æ„å»ºæ¨¡ï¼Œç‰¹å¾ï¼šæ‰‹å·¥åŠ æ— ç›‘ç£èšç±»å­¦ä¹ ã€‚æ— åå‘ä¼ æ’­ã€‚\n1.3 å·ç§¯ç¥ç»ç½‘ç»œåˆ†è§£ # é€šç”¨çš„CNNæ¶æ„èƒ½è¢«åˆ†è§£ä¸ºä»¥ä¸‹å‡ ä¸ªåŸºæœ¬ç»“æ„ã€‚\næ ‡å‡†åŒ–ï¼ˆNormalisationï¼‰:å¯¹æ¯”åº¦æ ‡å‡†åŒ–ç­‰ æ»¤æ³¢å™¨ç»„ï¼ˆFilter banksï¼‰:è¾¹ç¼˜æ£€æµ‹ç­‰ éçº¿æ€§åŒ–ï¼ˆNon-linearitiesï¼‰:ç¨€ç–åŒ–ã€ReLUç­‰ æ± åŒ–ï¼ˆpoolingï¼‰:æœ€å¤§æ± åŒ–ï¼ˆmax poolingï¼‰ç­‰ 2. è‡ªç„¶ä¿¡å·æ•°æ®ï¼ˆNatural Signalsï¼‰ # 2.1 è‡ªç„¶ä¿¡å·æ•°æ®ç‰¹æ€§ # å‘¨æœŸæ€§ï¼šåœ¨æ—¶åŸŸå¾ˆå¤šæ¨¡å¼éƒ½ä¼šé‡å¤å‡ºç° å±€éƒ¨æ€§ï¼šç›¸é‚»çš„ç‚¹è¾ƒç›¸è¿œçš„ç‚¹æ¥è¯´æ›´å…·å…³è”æ€§ åˆæˆæ€§ï¼šå¤æ‚çš„äº‹ç‰©å¯ä»¥ç”±ç®€å•çš„äº‹ç‰©ç»„åˆè€Œæˆã€‚å­—æ¯-\u0026gt;å•è¯-\u0026gt;å¥å­-\u0026gt;æ–‡ç«  2.2 å¯¹åº”ç¥ç»ç½‘ç»œä¸­çš„å¤„ç†æ–¹æ³• # å‘¨æœŸæ€§$\\rightarrow$å‚æ•°å…±äº«\nå¦‚æœæ•°æ®å­˜åœ¨å‘¨æœŸæ€§ï¼Œå¯ä»¥ä½¿ç”¨å‚æ•°å…±äº«ï¼Œå³å·ç§¯æ ¸ã€‚ å±€éƒ¨æ€§$\\rightarrow$ç¨€ç–\nå¦‚æœæ•°æ®å­˜åœ¨å±€éƒ¨æ€§ï¼Œé‚£ä¹ˆæ¯ä¸ªç¥ç»å…ƒåªéœ€è¦ä¸å‰å‡ ä¸ªç¥ç»å…ƒè¿æ¥ åˆæˆæ€§$\\rightarrow$å¤šå±‚\nå³ç¥ç»ç½‘ç»œä¸­å¤šå±‚ç½‘ç»œåˆæˆæœ€ç»ˆçš„ç»“æœ 3. Pytorchå®ç°Mnistæ‰‹å†™å­—è¯†åˆ« # # load package and data import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim from torchvision import datasets, transforms import matplotlib.pyplot as plt device = torch.device(\u0026#34;cuda:0\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34;) # ç¥ç»ç½‘ç»œæ¨¡å‹åçˆ±æ ‡å‡†åŒ–æ•°æ®ï¼ŒåŸå› æ˜¯å‡å€¼ä¸º0æ–¹å·®ä¸º1çš„æ•°æ®åœ¨sigmoidã€tanhç»è¿‡æ¿€æ´»å‡½æ•°åæ±‚å¯¼å¾—åˆ°çš„å¯¼æ•°å¾ˆå¤§ï¼Œ # åä¹‹åŸå§‹æ•°æ®ä¸ä»…åˆ†å¸ƒä¸å‡ï¼ˆå™ªå£°å¤§ï¼‰è€Œä¸”æ•°å€¼é€šå¸¸éƒ½å¾ˆå¤§ï¼ˆæœ¬ä¾‹ä¸­æ•°å€¼èŒƒå›´æ˜¯0~255ï¼‰ï¼Œæ¿€æ´»å‡½æ•°åæ±‚å¯¼å¾—åˆ°çš„å¯¼æ•° # åˆ™æ¥è¿‘ä¸0ï¼Œè¿™ä¹Ÿè¢«ç§°ä¸ºæ¢¯åº¦æ¶ˆå¤±ã€‚ # ç›®å½•æ”¾è‡ªå·±ä¸‹è½½å¥½çš„mnistç›®å½•ï¼Œæ²¡æœ‰ä¸‹è½½å°†download=True,è‡ªå·±æ–°å»ºä¸€ä¸ªå­˜æ”¾æ•°æ®ç›®å½•å³å¯ train_loader = torch.utils.data.DataLoader( datasets.MNIST(\u0026#39;../LSTM_mnist/mnist\u0026#39;, train=True, download=False, transform=transforms.Compose([ transforms.ToTensor(), # mnistæ•°æ®é›†å‡å€¼0.1307ï¼Œæ ‡å‡†å·®0.3081 transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True) test_loader = torch.utils.data.DataLoader( datasets.MNIST(\u0026#39;../LSTM_mnist/mnist\u0026#39;, train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=1000, shuffle=True) # define model class SimpleCNN(nn.Module): def __init__(self, input_size, n_feature, output_size): super(SimpleCNN, self).__init__() self.n_feature = n_feature # å…³äºnn.Conv2d()ä¸­å‚æ•°çš„è§£é‡Š # in_channels (int): Number of channels in the input image # out_channels (int): Number of channels produced by the convolution # kernel_size (int or tuple): Size of the convolving kernel # default stride=1, padding=0, dilation=1, groups=1 # [groupscå‚æ•°è¯¦è§£](https://www.jianshu.com/p/20ba3d8f283c) # [å›¾è§£å·ç§¯ç¥ç»ç½‘ç»œä¸­stride, paddingç­‰æ“ä½œå¯è§†åŒ–](https://github.com/vdumoulin/conv_arithmetic) # input: (N, C_in, H_in, W_in) self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5) self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5) self.fc1 = nn.Linear(n_feature*4*4, 50) self.fc2 = nn.Linear(50, 10) def forward(self, x): x = self.conv1(x) # Mnistæ•°æ®åŸå§‹å¤§å°ï¼ˆ28*28ï¼‰28-5+1 = 24 (24*24*n_feature) x = F.relu(x) x = F.max_pool2d(x, kernel_size=2) # (12*12*n_feature) x = self.conv2(x) # 12-5+1 = 8 (8*8*n_feature) x = F.relu(x) x = F.max_pool2d(x, kernel_size=2) # (4*4*n_feature)è¿™é‡Œè§£é‡Šäº†ä¸Šé¢å…¨è¿æ¥æ—¶ä¸ºå•¥æ˜¯4*4 x = x.view(-1, self.n_feature*4*4) x = self.fc1(x) x = F.relu(x) x = self.fc2(x) x = F.log_softmax(x, dim=1) return x # hyper parameters epochs = 1 input_size = 28*28 output_size = 10 n_features = 6 lr = 0.01 model = SimpleCNN(input_size, n_features, output_size) model.to(device) # optimizer optimizer = optim.SGD(model.parameters(), lr, momentum=0.5) print(\u0026#39;Number of parameters: {}\u0026#39;.format(get_n_params(model))) # model train for epoch in range(epochs): model.train() for i, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) output = model(data) loss = F.nll_loss(output, target) optimizer.zero_grad() loss.backward() optimizer.step() if i % 100 == 0: print(\u0026#39;Train Epoch [{}/{}], [{}/{} ({:.0f}%)], Loss: {:.4f}\u0026#39;.format( epoch+1, epochs, i*len(data), len(train_loader.dataset), 100*i/len(train_loader), loss.item())) # model eval model.eval() test_loss = 0 correct = 0 accuracy_list = [] for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) test_loss += F.nll_loss(output, target, reduction=\u0026#39;sum\u0026#39;).item() pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability correct += pred.eq(target.data.view_as(pred)).cpu().sum().item() test_loss /= len(test_loader.dataset) accuracy = 100. * correct / len(test_loader.dataset) accuracy_list.append(accuracy) print(\u0026#39;\\nTest set Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\u0026#39;.format( test_loss, correct, len(test_loader.dataset), accuracy)) # å‡ ä¸ªé¢„æµ‹çš„å®ä¾‹å¯è§†åŒ– for i in range(10): plt.subplot(2, 5, i+1) plt.imshow(data[i][0]) plt.title(\u0026#34;Prediction: {}\u0026#34;.format( output.data.max(1, keepdim=True)[1][i].item())) plt.show() 4. è¡¥å…… # å¯ä»¥åšä¸€ä¸ªæœ‰è¶£çš„å®éªŒå³æ‰“ä¹±å›¾ç‰‡ä¸­çš„åƒç´ åCNNè¯†åˆ«æ­£ç¡®ç‡ä¸‹é™ï¼Œè€Œå…¨è¿æ¥ç½‘ç»œåˆ™ä¸ä¼šï¼Œå³ä¸æœ€å¼€å§‹æåˆ°çš„ä¸‰ä¸ªç‰¹æ€§ä»¥åŠå¯¹äºç¥ç»ç½‘ç»œé‡‡å–çš„å‡è®¾æ˜¯å»åˆçš„ã€‚ å‚è€ƒ2ä¸­æ˜¯å¯¹å·ç§¯ç¥ç»ç½‘ç»œå…¨é¢çš„ä»‹ç»ï¼ŒåŒ…æ‹¬CNNä¸­å¸¸ç”¨é‚£äº›å±‚ï¼Œä»¥åŠå¸¸ç”¨çš„æ¨¡å‹å’Œå‚æ•°å¤šå°‘è®¡ç®—ã€‚ ref # NYC PyTorch Deep Learningè¯¾ç¨‹ç½‘ç«™ cs231n convolutional networks pytorchå®˜æ–¹æ–‡æ¡£Conv2d è¯¾ç¨‹convnet.ipynb ","date":"1 April 2020","permalink":"/posts/20200401-pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/","section":"Posts","summary":"","title":"PyTorchæ·±åº¦å­¦ä¹ ï¼ˆ2ï¼‰"},{"content":"","date":"23 March 2020","permalink":"/tags/xgboost/","section":"Tags","summary":"","title":"xgboost"},{"content":" åœ¨ä½¿ç”¨xgboostæ–¹æ³•è°ƒå‚æ—¶ï¼Œå¯¹å…¶ä¸­ä¸ªåˆ«å‚æ•°ä¸æ˜¯ç‰¹åˆ«ç†è§£ã€‚æ•…é‡æ–°è¯»äº†ä¸€éåŸè®ºæ–‡ã€‚\n1. å¼•è¨€ # é˜è¿°æœºå™¨å­¦ä¹ å’Œæ•°æ®é©±åŠ¨çš„æ–¹æ³•åº”ç”¨æ—¶ä¸¤ä¸ªé‡è¦çš„å› ç´ ï¼š\nèƒ½æ•æ‰æ•°æ®é—´å¤æ‚ä¾èµ–å…³ç³»çš„æ¨¡å‹ å¯æ‰©å±•çš„å­¦ä¹ ç³»ç»Ÿï¼Œå¯ä»¥ä»å¤§é‡æ•°æ®ä¸­å­¦ä¹  åœ¨ç›®å‰å¸¸ç”¨çš„æ–¹æ³•ä¸­ï¼Œæ¢¯åº¦æå‡æ ‘ï¼ˆgradient tree boostingï¼‰åœ¨è®¸å¤šåœºæ™¯ä¸­æ•ˆæœéƒ½ä¸é”™ï¼Œä½œè€…åˆ—ä¸¾äº†ä¸€äº›ã€‚æå‡ºxgboostæ–¹æ³•åœ¨æ¯”èµ›ä»¥åŠå„ç±»é—®é¢˜ä¸­çš„åº”ç”¨ã€‚\nå™è¿°XGBoostçš„ä¼˜ç‚¹ï¼šè¿è¡Œæ›´å¿«ã€æ‹“å±•æ€§æ›´å¥½ã€‚åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š\né«˜åº¦å¯æ‹“å±•çš„ç«¯åˆ°ç«¯æå‡æ ‘ï¼ˆtree boostingï¼‰ç³»ç»Ÿ ç”¨äºé«˜æ•ˆè®¡ç®—çš„åŠ æƒåˆ†ä½æ•°å›¾ï¼ˆweighted quantile sketchï¼‰ æ–°é¢–çš„ç¨€ç–æ„ŸçŸ¥ç®—æ³•ï¼ˆsparsity-aware algorithmï¼‰ï¼Œç”¨äºå¹¶è¡Œæ ‘å­¦ä¹  æœ‰æ•ˆçš„ç¼“å­˜ä¼˜åŒ–ä»¥åŠå—ï¼ˆcache-aware blockï¼‰ç»“æ„ç”¨äºå¤–å­˜ï¼ˆout-of-coreï¼‰æ ‘å­¦ä¹  å…³äºä»¥ä¸Šå‡ ç‚¹åœ¨æ­£æ–‡ä¸­è¯¦è§£ã€‚ è®ºæ–‡ç»“æ„ï¼š\næå‡æ ‘ï¼ˆtree boostingï¼‰ç®€ä»‹ä»¥åŠç›®æ ‡å‡½æ•°æ­£åˆ™åŒ– åˆ†è£‚ç‚¹å¯»æ‰¾çš„æ–¹æ³• ç³»ç»Ÿè®¾è®¡ï¼ŒåŒ…æ‹¬ä¸ºæ¯ä¸ªä¼˜åŒ–æä¾›é‡åŒ–æ”¯æŒçš„ç»“æœ ç›¸å…³å·¥ä½œ è¯¦ç»†çš„ç«¯åˆ°ç«¯è¯„ä¼° æ€»ç»“ 2. æå‡æ ‘ï¼ˆTree Boostingï¼‰ç®€ä»‹ # é¦–å…ˆéœ€è¦äº†è§£CARTï¼ˆClassification And Regression Treeï¼‰ç®—æ³•ï¼Œå¯¹äºcartåˆ†ç±»æ ‘å’Œå›å½’æ ‘åˆ†åˆ«é‡‡ç”¨äº†ï¼šGiniç³»æ•°ã€å’Œæ–¹å·®åº¦é‡æ–¹å¼æ¥åˆ’åˆ†èŠ‚ç‚¹[1]ã€‚ä¾‹å¦‚å›å½’æ ‘ï¼Œå¯¹äºåˆ’åˆ†ç‰¹å¾A, åˆ’åˆ†ç‚¹sä½¿ä¸¤è¾¹æ•°æ®é›†D1å’ŒD2,æ±‚å‡ºä½¿ D1å’ŒD2å„è‡ªé›†åˆçš„å‡æ–¹å·®æœ€å°ï¼ŒåŒæ—¶D1å’ŒD2çš„å‡æ–¹å·®ä¹‹å’Œæœ€å°ã€‚ $$\\underline{min}_{\\text{A,s}}[\\underline{min}_{\\text{c1}}\\sum_{x_i\\in{D1(A,s)}}(y_i - c1)^2+\\underline{min}_{\\text{c2}}\\sum_{x_i\\in{D2(A,s)}}(y_i - c2)^2]$$ å…¶ä¸­ï¼Œc1ä¸ºD1çš„æ ·æœ¬è¾“å‡ºå‡å€¼ï¼Œc2ä¸ºD2çš„æ ·æœ¬è¾“å‡ºå‡å€¼, å›å½’æ ‘é‡‡ç”¨å¶å­èŠ‚ç‚¹çš„å‡å€¼æˆ–è€…ä¸­ä½æ•°æ¥é¢„æµ‹è¾“å‡ºç»“æœï¼Œ$y_i$å³æ ·æœ¬çš„labelï¼Œæ­¤æ—¶çš„è¾“å‡ºå€¼å³ä¸‹æ–‡ä¸­ç”¨åˆ°çš„$w_{q(x)}$ã€‚\n2.1 æ­£åˆ™åŒ–ç›®æ ‡å‡½æ•° # å¯¹äºè¿™ç§ç±»å‹çš„é›†æˆæ ‘æ¨¡å‹ï¼Œç”¨Kæ£µæ ‘çš„ç»“æœæ¥é¢„æµ‹æœ€åçš„ç»“æœï¼ˆå¼1ï¼‰ï¼Œé‚£ä¹ˆé—®é¢˜æ¥äº†æˆ‘ä»¬æ€ä¹ˆæ¥æ±‚è¿™äº›æ ‘çš„å‚æ•°ï¼Œæ¯æ£µæ ‘éƒ½å¯ä»¥çœ‹åšä¸€ä¸ªå‡½æ•°$f_i$åŒ…å«æ ‘çš„ç»“æ„ä»¥åŠæœ€åå¶èŠ‚ç‚¹æƒé‡ï¼Œé›†æˆæ¨¡å‹ä¸åƒä¼ ç»Ÿä¼˜åŒ–é—®é¢˜ä¸€æ ·é€šè¿‡ç®€å•ç”¨æ¢¯åº¦ä¸‹é™å¯ä»¥å¯¹æ‰€æœ‰çš„æ ‘è¿›è¡Œå­¦ä¹ æ±‚è§£ï¼Œæ‰€ä»¥ï¼Œåœ¨è¿™é‡Œç”¨åˆ°äº†åŠ æ³•ç­–ç•¥ï¼Œå³å›ºå®šå·²ç»å­¦ä¹ åˆ°çš„ï¼Œæ¯æ¬¡åŠ ä¸€æ£µæ ‘æ¥è¿›è¡Œå­¦ä¹ ï¼ˆå¼3ï¼‰ã€‚ $$\\hat{y_i} = \\phi(x_i) = \\sum_{k = 1}^{K} f_k(x_i)\\tag1$$ å…¶ä¸­$f(x) = w_{q(x)}$ï¼Œæ¯ä¸ª$f_k$å¯¹åº”ä¸€ä¸ªç‹¬ç«‹çš„æ ‘ç»“æ„qä»¥åŠå…¶å¶èŠ‚ç‚¹æƒé‡wï¼Œä¸ºäº†å­¦ä¹ æ¨¡å‹ä¸­çš„å‚æ•°ï¼Œæœ€å°åŒ–ä¸‹é¢æ­£åˆ™åŒ–çš„ç›®æ ‡å‡½æ•°ã€‚ $$L(\\phi) = \\sum_i l(\\hat{y_i}, y_i) + \\sum_k \\Omega(f_k)\\tag2$$\n$$\\Omega(f_k) = \\gamma T + \\frac{1}{2}\\lambda||w||^2$$ Tæ˜¯æ ‘çš„å¶èŠ‚ç‚¹æ•°\n2.2 æ¢¯åº¦æå‡æ ‘ï¼ˆGradient Tree Boostingï¼‰ # ç¬¬tæ¬¡é¢„æµ‹å€¼ç­‰äºt-1åŠ ä¸Šç¬¬tæ£µæ ‘çš„ç»“æœ $$\\hat{y_i} = \\hat{y_i}^{t-1} + f_t(x_i)\\tag3$$ æ­¤æ—¶ç›®æ ‡å‡½æ•°(å¼2)å¯ä»¥å†™æˆ $$L^{(t)} = \\sum_{i=1} ^n l(y_i, \\hat{y_i}^{(t-1)}+f_t(x_i)) + \\Omega(f_t)\\tag4$$ è¯¥å¼å­çš„äºŒé˜¶è¿‘ä¼¼å¯ä»¥è¡¨è¾¾ä¸º(å¼5ï¼‰ï¼Œå¯ä»¥å‚è€ƒè¡¥å……ä¸­äºŒé˜¶æ³°å‹’å±•å¼€çš„ä¸€èˆ¬å½¢å¼ $$L^{(t)} \\approx \\sum_{i=1} ^n [l(y_i, \\hat{y_i}^{(t-1)}) + g_if_t(x_i) + \\frac{1}{2}h_if_t^2(x_i)]+\\Omega(f_t)\\tag5$$ å…¶ä¸­ $g_i=\\partial_{\\hat{y}^{(t-1)}}{l(y_i, \\hat{y_i}^{(t-1)})}ï¼Œ h_i=\\partial_{\\hat{y}^{(t-1)}}^2{l(y_i, \\hat{y_i}^{(t-1)})}$\nå¼5ä¸­å»æ‰å¸¸æ•°é¡¹ï¼Œå³labelä¸ç¬¬t-1æ¬¡ç»“æœçš„æŸå¤±å‡½æ•°ï¼Œå¯ä»¥å¾—åˆ°ï¼š\n$$\\sum_{i=1}^n[g_if_t(x_i)+\\frac{1}{2}h_if_t^2(x_i)]+\\Omega(f_t)\\tag6$$\nå¼6å³å¯¹æ–°æ ‘çš„ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œè¿›ä¸€æ­¥åˆå¹¶å¯ä»¥å†™ä¸ºï¼š\n$$obj^{t} \\approx \\sum_{i=1}^{n}[g_i w_{q(x_i)} + \\frac{1}{2}h_i w^2_{q(x_i)}] + \\gamma T+ \\frac{1}{2}\\lambda \\sum _{j=1}^T w_j^2$$\nå®šä¹‰$I_j = {i|q(x_i)=j}$å³å¶èŠ‚ç‚¹jä¸Šçš„å®ä¾‹ã€‚\n$$obj^{t} \\approx \\sum_{j=1}^T[(\\sum_{i\\in{I_j}}g_i)w_j+\\frac{1}{2}(\\sum_{i\\in{I_j}}h_i+\\lambda)w_j^2]+\\gamma T\\tag7$$\nä¸Šå¼7å¯¹$w_j$æ±‚å¯¼å³å¯æ±‚å‡ºwæœ€ä¼˜å€¼\n$$w_j^* = -\\frac{\\sum_{i\\in{I_j}}g_i}{\\sum_{i\\in{I_j}}h_i+\\lambda} $$\nä»¤$G_j = \\sum_{i\\in{I_j}}g_iï¼ŒH_j=\\sum_{i\\in{I_j}}h_i$\næ­¤æ—¶ï¼Œå¯¹åº”çš„æœ€å°å€¼ä¸º: $$obj^* = -\\frac{1}{2}\\sum_{j=1}^T\\frac{G_j^2}{H_j+\\lambda}+\\gamma T$$ $\\color{red}\\frac{G_j^2}{H_j+\\lambda}$è¶Šå¤§ï¼Œlossè¶Šå°ï¼Œæ‰€ä»¥å¯¹å¶èŠ‚ç‚¹è¿›è¡Œåˆ†è£‚ï¼Œåˆ†è£‚åå¢ç›Šå®šä¹‰ä¸º $$Gain=\\frac{1}{2}[\\frac{G_L^2}{H_L+\\lambda}+\\frac{G_R^2}{H_R+\\lambda}-\\frac{(G_L+G_R)^2}{H_L+H_R+\\lambda}]-\\gamma\\tag8$$\n2.3 ç¼©å‡å’Œåˆ—æŠ½æ ·ï¼ˆShrinkage and Column Subsamplingï¼‰ # é™¤äº†åœ¨ç›®æ ‡å‡½æ•°ä¸­å¼•å…¥æ­£åˆ™é¡¹ï¼Œåœ¨é˜²æ­¢è¿‡æ‹Ÿåˆæ–¹é¢xgboostè¿˜è¿ç”¨äº†ä¸¤é¡¹æŠ€æœ¯ï¼Œç»™æ¯ä¸€æ­¥tree boostingå¾—åˆ°çš„ç»“æœä¸€ä¸ªæƒé‡$\\eta$ï¼Œæ¥é™ä½æ¯ä¸€æ­¥çš„å½±å“ä»è€Œç»™åé¢æ ‘çš„å½¢æˆç•™ä¸‹ç©ºé—´ï¼Œæ¯”å–»æˆä¼˜åŒ–é—®é¢˜ä¸­çš„å­¦ä¹ ç‡ç¼©å‡ï¼›åŒæ—¶è¿˜ç”¨åˆ°éšæœºæ£®æ—ä¸­çš„åˆ—æŠ½æ ·ï¼Œå³éšæœºç‰¹å¾ç­›é€‰ã€‚\n3. åˆ†è£‚ç‚¹å¯»æ‰¾ç®—æ³• # 3.1 ç²¾ç¡®è´ªå©ªç®—æ³•ï¼ˆBasic Exact Greedy Algorithmï¼‰ # å³æŒ‰ç…§2.2ä¸­å¼8æ¥å¯»æ‰¾åˆ†è£‚ç‚¹ pythonscikit-learnï¼ŒRgbmï¼Œå•æœºçš„xgboostéƒ½æ”¯æŒã€‚\n3.2 è¿‘ä¼¼ç®—æ³•ï¼ˆApproximate Algorithmï¼‰ # ç²¾ç¡®è´ªå©ªç®—æ³•ç”±äºåˆ—ä¸¾äº†æ‰€æœ‰å¯èƒ½çš„åˆ†è£‚ç‚¹ï¼Œåœ¨æ•°æ®é‡å¾ˆå¤§ä¸èƒ½å…¨éƒ¨å†™å…¥å†…å­˜æ—¶ä¼šå¯¼è‡´ä¸æ˜¯é‚£ä¹ˆé«˜æ•ˆã€‚æ‰€ä»¥æå‡ºè¿‘ä¼¼ç®—æ³•ã€‚å¯¹äºæ¯ä¸ªç‰¹å¾ï¼Œåªè€ƒå¯Ÿåˆ†ä½ç‚¹ï¼Œå‡å°‘è®¡ç®—å¤æ‚åº¦ã€‚ è¿‘ä¼¼ç®—æ³•å­˜åœ¨ä¸¤ä¸ªå˜ç§ï¼š\nglobal: å­¦ä¹ æ¯æ£µæ ‘å‰ï¼Œæå‡ºå€™é€‰åˆ†è£‚ç‚¹ local: æ¯æ¬¡åˆ†è£‚å‰ï¼Œé‡æ–°æå‡ºå€™é€‰åˆ†è£‚ç‚¹ 3.3 åŠ æƒåˆ†ä½æ•°å›¾ï¼ˆWeighted Quantile Sketchï¼‰ # è¿‘ä¼¼ç®—æ³•ä¸­æœ€é‡è¦ä¸€ç‚¹å³æå‡ºå€™é€‰åˆ†è£‚ç‚¹ï¼Œxgboostä¸æ˜¯ç®€å•çš„æŒ‰ç…§æ ·æœ¬ä¸ªä½“è¿›è¡Œåˆ†ä½ï¼Œè€Œæ˜¯ä»¥æŸå¤±å‡½æ•°äºŒé˜¶å¯¼æ•°å€¼ä½œä¸ºæƒé‡è¿›è¡Œåˆ†ä½æ•°åˆ†è£‚ã€‚å¦‚ä½•å¯»æ‰¾äºŒé˜¶å¯¼æ•°åˆ†ä½ç‚¹ï¼Œé¦–å…ˆæ˜¯åˆ©ç”¨æƒé‡è®¡ç®—æ’åºå‡½æ•°ï¼Œç„¶åç›¸é‚»ç›¸å‡å€¼ä½œä¸ºåˆ¤æ–­ä¾æ®ã€‚é—®é¢˜æ˜¯ä¸ºä»€ä¹ˆä¼šæƒ³åˆ°åˆ©ç”¨æŸå¤±å‡½æ•°äºŒé˜¶å¯¼æ•°å€¼ä½œä¸ºæƒé‡æ¥åˆ’åˆ†ã€‚ æ–‡ä¸­ç»™å‡ºå¼6å¯ä»¥å˜å½¢ä¸º $$\\sum_{i=1}^n\\frac{1}{2}h_i(f_t(x_i)-g_i/h_i)^2 + \\Omega(f_t) + constant\\tag9$$ æŒ‡å‡ºè¯¥å¼æ°å¥½æ˜¯æƒé‡å¹³æ–¹å·®æŸå¤±å‡½æ•°ï¼Œæƒé‡$h_i$ä»¥åŠlabel $g_i/h_i$ è‡ªå·±ä»å¼6å˜ä¸åˆ°å¼9ï¼Œè§‰å¾—ä¸­é—´ç¬¦å·æ˜¯+è¿˜å·®ä¸å¤šã€‚ çœ‹æœ‰äººç†è§£è¯´å˜æˆå¼10æ‰å¯¹ã€‚æ˜¯å¦ä½œè€…çœŸçš„æ˜¯è¿™æ ·æƒ³çš„ï¼Œä¸å¾—è€ŒçŸ¥ã€‚æ¬¢è¿æŒ‡æ­£ã€‚ $$\\sum_{i=1}^n\\frac{1}{2}h_i(f_t(x_i)-(-g_i/h_i))^2 + \\Omega(f_t) + constant\\tag{10}$$ stackexchangeä¸Šå…³äºç†è§£xgboostè¿‘ä¼¼åˆ†è£‚ç‚¹\n3.4 ç¨€ç–å€¼æ„ŸçŸ¥åˆ†è£‚ï¼ˆSparsity-aware split findingï¼‰ # é€ æˆç¨€ç–å€¼çš„åŸå› ï¼š1ï¼‰ç¼ºå¤±å€¼ 2ï¼‰ç»Ÿè®¡è¿‡ç¨‹ä¸­é¢‘ç¹çš„0å€¼è¾“å…¥ 3ï¼‰one-hotç¼–ç ä»¥åŠå…¶ä»–ç‰¹å¾å·¥ç¨‹ æ‰€ä»¥è®©ç®—æ³•æ³¨æ„æ•°æ®ä¸­ç¨€ç–è§„å¾‹å¾ˆé‡è¦ï¼Œéå†æ‰€æœ‰ç‰¹å¾ï¼Œåœ¨åˆ’åˆ†å­èŠ‚ç‚¹æ—¶ï¼Œç»Ÿä¸€å°†è¯¥ç‰¹å¾çš„ç¼ºå¤±å€¼åˆ’åˆ†åˆ°å³æ”¯æˆ–è€…å·¦æ”¯ï¼Œè®¡ç®—æœ€å¤§çš„gainã€‚\n$\\color{red}è¿™é‡Œä¹Ÿæœ‰ä¸ªç–‘é—®å°±æ˜¯ä¸ºä»€ä¹ˆæ’åºç¬¬ä¸€æ¬¡æ˜¯å‡åºï¼Œç¬¬äºŒæ¬¡æ˜¯é™åº$\n4. ç³»ç»Ÿè®¾è®¡ # 4.1 åˆ†å—å¹¶è¡Œï¼ˆColumn Block for Parallel Learningï¼‰ # åŸºäºæ ‘å­¦ä¹ è¿‡ç¨‹ä¸­æœ€è€—æ—¶çš„æ˜¯å°†æ•°æ®æ’åºï¼Œä¸ºäº†å‡å°‘æ’åºçš„æ—¶é—´æˆæœ¬ï¼Œæå‡ºåŸºäºå†…å­˜çš„blockç»“æ„ã€‚\nåœ¨Exact greedyç®—æ³•ä¸­ï¼Œå°†æ•´ä¸ªæ•°æ®é›†å­˜æ”¾åœ¨ä¸€ä¸ªBlockä¸­ åœ¨è¿‘ä¼¼ç®—æ³•ä¸­ï¼Œä½¿ç”¨å¤šä¸ªBlockï¼Œæ¯ä¸ªBlockå¯¹åº”åŸæ¥æ•°æ®çš„å­é›†ã€‚ä¸åŒçš„Blockå¯ä»¥åœ¨ä¸åŒçš„æœºå™¨ä¸Šå¹¶è¡Œè®¡ç®— 4.2 ç¼“å­˜ä¼˜åŒ– # è¿™é‡ŒæŒ‡åˆ©ç”¨CPUç¼“å­˜å¯¹ç®—æ³•è¿›è¡Œä¼˜åŒ–ã€‚\n4.1ä¸­column blockæŒ‰ç‰¹å¾å¤§å°é¡ºåºå­˜å‚¨ï¼Œç›¸åº”çš„æ ·æœ¬çš„æ¢¯åº¦ä¿¡æ¯æ˜¯åˆ†æ•£çš„ï¼Œé€ æˆå†…å­˜çš„ä¸è¿ç»­è®¿é—®ï¼Œé™ä½CPU cacheå‘½ä¸­ç‡ã€‚ ä¼˜åŒ–æ–¹æ³•ï¼š\nå¯¹äºç²¾ç¡®è´ªå©ªç®—æ³•ï¼Œé¢„å–æ•°æ®åˆ°bufferä¸­ï¼ˆéè¿ç»­-\u0026gt;è¿ç»­ï¼‰ï¼Œå†ç»Ÿè®¡æ¢¯åº¦ä¿¡æ¯ã€‚ å¯¹äºè¿‘ä¼¼ç®—æ³•ï¼Œè°ƒèŠ‚blockçš„å¤§å°ï¼Œè®¾ç½®è¿‡å¤§åˆ™å®¹æ˜“å¯¼è‡´å‘½ä¸­ç‡ä½ï¼Œè¿‡å°åˆ™å®¹æ˜“å¯¼è‡´å¹¶è¡ŒåŒ–æ•ˆç‡ä¸é«˜ã€‚ 4.3 å¤–å­˜è®¡ç®— # é™¤äº†å¤„ç†å™¨ä»¥åŠå†…å­˜ï¼Œåˆ©ç”¨ç£ç›˜ç©ºé—´æ¥å¤„ç†ä¸èƒ½è¿›å…¥å†…å­˜çš„æ•°æ®ä¹Ÿååˆ†é‡è¦ï¼Œæ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªBlockå¹¶å­˜æ”¾åœ¨ç£ç›˜ä¸Šã€‚è®¡ç®—çš„æ—¶å€™ï¼Œä½¿ç”¨ç‹¬ç«‹çš„çº¿ç¨‹é¢„å…ˆå°†Blockæ”¾å…¥ä¸»å†…å­˜ï¼Œå› æ­¤å¯ä»¥åœ¨è®¡ç®—çš„åŒæ—¶è¯»å–ç£ç›˜ã€‚åœ¨å‡å°‘è®¡ç®—èµ„æºå¼€é”€ä»¥åŠæé«˜ç£ç›˜è¾“å…¥è¾“å‡ºæ–¹é¢ä¸»è¦ç”¨åˆ°ä»¥ä¸‹æŠ€æœ¯ï¼š\nBlockå‹ç¼©ï¼ŒæŒ‰åˆ—å‹ç¼©ï¼ŒåŠ è½½åˆ°ä¸»å†…å­˜æ—¶ç”±ç‹¬ç«‹çº¿ç¨‹åŠ¨æ€è§£å‹ç¼©ã€‚å…·ä½“å‹ç¼©æŠ€æœ¯å‚çœ‹åŸæ–‡ã€‚ Block Shardingï¼Œå°†æ•°æ®åˆ’åˆ†åˆ°ä¸åŒç¡¬ç›˜ä¸Šï¼Œæé«˜ç£ç›˜ååç‡ã€‚ 5. ç«¯åˆ°ç«¯è¯„ä¼° # åˆ©ç”¨4ä¸ªæ•°æ®é›†å¯¹xgboostè¯„ä¼°ï¼š\nåˆ†ç±»é—®é¢˜ æ’åºé—®é¢˜ å¤–å­˜è®¡ç®—å®éªŒ åˆ†å¸ƒè®¡ç®—å®éªŒ è¿™å‡ ä¸ªæ–¹é¢è¿›è¡Œè¯„ä¼°ï¼Œè¯¦ç»†ç»“æœè§è®ºæ–‡ã€‚\nref # CARTåˆ†ç±»æ ‘ä¸å›å½’æ ‘ Markdownæ•°å­¦å…¬å¼ Mathjaxåº”ç”¨åœ¨ç½‘é¡µ XGBoost.ppt readthedocs xgboost tutorialsæ¨è gbdt.ppt xgbooståŸæ–‡ è¡¥å…… # æ–‡ä¸­å¾ˆå¤šæœ¯è¯­ç¿»è¯‘å¯èƒ½æœ‰ä¸æ°å½“çš„åœ°æ–¹ï¼Œæ¬¢è¿æŒ‡å‡ºã€‚ äºŒé˜¶æ³°å‹’å±•å¼€çš„ä¸€èˆ¬å½¢å¼ï¼š $$f(x^t) = f(x^{t-1}+\\Delta x)\\approx{f(x^{t-1})+ f^{\\prime}(x^{t-1})\\Delta{x}+f^{\\prime\\prime}(x^{t-1})\\frac{\\Delta x^2}{2}}$$ å¼4ä¸­åŠ å…¥loss functionæ˜¯mean squared error(MSE)ï¼Œå¯ä»¥æ±‚å‡ºç›¸åº”çš„giï¼Œ hiä½œä¸ºä¸€ä¸ªç‰¹ä¾‹æ¥éªŒè¯è¯¥åšæ³•ã€‚ åŸºäºæ ‘çš„ç®—æ³•ç†è§£æ—¶å¸¦ç€è¿™å‡ ä¸ªé—®é¢˜å»ç†è§£æ¯ä¸€æ­¥æ˜¯ç”¨æ¥åšä»€ä¹ˆçš„ï¼šé€‰æ‹©å“ªä¸ªç‰¹å¾è¿›è¡Œåˆ†è£‚ï¼Ÿåœ¨ç‰¹å¾ä»€ä¹ˆç‚¹ä½è¿›è¡Œåˆ†è£‚ï¼Ÿåˆ†è£‚åå¶èŠ‚ç‚¹å–ä»€ä¹ˆå€¼ï¼Ÿ åˆ†åˆ«å¯¹åº”ï¼šéå†æ¯ä¸ªç‰¹å¾ï¼ŒåŠ æƒåˆ†ä½æ•°å›¾ï¼Œ$w_j$\nå¯¹äºç³»ç»Ÿè®¾è®¡ä¸­åº”ç”¨åˆ°çš„æŠ€æœ¯ç†è§£ä¸æ˜¯ååˆ†æ·±åˆ»ï¼Œå¯¹åº”ä¸€ä¸ªç®—æ³•å¦‚ä½•ä»è®¡ç®—æœºç¡¬ä»¶çš„æ–¹æ–¹é¢é¢è€ƒè™‘å»ä¼˜åŒ–å¯¹éä¸“ä¸šé¢†åŸŸç ”ç©¶è€…è¿˜æ˜¯æ¯”è¾ƒéš¾ ","date":"23 March 2020","permalink":"/posts/20200323-%E9%87%8D%E8%AF%BBxgboost/","section":"Posts","summary":"","title":"é‡è¯»XGBoost"},{"content":"","date":"9 March 2020","permalink":"/tags/lstm/","section":"Tags","summary":"","title":"lstm"},{"content":" åœ¨å»å¹´ä»‹ç»çš„ä¸€ç¯‡paperä¸­ï¼Œåº”ç”¨äº†å¤šä»»åŠ¡RNNæ¥è§£å†³é—®é¢˜ï¼Œå½“æ—¶RNNæŒ‡çš„å³æ˜¯LSTMã€‚æœ¬æ–‡ä»‹ç»LSTMå®ç°ä»¥åŠåº”ç”¨ã€‚\n1. LSTMç®€ä»‹ # å¾ªç¯ç¥ç»ç½‘ç»œè¦ç‚¹åœ¨äºå¯ä»¥å°†ä¸Šä¸€æ—¶åˆ»çš„ä¿¡æ¯ä¼ é€’ç»™ä¸‹ä¸€æ—¶åˆ»ï¼Œä½†æ˜¯åœ¨éœ€è¦é•¿ç¨‹ä¿¡æ¯ä¾èµ–çš„åœºæ™¯ï¼Œè®­ç»ƒä¸€ä¸ªå¥½çš„RNNååˆ†å›°éš¾ï¼Œå­˜åœ¨æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±çš„æƒ…å†µã€‚LSTMé€šè¿‡åˆ»æ„çš„è®¾è®¡æ¥è§£å†³è¯¥é—®é¢˜ã€‚\nç®€å•çš„RNNç½‘ç»œä¸­é‡å¤çš„æ¨¡å—åªæœ‰ä¸€ä¸ªç®€å•çš„ç»“æ„ï¼Œä¾‹å¦‚ä¸€ä¸ªreluå±‚ï¼Œè€Œåœ¨LSTMä¸­é‡å¤çš„æ¨¡å—æ‹¥æœ‰4ä¸ªä¸åŒçš„ç»“æ„ç›¸äº’äº¤äº’æ¥å®Œæˆã€‚\n1.1 é¦–å…ˆå†³å®šä»cellä¸­ä¸¢å¼ƒä»€ä¹ˆä¿¡æ¯ # $$f_t = \\sigma(W_f*[h_{t-1}, X_t] + b_f) \\tag1$$ sigmaå‡½æ•°åœ¨0åˆ°1é€‰æ‹©ä»£è¡¨ä¸¢å¼ƒä¸å¦\n1.2 ä»€ä¹ˆæ ·çš„æ–°ä¿¡æ¯å­˜æ”¾åˆ°cellä¸­ # $$i_t = \\sigma(W_i*[h_{t-1}, x_t] + b_i) \\tag2$$\n$$\\widetilde{C_t} = tanh(W_c*[h_{t-1}, x_t] + b_c) \\tag3$$\n$$C_t = f_t*C_{t-1} + {i_t} * \\widetilde{C_{t}} \\tag4$$\n4å¼ä¸­æ—§çŠ¶æ€ä¸$f_t$ç›¸ä¹˜ï¼Œä¸¢å¼ƒç¡®å®šéœ€è¦ä¸¢å¼ƒçš„ä¿¡æ¯ï¼ŒåŠ ä¸Šæ–°çš„å€™é€‰å€¼ã€‚å¯ä»¥çœ‹åˆ°å‡å¦‚é—å¿˜é—¨ä¸€ç›´ä¸º1ï¼Œå°±å¯ä»¥ä¿æŒä»¥å‰çš„ä¿¡æ¯$C_{t-1}$\n1.3 è¾“å‡ºç»“æœ # $$o_t = \\sigma(W_o[h_{t-1}, x_t] + b_o)\\tag5$$ $$h_t = o_t*tanh(C_t)\\tag6$$\n2. LSTMå®ä¾‹ä»¥åŠPytorchå®ç° # å¾ªç¯ç¥ç»ç½‘ç»œå¯ä»¥åº”ç”¨åˆ°ä»¥ä¸‹åœºæ™¯ã€‚\nç‚¹å¯¹ç‚¹ï¼ˆå•ä¸ªå›¾ç‰‡ï¼ˆæ–‡å­—ï¼‰è¢«åˆ†ç±»ï¼›å›¾åƒåˆ†ç±»ï¼‰ ç‚¹å¯¹åºåˆ—ï¼ˆå•ä¸ªå›¾åƒï¼ˆæ–‡å­—ï¼‰è¢«åˆ†ä¸ºå¤šä¸ªç±»ï¼›å›¾åƒè¾“å‡ºæ–‡å­—ï¼‰ åºåˆ—åˆ†æï¼ˆä¸€ç³»åˆ—å›¾ç‰‡ï¼ˆæ–‡å­—ï¼‰è¢«åˆ†ç±»ï¼›æƒ…æ„Ÿåˆ†æï¼‰ ä¸ç­‰é•¿åºåˆ—å¯¹åºåˆ—ï¼ˆæœºå™¨ç¿»è¯‘ï¼‰ ç­‰é•¿åºåˆ—å¯¹åºåˆ—ï¼ˆè§†é¢‘å¸§åˆ†ç±»ï¼‰ ä¸¾ä¸¤ä¸ªä¾‹å­ï¼šå›¾åƒåˆ†ç±»ä»¥åŠæ—¶é—´åºåˆ—é¢„æµ‹\n2.1 LSTMå›¾åƒåˆ†ç±» # å…³äºå›¾ç‰‡åˆ†ç±»å¸¸ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œä¾§é‡ç©ºé—´ä¸Šå¤„ç†ï¼›è€Œå¾ªç¯ç¥ç»ç½‘ç»œä¾§é‡åºåˆ—å¤„ç†ã€‚ä½†æ˜¯ä¹Ÿèƒ½ç”¨æ¥å›¾ç‰‡åˆ†ç±»ã€‚ç¬¬ä¸€ä¸ªä¾‹å­ä»¥å¸¸ç”¨çš„mnistæ‰‹å†™å­—ä½“è¯†åˆ«ä¸ºä¾‹ã€‚\n2.1.1 å¯¼å…¥æ‰€éœ€ç”¨åˆ°çš„åŒ…ä»¥åŠè¶…å‚æ•°è®¾ç½®ç­‰ # # Setup import torch from torch import nn from torch.utils.data import DataLoader import torchvision.datasets as dsets import torchvision.transforms as transforms torch.manual_seed(1) # Device configuration device = torch.device(\u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39;) 2.1.2 å¯¼å…¥æ•°æ®é›† # # Mnistæ‰‹å†™æ•°å­— train_data = dsets.MNIST(root=\u0026#39;./mnist/\u0026#39;, # ä¿å­˜æˆ–è€…æå–ä½ç½® train=True, # this is tra`ining data transform=transforms.ToTensor(), # è½¬æ¢ PIL.Image or numpy.ndarray æˆ # torch.FloatTensor (C x H x W), è®­ç»ƒçš„æ—¶å€™ normalize æˆ [0.0, 1.0] åŒºé—´ download=True, # æ²¡ä¸‹è½½å°±ä¸‹è½½, ä¸‹è½½äº†å°±ä¸ç”¨å†ä¸‹äº†æ”¹æˆFalse ) test_data = dsets.MNIST(root=\u0026#39;./mnist/\u0026#39;, train=False, transform=transforms.ToTensor()) # Dataloader # PyTorchä¸­æ•°æ®è¯»å–çš„ä¸€ä¸ªé‡è¦æ¥å£ï¼Œè¯¥æ¥å£å®šä¹‰åœ¨dataloader.pyä¸­ï¼Œåªè¦æ˜¯ç”¨PyTorchæ¥è®­ç»ƒæ¨¡å‹åŸºæœ¬éƒ½ä¼šç”¨åˆ°è¯¥æ¥å£ï¼ˆé™¤éç”¨æˆ·é‡å†™â€¦ï¼‰ï¼Œ # è¯¥æ¥å£çš„ç›®çš„ï¼šå°†è‡ªå®šä¹‰çš„Datasetæ ¹æ®batch sizeå¤§å°ã€æ˜¯å¦shuffleç­‰å°è£…æˆä¸€ä¸ªBatch Sizeå¤§å°çš„Tensorï¼Œç”¨äºåé¢çš„è®­ç»ƒã€‚ train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True) # åœ¨æ¯ä¸ªepochå¼€å§‹çš„æ—¶å€™ï¼Œå¯¹æ•°æ®é‡æ–°æ‰“ä¹±è¿›è¡Œè®­ç»ƒã€‚åœ¨è¿™é‡Œå…¶å®æ²¡å•¥ç”¨ï¼Œå› ä¸ºåªè®­ç»ƒäº†ä¸€æ¬¡ test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False) 2.1.3 å»ºç«‹æ¨¡å‹ # # LSTM # __init__ is basically a function which will \u0026#34;initialize\u0026#34;/\u0026#34;activate\u0026#34; the properties of the class for a specific object # self represents that object which will inherit those properties class simpleLSTM(nn.Module): def __init__(self, input_size, hidden_size, num_layers, num_classes): super(simpleLSTM, self).__init__() self.hidden_size = hidden_size self.num_layers = num_layers self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) self.fc = nn.Linear(hidden_size, num_classes) def forward(self, x): # x shape (batch, time_step, input_size) # out shape (batch, time_step, output_size) # h_n shape (n_layers, batch, hidden_size) # h_c shape (n_layers, batch, hidden_size) # åˆå§‹åŒ–hiddenå’Œmemory cellå‚æ•° h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # forward propagate lstm out, (h_n, h_c) = self.lstm(x, (h0, c0)) # é€‰å–æœ€åä¸€ä¸ªæ—¶åˆ»çš„è¾“å‡º out = self.fc(out[:, -1, :]) return out model = simpleLSTM(input_size, hidden_size, num_layers, num_classes) # loss and optimizer criterion = nn.CrossEntropyLoss() optimizer = torch.optim.Adam(model.parameters(), lr) 2.1.4 è®­ç»ƒæ¨¡å‹ # # train the model # å…³äºreshape(-1)çš„è§£é‡Š https://www.zhihu.com/question/52684594 # view()å’Œreshape()åŒºåˆ«çš„è§£é‡Š https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch # Hyper Parameters epochs = 1 # è®­ç»ƒæ•´æ‰¹æ•°æ®å¤šå°‘æ¬¡, ä¸ºäº†èŠ‚çº¦æ—¶é—´, æˆ‘ä»¬åªè®­ç»ƒä¸€æ¬¡ batch_size = 64 time_step = 28 # rnn æ—¶é—´æ­¥æ•° / å›¾ç‰‡é«˜åº¦ input_size = 28 # rnn æ¯æ­¥è¾“å…¥å€¼ / å›¾ç‰‡æ¯è¡Œåƒç´  hidden_size = 64 num_layers = 1 num_classes = 10 lr = 0.01 # learning rate total_step = len(train_loader) for epoch in range(epochs): for i, (images, labels) in enumerate(train_loader): images = images.reshape(-1, time_step, input_size).to(device) labels = labels.to(device) # forward pass outputs = model(images) loss = criterion(outputs, labels) # backward and optimize optimizer.zero_grad() loss.backward() optimizer.step() if i % 100 == 0: print(\u0026#39;Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}\u0026#39; .format(epoch+1, epochs, i+1, total_step, loss.item())) 2.1.5 æµ‹è¯•æ¨¡å‹ # # Test the model # https://stackoverflow.com/questions/55627780/evaluating-pytorch-models-with-torch-no-grad-vs-model-eval # torch.max()ç”¨æ³•ã€‚https://blog.csdn.net/weixin_43255962/article/details/84402586 model.eval() with torch.no_grad(): correct = 0 total = 0 for images, labels in test_loader: images = images.reshape(-1, time_step, input_size).to(device) labels = labels.to(device) outputs = model(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum().item() print(\u0026#39;Test Accuracy of the model on the 10000 test images: {} %\u0026#39;.format(100 * correct / total)) 2.2 æ—¶é—´åºåˆ—é¢„æµ‹ # Todo\n2.3 å›¾åƒè¾“å‡ºæ–‡å­— # Todo\nè¡¥å…… # åœ¨åŸå§‹å‘è¡¨æ–‡çŒ®ç”¨çš„å›¾ç¤ºæ˜¯ç±»ä¼¼äºä¸‹å›¾çš„è¿™ç§ï¼Œçœ‹èµ·æ¥æ¯”è¾ƒå¥½å®¹æ˜“ç†è§£å½“åˆå½¢æˆLSTMçš„åŸå›  pytorch lstmå‡½æ•°ç”¨æ³•ç¤ºä¾‹\nrnn = nn.LSTM(10, 20, 2) # input_size, hidden_size, num_layers input = torch.randn(5, 3, 10) # time_step, batch, input_sizeï¼ˆè¿™é‡Œinput_sizeå³featuresï¼‰ h0 = torch.randn(2, 3, 20) # num_layers, batch, hidden_size c0 = torch.randn(2, 3, 20) # num_layers, batch, hidden_size output, (hn, cn) = rnn(input, (h0, c0)) # outputåŒ…å«ä»æœ€åä¸€å±‚lstmä¸­è¾“å‡ºçš„htã€‚shape: time_step, batch, hidden_size hidden_size is the number of units of your LSTM cell. This means all the layers (input, forget, etc.) will have this size\nhidden_sizeå³pytorchéšå«å±‚æ¯ä¸ªç»“æ„ä¸­å«æœ‰çš„éšå«cellæ•°ç›®\nlstmå‡½æ•°ä¸­åŠ å…¥bidirectional=Trueå‚æ•°å³åŒå‘ç¥ç»ç½‘ç»œ Reference # ç†è§£LSTM(http://colah.github.io/posts/2015-08-Understanding-LSTMs/) é«˜æ•ˆRNN(http://karpathy.github.io/2015/05/21/rnn-effectiveness/) Hochreiter \u0026amp; Schmidhuber (1997) LSTM Pytorch LSTMå®˜æ–¹æ–‡æ¡£(https://pytorch.org/docs/stable/nn.html#lstm) ","date":"9 March 2020","permalink":"/posts/20200307-lstm%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/","section":"Posts","summary":"","title":"LSTMåº”ç”¨åœºæ™¯ä»¥åŠpytorchå®ä¾‹"},{"content":" 1. History, motivation and evolution of Deep Learning # ç§‘å­¦æŠ€æœ¯å‘å±•å¦‚æµ·æµªä¸€æ ·ä¹Ÿä¼šæ½®èµ·æ½®è½ï¼Œæ·±åº¦å­¦ä¹ åœ¨ç»å†äº†å‡ æ¬¡ä½è°·åã€‚2010å¹´å·¦å³ï¼Œåœ¨è¯­éŸ³è¯†åˆ«é¢†åŸŸå–å¾—è¿›å±•ï¼Œ2012å¹´åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸä¹Ÿå‘å±•èµ·æ¥ï¼Œéšåå„ä¸ªé¢†åŸŸéƒ½å¼€å§‹ä½¿ç”¨åº”ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œè€Œä¼¼ä¹æ¸æ¸æŠ›å¼ƒäº†å…¶ä»–æ–¹æ³•ï¼Œé‚£ä¹ˆæ·±åº¦å­¦ä¹ æ˜¯ä¸æ˜¯é—®é¢˜çš„æœ€ç»ˆè§£å†³ä¹‹é“å‘¢ï¼Ÿç ”ç©¶æ–¹å‘å®½æ³›è€Œå¤šç»´æ‰æ˜¯åˆç†çš„é“è·¯ï¼Œä¸åº”è¿‡åˆ†è¿½æ±‚çƒ­ç‚¹é¢†åŸŸã€‚æ­£å¦‚ä¸Šä¸–çºª80å¹´ä»£æ—¥æœ¬å­¦è€…åœ¨ä½è°·æ—¶æœŸä»ç„¶åšæŒè‡ªå·±çš„ç ”ç©¶é¢†åŸŸã€‚\nå­¦ä¹ è¡¨å¾ï¼šå¦‚ä½•å­¦ä¹ å¥½çš„è¡¨å¾æ˜¯æ·±åº¦å­¦ä¹ è¦è§£å†³çš„é—®é¢˜ä¹‹ä¸€ï¼ŒåŸå§‹æ•°æ®ä»¥ä¸€ç§æœ‰ç”¨çš„å½¢å¼è¿”å›ã€‚è‡ªç„¶çŠ¶æ€ä¸‹æ•°æ®ç›¸äº’ä¾èµ–æœ‰å…³ç³»çš„ã€‚é«˜æ•ˆçš„è¡¨è¾¾æ–¹å¼åº”è¯¥æ˜¯æ¯ç±»æ•°æ®éƒ½æ˜¯å®Œå…¨ç‹¬ç«‹èƒ½å®Œå…¨å•ç‹¬è¡¨è¾¾æŸä¸ªæ–¹é¢ã€‚\nspace tiling random projections polynomial classifier radial basis functions kernel machines 2. Gradient Descent and Backpropagation # 2.1 Gradient Descent # $$J(w, b) = \\frac{1}{m}\\sum_1^mL(\\hat{y}^{(i)}, y^{i})$$ J(w, b)ä¸ºé—®é¢˜çš„cost functionå³ç›®æ ‡å‡½æ•°ï¼Œå³mä¸ªæ ·æœ¬çš„æŸå¤±å‡½æ•°å¹³å‡å€¼ã€‚ä½¿ç›®æ ‡å‡½æ•°æœ€å°å¾—åˆ°æ­¤æ—¶w,bå‚æ•°æ˜¯æˆ‘ä»¬çš„ä¼˜åŒ–é—®é¢˜ã€‚\n2.1.1 æ¢¯åº¦ä¸‹é™(batch gradient descent) # æ¢¯åº¦ä¸‹é™å³ä¸Šå¼å¯¹æ‰€æœ‰æ ·æœ¬è®¡ç®—æ±‚å‡ºç›®æ ‡å‡½æ•°ï¼Œé€šè¿‡å¯¹w,bæ±‚æ¢¯åº¦æ¥æ‰¾åˆ°ç›®æ ‡å‡½æ•°æœ€å°å€¼ï¼Œå¸¸ç”¨çš„ä¸€ä¸ªæ¯”å–»å³æ‰¾æœ€å¿«è·¯å¾„ä¸‹å±±ã€‚æ•°å­¦ç†è§£æ˜¯ç®—æ³•å®ç°çš„é‡è¦ä¸€æ­¥ï¼Œä½†ä¸åœ¨è®¡ç®—æœºä¸Šå®ç°è¿˜æ˜¯æœ‰åŒºåˆ«çš„ï¼Œé‚£ä¹ˆå®é™…åšæ³•æ˜¯ä»€ä¹ˆæ ·çš„å‘¢ï¼Ÿ\nå½“ä½ å¯¹å¤æ‚çš„é—®é¢˜æƒ³ä¸æ¸…æ¥šæ—¶ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å‡ºå‘æ¥ç®€åŒ–é—®é¢˜ï¼Œå¯¹äºè¿™ä¸ªé—®é¢˜è€ƒè™‘åªæœ‰ä¸€ä¸ªæ ·æœ¬æ—¶ï¼Œæˆ‘ä»¬æ€ä¹ˆç¼–ç¨‹å®ç°å‘¢ï¼Ÿå¯¹w1ã€ b1ï¼Œè®¡ç®—ä¸€ä¸ªæ ·æœ¬çš„lossç„¶åå¯¹w1ã€b1æ±‚å¯¼ä¼˜åŒ–æ€è·¯å¾ˆæ¸…æ™°ï¼Œé‚£ä¹ˆæœ‰mä¸ªæ ·æœ¬çš„æ—¶å€™å‘¢ï¼Ÿåªéœ€å°†å…¶ä»–æ ·æœ¬è®¡ç®—lossï¼Œç„¶åå¯¹w1ã€b1æ±‚å¯¼ç›¸åŠ ã€‚æœ€ååœ¨é€šè¿‡å­¦ä¹ ç‡æ¥æ›´æ–°wã€bã€‚å¯ä»¥çœ‹åˆ°æ¯æ¬¡æ›´æ–°éƒ½éœ€è¦è¿›è¡Œmæ¬¡è¿ç®—\n2.1.2 å°æ ·æœ¬æ¢¯åº¦ä¸‹é™ï¼ˆmini-batch gradient descentï¼‰ # åœ¨æ¯æ¬¡æ›´æ–°æ—¶ç”¨nä¸ªæ ·æœ¬ï¼Œä¸ç”¨å…¨éƒ¨çš„æ ·æœ¬ã€‚åœ¨æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨è¿™ç§æ–¹æ³•ã€‚ç”¨mini-batchå¯ä»¥äº«å—å‘é‡åŒ–å¸¦æ¥çš„ä¾¿åˆ©ï¼Œä¹Ÿä¸ç”¨å…¨æ¢¯åº¦ä¸‹é™é‚£ä¹ˆå¤§è®¡ç®—é‡ï¼ŒåŒæ—¶è¿™ä¹Ÿæ˜¯åº”å¯¹å†—ä½™æ•°æ®çš„ä¸€ç§æ–¹æ³•ã€‚\n2.1.3 éšæœºæ¢¯åº¦ä¸‹é™(stochastic gradient descent) # å½“n = 1çš„æ—¶å€™ï¼Œæ¯æ¬¡æ›´æ–°çš„æ—¶å€™ç”¨1ä¸ªæ ·æœ¬ã€‚è¯¥æ–¹æ³•åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ¯”å…¨æ ·æœ¬çš„æ¢¯åº¦ä¸‹é™è¦å¿«ã€‚\nä¸‰ç§ä¼˜åŒ–æ–¹æ³•æœ€åæ”¶æ•›å—ï¼Ÿæœ€åèƒ½è¾¾åˆ°å…¨å±€æœ€å°å€¼å—ï¼Ÿè¿™æ˜¯ä¼˜åŒ–æ–¹æ³•éƒ½éœ€è¦è€ƒè™‘åˆ°çš„ã€‚å¯ä»¥é˜…è¯»Optimization Methods for Large-Scale Machine Learningï¼Œæˆ‘è‡ªå·±è¿˜æ²¡è¯»è¿‡\u0026hellip;\n2.2 Backprop # åå‘ä¼ æ’­æ˜¯ä¸ºäº†æ±‚æ¢¯åº¦ç”¨åˆ°çš„å¾®ç§¯åˆ†é“¾å¼æ³•åˆ™ï¼Œä»è€Œä½¿æ¢¯åº¦ä¸‹é™ç®—æ³•è¿è¡Œã€‚\n2.3 PyTorchè®­ç»ƒç¥ç»ç½‘ç»œæ­¥éª¤ # output = model(input) å³ç¥ç»ç½‘ç»œå‰å‘ä¼ æ’­ J = loss(output, label) è®¡ç®—cost function model.zero_grad() æ¸…é™¤æ¢¯åº¦è®¡ç®— J.backward() å¯¹requires_grad = Trueçš„å˜é‡è®¡ç®—æ¢¯åº¦ optimiser.step() è¿›è¡Œæ¢¯åº¦ä¸‹é™ 3. æ€»ç»“ # çœ‹äº†å‰ä¸¤èŠ‚ï¼Œè§‰å¾—è¿˜æ˜¯å´æ©è¾¾å¤§ä½¬è®²çš„å¥½ä¸€äº›ã€‚å»ºè®®ç½‘é¡µä¸Šå¿«é€Ÿè¿‡å†…å®¹å³å¯ï¼Œè§†é¢‘ä¸ç”¨ç»†çœ‹ã€‚\n","date":"5 March 2020","permalink":"/posts/20200305-pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","section":"Posts","summary":"","title":"PyTorchæ·±åº¦å­¦ä¹ ï¼ˆ1ï¼‰"},{"content":"","date":"4 March 2019","permalink":"/tags/git/","section":"Tags","summary":"","title":"git"},{"content":"ä»¥ä¸‹æ“ä½œåŸºäºmacOSï¼ŒWindowsä»…ä¾›å‚è€ƒã€‚\ngitåˆå§‹åŒ–æ–‡ä»¶å¤¹ # è¿›å…¥ç›®å½•\ngit init æ–°å»º.gitignore # ç„¶ååœ¨å…¶ä¸­åŠ å…¥éœ€è¦å¿½ç•¥çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹.gitignore ä¾‹å¦‚public\\\ngitåˆ é™¤.DS_Storeæ–‡ä»¶ # ä»è¯¥ä»“åº“ä¸­åˆ é™¤å·²å­˜åœ¨çš„DS_Storeæ–‡ä»¶1 find . -name .DS_Store -print0 | xargs -0 git rm -f --ignore-unmatch æ–°å»º.gitignore_globalæ–‡ä»¶å¹¶å°†.DS_Storeä»¥åŠ*/.DS_StoreåŠ å…¥å…¶ä¸­ vi .gitignore_global # å†™å…¥.DS_Storeï¼Œ*/.DS_Store git config --global core.excludesfile ~/.gitignore_global æ¨åˆ°ä»“åº“ git add .gitignore git commit -m \u0026#39;.DS_Store banished!\u0026#39; æ£€æŸ¥ä»“åº“ä¸­æ˜¯å¦è¿˜æœ‰ git status gitåˆ é™¤è¿œç¨‹åˆ†æ”¯æ–‡ä»¶ # å½“æˆ‘ä»¬éœ€è¦åˆ é™¤æš‚å­˜åŒºæˆ–åˆ†æ”¯ä¸Šçš„æ–‡ä»¶, åŒæ—¶å·¥ä½œåŒºä¹Ÿä¸éœ€è¦è¿™ä¸ªæ–‡ä»¶äº†, å¯ä»¥ä½¿ç”¨\ngit rm file_path å½“æˆ‘ä»¬éœ€è¦åˆ é™¤æš‚å­˜åŒºæˆ–åˆ†æ”¯ä¸Šçš„æ–‡ä»¶, ä½†æœ¬åœ°åˆéœ€è¦ä½¿ç”¨, åªæ˜¯ä¸å¸Œæœ›è¿™ä¸ªæ–‡ä»¶è¢«ç‰ˆæœ¬æ§åˆ¶, å¯ä»¥ä½¿ç”¨\ngit rm â€“cached file_path æ‰€ä»¥æˆ‘ä»¬ç»å¸¸ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¥åˆ é™¤gitä¸­çš„æ–‡ä»¶\ngit rm -r --cached filename git commit -m \u0026#39;delete some file\u0026#39; git push origin master gitå†²çªå¤„ç† # gitè¿œç¨‹åˆ†æ”¯ä¿®æ”¹ï¼Œæœ¬åœ°ä¹Ÿä¿®æ”¹äº†å‡†å¤‡æäº¤å‡ºç°å†²çª\nå…ˆæ‹‰åœ¨æ¨ git pull --rebase #æ£€æŸ¥åˆå¹¶æ˜¯å¦å†²çª git push -u origin master å¼ºåˆ¶æŒ‰æœ¬åœ°æ›´æ–° git push -f gitå­æ¨¡å—ï¼ˆsubmoduleï¼‰ # å¯¹äºå…¬å…±èµ„æºæˆ–è€…å¸¸ç”¨çš„ä»£ç ï¼Œä½ å¯èƒ½ä¼šæŠŠæœ€æ–°ç‰ˆæœ¬é€ä¸ªå¤åˆ¶åˆ°Nä¸ªé¡¹ç›®ä¸­ï¼Œå¦‚æœä½¿ç”¨äº†submoduleæ¨¡å—ï¼Œé‚£ä¹ˆåªéœ€è¦åœ¨å„ä¸ªé¡¹ç›®ä¸­\ngit submodule update è¿›å…¥å­æ¨¡å—ç›®å½•æ­£å¸¸æ“ä½œå³å¯\ngitå¤šè´¦æˆ·åˆ‡æ¢ # åˆ é™¤keychain accessç§å­˜å‚¨è´¦æˆ·\nGitåˆ é™¤.DS_Store\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"4 March 2019","permalink":"/posts/20190304-git/","section":"Posts","summary":"","title":"Gitå¸¸ç”¨å‘½ä»¤"},{"content":"","date":"4 March 2019","permalink":"/categories/syntax/","section":"Categories","summary":"","title":"Syntax"}]