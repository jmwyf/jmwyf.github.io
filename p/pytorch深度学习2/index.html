<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="本文是NYC深度学习课程学习总结第三四节笔记以及pytorch mnist手写字识别CNN实践"><title>PyTorch深度学习（2）</title><link rel=canonical href=https://jmwyf.github.io/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/><link rel=stylesheet href=/scss/style.min.8191399262444ab68b72a18c97392f5349be20a1615d77445be51e974c144cff.css><meta property="og:title" content="PyTorch深度学习（2）"><meta property="og:description" content="本文是NYC深度学习课程学习总结第三四节笔记以及pytorch mnist手写字识别CNN实践"><meta property="og:url" content="https://jmwyf.github.io/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/"><meta property="og:site_name" content="从百草园到三味书屋"><meta property="og:type" content="article"><meta property="article:section" content="Post"><meta property="article:tag" content="pytorch"><meta property="article:published_time" content="2020-04-01T14:51:32+00:00"><meta property="article:modified_time" content="2020-04-01T14:51:32+00:00"><meta property="og:image" content="https://jmwyf.github.io/images/pytorch/mnist_pre.png"><meta name=twitter:title content="PyTorch深度学习（2）"><meta name=twitter:description content="本文是NYC深度学习课程学习总结第三四节笔记以及pytorch mnist手写字识别CNN实践"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jmwyf.github.io/images/pytorch/mnist_pre.png"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-133677720-1","auto"),ga("send","pageview"))</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_huee84e2c56840f3483a5fc1306f905ef2_56463_300x0_resize_box_3.png width=300 height=274 class=site-logo loading=lazy alt=Avatar></a>
<span class=emoji>🍥</span></figure><div class=site-meta><h1 class=site-name><a href=/>从百草园到三味书屋</a></h1><h2 class=site-description>靡不有初，鲜克有终.</h2></div></header><ol class=social-menu><li><a href target=_blank title=GitHub rel=me><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg><span>Home</span></a></li><li><a href=/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg><span>About</span></a></li><li><a href=/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg><span>Archives</span></a></li><li><a href=/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg><span>Search</span></a></li><li><a href=/links/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg><span>Links</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg><select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://jmwyf.github.io/ selected>English</option><option value=https://jmwyf.github.io/zh-cn/>中文</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg><span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#1-卷积神经网络>1. 卷积神经网络</a><ol><li><a href=#11-神经网络可视化visualization-of-neural-networks>1.1 神经网络可视化（Visualization of neural networks）</a></li><li><a href=#12-卷积神经网络的起源convolutional-neural-networkcnn>1.2 卷积神经网络的起源（Convolutional Neural Network；CNN）</a></li><li><a href=#13-卷积神经网络分解>1.3 卷积神经网络分解</a></li></ol></li><li><a href=#2-自然信号数据natural-signals>2. 自然信号数据（Natural Signals）</a><ol><li><a href=#21-自然信号数据特性>2.1 自然信号数据特性</a></li><li><a href=#22-对应神经网络中的处理方法>2.2 对应神经网络中的处理方法</a></li></ol></li><li><a href=#3-pytorch实现mnist手写字识别>3. Pytorch实现Mnist手写字识别</a></li><li><a href=#4-补充>4. 补充</a></li><li><a href=#ref>ref</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/><img src=/images/pytorch/mnist_pre.png loading=lazy alt="Featured image of post PyTorch深度学习（2）"></a></div><div class=article-details><header class=article-category><a href=/categories/deep-learning/>Deep Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/>PyTorch深度学习（2）</a></h2><h3 class=article-subtitle>本文是NYC深度学习课程学习总结第三四节笔记以及pytorch mnist手写字识别CNN实践</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg><time class=article-time--published>Apr 01, 2020</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg><time class=article-time--reading>4 minute read</time></div></footer></div></header><section class=article-content><h1 id=pytorch深度学习2>PyTorch深度学习（2）</h1><p>Deep Learning = Learning Hierarchical Representations
深度学习即学习层次的表征。</p><h2 id=1-卷积神经网络>1. 卷积神经网络</h2><h3 id=11-神经网络可视化visualization-of-neural-networks>1.1 神经网络可视化（Visualization of neural networks）</h3><p>神经网络每一层的操作有点像将空间某些区域进行折叠</p><h3 id=12-卷积神经网络的起源convolutional-neural-networkcnn>1.2 卷积神经网络的起源（Convolutional Neural Network；CNN）</h3><p>受到Fukushima在视觉皮层建模方面的启发，使用简单/复杂的细胞层次结构，结合有监督的训练和反向传播，由Yann LeCun教授于88-89年在多伦多大学开发了第一个CNN。</p><p>Fukushima的工作具体是什么呢？<br>手写数字识别。首次提出应用多层简单或者复杂的细胞结构建模，特征：手工加无监督聚类学习。无反向传播。</p><h3 id=13-卷积神经网络分解>1.3 卷积神经网络分解</h3><p>通用的CNN架构能被分解为以下几个基本结构。</p><ul><li>标准化（Normalisation）:对比度标准化等</li><li>滤波器组（Filter banks）:边缘检测等</li><li>非线性化（Non-linearities）:稀疏化、ReLU等</li><li>池化（pooling）:最大池化（max pooling）等</li></ul><h2 id=2-自然信号数据natural-signals>2. 自然信号数据（Natural Signals）</h2><h3 id=21-自然信号数据特性>2.1 自然信号数据特性</h3><ul><li>周期性：在时域很多模式都会重复出现</li><li>局部性：相邻的点较相远的点来说更具关联性</li><li>合成性：复杂的事物可以由简单的事物组合而成。字母->单词->句子->文章</li></ul><h3 id=22-对应神经网络中的处理方法>2.2 对应神经网络中的处理方法</h3><ul><li>周期性$\rightarrow$参数共享<br>如果数据存在周期性，可以使用参数共享，即卷积核。</li><li>局部性$\rightarrow$稀疏<br>如果数据存在局部性，那么每个神经元只需要与前几个神经元连接</li><li>合成性$\rightarrow$多层<br>即神经网络中多层网络合成最终的结果</li></ul><h2 id=3-pytorch实现mnist手写字识别>3. Pytorch实现Mnist手写字识别</h2><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># load package and data</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision</span> <span class=kn>import</span> <span class=n>datasets</span><span class=p>,</span> <span class=n>transforms</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;cuda:0&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 神经网络模型偏爱标准化数据，原因是均值为0方差为1的数据在sigmoid、tanh经过激活函数后求导得到的导数很大，</span>
</span></span><span class=line><span class=cl><span class=c1># 反之原始数据不仅分布不均（噪声大）而且数值通常都很大（本例中数值范围是0~255），激活函数后求导得到的导数</span>
</span></span><span class=line><span class=cl><span class=c1># 则接近与0，这也被称为梯度消失。</span>
</span></span><span class=line><span class=cl><span class=c1># 目录放自己下载好的mnist目录，没有下载将download=True,自己新建一个存放数据目录即可</span>
</span></span><span class=line><span class=cl><span class=n>train_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>datasets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=s1>&#39;../LSTM_mnist/mnist&#39;</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>download</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                   <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                       <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                       <span class=c1># mnist数据集均值0.1307，标准差0.3081</span>
</span></span><span class=line><span class=cl>                       <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>((</span><span class=mf>0.1307</span><span class=p>,),</span> <span class=p>(</span><span class=mf>0.3081</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>                   <span class=p>])),</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_loader</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>DataLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>datasets</span><span class=o>.</span><span class=n>MNIST</span><span class=p>(</span><span class=s1>&#39;../LSTM_mnist/mnist&#39;</span><span class=p>,</span> <span class=n>train</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>                       <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                       <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>((</span><span class=mf>0.1307</span><span class=p>,),</span> <span class=p>(</span><span class=mf>0.3081</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>                   <span class=p>])),</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>shuffle</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># define model</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SimpleCNN</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_size</span><span class=p>,</span> <span class=n>n_feature</span><span class=p>,</span> <span class=n>output_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>SimpleCNN</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_feature</span> <span class=o>=</span> <span class=n>n_feature</span>
</span></span><span class=line><span class=cl>        <span class=c1># 关于nn.Conv2d()中参数的解释</span>
</span></span><span class=line><span class=cl>        <span class=c1># in_channels (int): Number of channels in the input image</span>
</span></span><span class=line><span class=cl>        <span class=c1># out_channels (int): Number of channels produced by the convolution</span>
</span></span><span class=line><span class=cl>        <span class=c1># kernel_size (int or tuple): Size of the convolving kernel</span>
</span></span><span class=line><span class=cl>        <span class=c1># default stride=1, padding=0, dilation=1, groups=1</span>
</span></span><span class=line><span class=cl>        <span class=c1># [groupsc参数详解](https://www.jianshu.com/p/20ba3d8f283c)</span>
</span></span><span class=line><span class=cl>        <span class=c1># [图解卷积神经网络中stride, padding等操作可视化](https://github.com/vdumoulin/conv_arithmetic)</span>
</span></span><span class=line><span class=cl>        <span class=c1># input: (N, C_in, H_in, W_in)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>out_channels</span><span class=o>=</span><span class=n>n_feature</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>n_feature</span><span class=p>,</span> <span class=n>n_feature</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>n_feature</span><span class=o>*</span><span class=mi>4</span><span class=o>*</span><span class=mi>4</span><span class=p>,</span> <span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>50</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># Mnist数据原始大小（28*28）28-5+1 = 24 (24*24*n_feature)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>max_pool2d</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>  <span class=c1># (12*12*n_feature)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># 12-5+1 = 8 (8*8*n_feature)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>max_pool2d</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>  <span class=c1># (4*4*n_feature)这里解释了上面全连接时为啥是4*4</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_feature</span><span class=o>*</span><span class=mi>4</span><span class=o>*</span><span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># hyper parameters</span>
</span></span><span class=line><span class=cl><span class=n>epochs</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>input_size</span> <span class=o>=</span> <span class=mi>28</span><span class=o>*</span><span class=mi>28</span>
</span></span><span class=line><span class=cl><span class=n>output_size</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=n>n_features</span> <span class=o>=</span> <span class=mi>6</span>
</span></span><span class=line><span class=cl><span class=n>lr</span> <span class=o>=</span> <span class=mf>0.01</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>SimpleCNN</span><span class=p>(</span><span class=n>input_size</span><span class=p>,</span> <span class=n>n_features</span><span class=p>,</span> <span class=n>output_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># optimizer</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=p>,</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Number of parameters: </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>get_n_params</span><span class=p>(</span><span class=n>model</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># model train</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>train_loader</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>target</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>nll_loss</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>i</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Train Epoch [</span><span class=si>{}</span><span class=s1>/</span><span class=si>{}</span><span class=s1>], [</span><span class=si>{}</span><span class=s1>/</span><span class=si>{}</span><span class=s1> (</span><span class=si>{:.0f}</span><span class=s1>%)], Loss: </span><span class=si>{:.4f}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>epoch</span><span class=o>+</span><span class=mi>1</span><span class=p>,</span> <span class=n>epochs</span><span class=p>,</span> <span class=n>i</span><span class=o>*</span><span class=nb>len</span><span class=p>(</span><span class=n>data</span><span class=p>),</span> <span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=mi>100</span><span class=o>*</span><span class=n>i</span><span class=o>/</span><span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>),</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=c1># model eval</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>test_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>accuracy_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=ow>in</span> <span class=n>test_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=p>,</span> <span class=n>target</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span> <span class=n>target</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>test_loss</span> <span class=o>+=</span> <span class=n>F</span><span class=o>.</span><span class=n>nll_loss</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>target</span><span class=p>,</span> <span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;sum&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>pred</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span>  <span class=c1># get the index of the max log-probability</span>
</span></span><span class=line><span class=cl>    <span class=n>correct</span> <span class=o>+=</span> <span class=n>pred</span><span class=o>.</span><span class=n>eq</span><span class=p>(</span><span class=n>target</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>view_as</span><span class=p>(</span><span class=n>pred</span><span class=p>))</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>test_loss</span> <span class=o>/=</span> <span class=nb>len</span><span class=p>(</span><span class=n>test_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=mf>100.</span> <span class=o>*</span> <span class=n>correct</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>test_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>accuracy_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>accuracy</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>Test set Average loss: </span><span class=si>{:.4f}</span><span class=s1>, Accuracy: </span><span class=si>{}</span><span class=s1>/</span><span class=si>{}</span><span class=s1> (</span><span class=si>{:.0f}</span><span class=s1>%)</span><span class=se>\n</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>test_loss</span><span class=p>,</span> <span class=n>correct</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>test_loader</span><span class=o>.</span><span class=n>dataset</span><span class=p>),</span> <span class=n>accuracy</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 几个预测的实例可视化</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>subplot</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Prediction: </span><span class=si>{}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>1</span><span class=p>][</span><span class=n>i</span><span class=p>]</span><span class=o>.</span><span class=n>item</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p><img src=/images/pytorch/mnist_pre.png loading=lazy></p><h2 id=4-补充>4. 补充</h2><ol><li>可以做一个有趣的实验即打乱图片中的像素后CNN识别正确率下降，而全连接网络则不会，即与最开始提到的三个特性以及对于神经网络采取的假设是吻合的。</li><li>参考2中是对卷积神经网络全面的介绍，包括CNN中常用那些层，以及常用的模型和参数多少计算。</li></ol><h2 id=ref>ref</h2><ol><li><a class=link href=https://atcold.github.io/pytorch-Deep-Learning/ target=_blank rel=noopener>NYC PyTorch Deep Learning</a>课程网站</li><li>cs231n <a class=link href=https://cs231n.github.io/convolutional-networks/ target=_blank rel=noopener>convolutional networks</a></li><li><a class=link href=https://pytorch.org/docs/stable/nn.html#convolution-layers target=_blank rel=noopener>pytorch官方文档Conv2d</a></li><li><a class=link href=https://github.com/Atcold/pytorch-Deep-Learning/blob/master/06-convnet.ipynb target=_blank rel=noopener>课程convnet.ipynb</a></li></ol></section><footer class=article-footer><section class=article-tags><a href=/tags/pytorch/>pytorch</a></section><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg><span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/lstm%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%BB%A5%E5%8F%8Apytorch%E5%AE%9E%E4%BE%8B/><div class=article-image><img src=/images/LSTM/LSTM.jpg loading=lazy data-key data-hash=/images/LSTM/LSTM.jpg></div><div class=article-details><h2 class=article-title>LSTM应用场景以及pytorch实例</h2></div></a></article><article class=has-image><a href=/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A01/><div class=article-image><img src=/images/pytorch/pytorch.jpeg loading=lazy data-key data-hash=/images/pytorch/pytorch.jpeg></div><div class=article-details><h2 class=article-title>PyTorch深度学习（1）</h2></div></a></article></div></div></aside><div id=cusdis_thread data-host=https://cusdis.com data-app-id=1cfc2662-243a-4573-b9e7-8b2b4a986fba data-page-id=2fff665a22522e759c303d6d92a722da data-page-url=https://jmwyf.github.io/p/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/ data-page-title=PyTorch深度学习（2）></div><script async defer src=https://cusdis.com/js/cusdis.es.js></script>
<script>function setCusdisTheme(e){let t=document.querySelector("#cusdis_thread iframe");t&&window.CUSDIS.setTheme(e)}window.addEventListener("onColorSchemeChange",e=>{setCusdisTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2019 -
2022 从百草园到三味书屋</section><section class=powerby>his history is history<br>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.16.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script>
<script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>